{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5881e11444aa48a8ac5c8e0e146b76b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69ead85cc60242eaa537662010eacb91",
              "IPY_MODEL_78f609b3e77147d39a479f5de4472585",
              "IPY_MODEL_8284ba80ff4c4764a4615d5618d5b95a"
            ],
            "layout": "IPY_MODEL_93c1076499f14c2691b99edd35e57dd3"
          }
        },
        "69ead85cc60242eaa537662010eacb91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19c23dd96fe14f8d91339df508976953",
            "placeholder": "​",
            "style": "IPY_MODEL_870e257011554e43abc83ee384268a91",
            "value": "Downloading: 100%"
          }
        },
        "78f609b3e77147d39a479f5de4472585": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89c8aba0ac314cb698754a0073c9e0eb",
            "max": 80,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b79563cd8c0f4fd293fa471aba222193",
            "value": 80
          }
        },
        "8284ba80ff4c4764a4615d5618d5b95a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e76ed75d061f402e8a16504493c95619",
            "placeholder": "​",
            "style": "IPY_MODEL_74d72780fe254b55844132cbd8919a75",
            "value": " 80.0/80.0 [00:00&lt;00:00, 3.03kB/s]"
          }
        },
        "93c1076499f14c2691b99edd35e57dd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19c23dd96fe14f8d91339df508976953": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "870e257011554e43abc83ee384268a91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89c8aba0ac314cb698754a0073c9e0eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b79563cd8c0f4fd293fa471aba222193": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e76ed75d061f402e8a16504493c95619": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74d72780fe254b55844132cbd8919a75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e922005e9404a219f336027eb305c19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dc98bbfead18413ebce741e71b22e2d2",
              "IPY_MODEL_4be8e8d8ca8e48ecb8e45447c7a35295",
              "IPY_MODEL_4c78a627b1b84cf1a905f5aa8d09b7dd"
            ],
            "layout": "IPY_MODEL_270c2261e2084300ba18e2b98e0894b7"
          }
        },
        "dc98bbfead18413ebce741e71b22e2d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b44a1dfb03043a49f8e92c8d389a3b8",
            "placeholder": "​",
            "style": "IPY_MODEL_31147d20714f459fbc25fbe9c8b5b2e4",
            "value": "Downloading: 100%"
          }
        },
        "4be8e8d8ca8e48ecb8e45447c7a35295": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88f8ca538fde48158e173fab9c197672",
            "max": 725,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9b17be4f58764e47a2b762bb6457565d",
            "value": 725
          }
        },
        "4c78a627b1b84cf1a905f5aa8d09b7dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a803bed50ac844fbb37620e7a24cd519",
            "placeholder": "​",
            "style": "IPY_MODEL_a7fafe42326f4ce6a264d707be365f73",
            "value": " 725/725 [00:00&lt;00:00, 28.5kB/s]"
          }
        },
        "270c2261e2084300ba18e2b98e0894b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b44a1dfb03043a49f8e92c8d389a3b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31147d20714f459fbc25fbe9c8b5b2e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88f8ca538fde48158e173fab9c197672": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b17be4f58764e47a2b762bb6457565d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a803bed50ac844fbb37620e7a24cd519": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7fafe42326f4ce6a264d707be365f73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b72aa76271c4246b3d5eea309d17058": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee75d1c3f6f34c0988ae3bbb83065f41",
              "IPY_MODEL_b76d8d4a25b64fdaacb72edca24b35a5",
              "IPY_MODEL_27857de3626b430bb1843a1c18c8fe48"
            ],
            "layout": "IPY_MODEL_f54c1719a3f144fe9f209117e7da7ddd"
          }
        },
        "ee75d1c3f6f34c0988ae3bbb83065f41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_803aad3a03b04cd092ffb11e2ff64c7c",
            "placeholder": "​",
            "style": "IPY_MODEL_fc6cf49180464a97ab218c9088c84f2f",
            "value": "Downloading: 100%"
          }
        },
        "b76d8d4a25b64fdaacb72edca24b35a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccbf3f6a891f4f55a98ff90937aa89ed",
            "max": 344259,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_681b2ff69dea4e278a618f7188aacf6b",
            "value": 344259
          }
        },
        "27857de3626b430bb1843a1c18c8fe48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abd69173de6a4c1a8123fce745de2503",
            "placeholder": "​",
            "style": "IPY_MODEL_bd23c527454f4f4e8bd3b2723f6f1b52",
            "value": " 344k/344k [00:00&lt;00:00, 283kB/s]"
          }
        },
        "f54c1719a3f144fe9f209117e7da7ddd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "803aad3a03b04cd092ffb11e2ff64c7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc6cf49180464a97ab218c9088c84f2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ccbf3f6a891f4f55a98ff90937aa89ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "681b2ff69dea4e278a618f7188aacf6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "abd69173de6a4c1a8123fce745de2503": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd23c527454f4f4e8bd3b2723f6f1b52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52ac3cb9c9394221b0a652eaba07df8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4c199c10f1fc4ced95802058baffc92e",
              "IPY_MODEL_cc7901be85964c45b29914415d557246",
              "IPY_MODEL_143120b401674f5387a48ad80c1ee5cc"
            ],
            "layout": "IPY_MODEL_60213d8ea19042389f81c71e3fe04236"
          }
        },
        "4c199c10f1fc4ced95802058baffc92e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_daa31a90026f465e93ac0a7ddd42d41c",
            "placeholder": "​",
            "style": "IPY_MODEL_1cd7e2b2807740e1879a530490307a24",
            "value": "Downloading: 100%"
          }
        },
        "cc7901be85964c45b29914415d557246": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ba077b488844d1e81a69d634031b58d",
            "max": 475782997,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2c548db94e704c77bb700339d40caee6",
            "value": 475782997
          }
        },
        "143120b401674f5387a48ad80c1ee5cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64c2a6dbcfe641d997f68e0a01d5b204",
            "placeholder": "​",
            "style": "IPY_MODEL_0dac962745a748f88d440a339358c84e",
            "value": " 476M/476M [00:07&lt;00:00, 68.4MB/s]"
          }
        },
        "60213d8ea19042389f81c71e3fe04236": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "daa31a90026f465e93ac0a7ddd42d41c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cd7e2b2807740e1879a530490307a24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ba077b488844d1e81a69d634031b58d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c548db94e704c77bb700339d40caee6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "64c2a6dbcfe641d997f68e0a01d5b204": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dac962745a748f88d440a339358c84e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q69TX6aiAHi5",
        "outputId": "ea8211d5-2350-4fd2-ef02-a1af2287aa21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.6.1-py3-none-any.whl (441 kB)\n",
            "\u001b[K     |████████████████████████████████| 441 kB 36.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n",
            "\u001b[K     |████████████████████████████████| 115 kB 88.5 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.2.0\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 10.5 MB/s \n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 95.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (5.0.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.8.2)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.3)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 91.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.9.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: urllib3, xxhash, responses, multiprocess, huggingface-hub, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed datasets-2.6.1 huggingface-hub-0.10.1 multiprocess-0.70.13 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.23.1-py3-none-any.whl (5.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.3 MB 10.4 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 80.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (5.0.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.9.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "Successfully installed tokenizers-0.13.1 transformers-4.23.1\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python3-dev is already the newest version (3.6.7-1~18.04).\n",
            "python3-dev set to manually installed.\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n",
            "  libatk-wrapper-java-jni libgail-common libgail18 libgtk2.0-0 libgtk2.0-bin\n",
            "  libgtk2.0-common libxxf86dga1 openjdk-8-jdk-headless openjdk-8-jre\n",
            "  openjdk-8-jre-headless x11-utils\n",
            "Suggested packages:\n",
            "  gvfs openjdk-8-demo openjdk-8-source visualvm libnss-mdns\n",
            "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
            "  fonts-wqy-zenhei fonts-indic mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n",
            "  libatk-wrapper-java-jni libgail-common libgail18 libgtk2.0-0 libgtk2.0-bin\n",
            "  libgtk2.0-common libxxf86dga1 openjdk-8-jdk openjdk-8-jdk-headless\n",
            "  openjdk-8-jre openjdk-8-jre-headless x11-utils\n",
            "0 upgraded, 15 newly installed, 0 to remove and 12 not upgraded.\n",
            "Need to get 46.0 MB of archives.\n",
            "After this operation, 166 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxxf86dga1 amd64 2:1.1.4-1 [13.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-core all 2.37-1 [1,041 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-extra all 2.37-1 [1,953 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11-utils amd64 7.7+3build1 [196 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk-wrapper-java all 0.33.3-20ubuntu0.1 [34.7 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk-wrapper-java-jni amd64 0.33.3-20ubuntu0.1 [28.3 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-common all 2.24.32-1ubuntu1 [125 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-0 amd64 2.24.32-1ubuntu1 [1,769 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail18 amd64 2.24.32-1ubuntu1 [14.2 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail-common amd64 2.24.32-1ubuntu1 [112 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-bin amd64 2.24.32-1ubuntu1 [7,536 B]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jre-headless amd64 8u342-b07-0ubuntu1~18.04 [28.3 MB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jre amd64 8u342-b07-0ubuntu1~18.04 [69.6 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jdk-headless amd64 8u342-b07-0ubuntu1~18.04 [8,300 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jdk amd64 8u342-b07-0ubuntu1~18.04 [4,032 kB]\n",
            "Fetched 46.0 MB in 6s (7,985 kB/s)\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "(Reading database ... 123934 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libxxf86dga1_2%3a1.1.4-1_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
            "Selecting previously unselected package fonts-dejavu-core.\n",
            "Preparing to unpack .../01-fonts-dejavu-core_2.37-1_all.deb ...\n",
            "Unpacking fonts-dejavu-core (2.37-1) ...\n",
            "Selecting previously unselected package fonts-dejavu-extra.\n",
            "Preparing to unpack .../02-fonts-dejavu-extra_2.37-1_all.deb ...\n",
            "Unpacking fonts-dejavu-extra (2.37-1) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../03-x11-utils_7.7+3build1_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+3build1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java.\n",
            "Preparing to unpack .../04-libatk-wrapper-java_0.33.3-20ubuntu0.1_all.deb ...\n",
            "Unpacking libatk-wrapper-java (0.33.3-20ubuntu0.1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
            "Preparing to unpack .../05-libatk-wrapper-java-jni_0.33.3-20ubuntu0.1_amd64.deb ...\n",
            "Unpacking libatk-wrapper-java-jni:amd64 (0.33.3-20ubuntu0.1) ...\n",
            "Selecting previously unselected package libgtk2.0-common.\n",
            "Preparing to unpack .../06-libgtk2.0-common_2.24.32-1ubuntu1_all.deb ...\n",
            "Unpacking libgtk2.0-common (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgtk2.0-0:amd64.\n",
            "Preparing to unpack .../07-libgtk2.0-0_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgail18:amd64.\n",
            "Preparing to unpack .../08-libgail18_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgail18:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgail-common:amd64.\n",
            "Preparing to unpack .../09-libgail-common_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgail-common:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgtk2.0-bin.\n",
            "Preparing to unpack .../10-libgtk2.0-bin_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgtk2.0-bin (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "Preparing to unpack .../11-openjdk-8-jre-headless_8u342-b07-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u342-b07-0ubuntu1~18.04) ...\n",
            "Selecting previously unselected package openjdk-8-jre:amd64.\n",
            "Preparing to unpack .../12-openjdk-8-jre_8u342-b07-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre:amd64 (8u342-b07-0ubuntu1~18.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../13-openjdk-8-jdk-headless_8u342-b07-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u342-b07-0ubuntu1~18.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk:amd64.\n",
            "Preparing to unpack .../14-openjdk-8-jdk_8u342-b07-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk:amd64 (8u342-b07-0ubuntu1~18.04) ...\n",
            "Setting up libgtk2.0-common (2.24.32-1ubuntu1) ...\n",
            "Setting up fonts-dejavu-core (2.37-1) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
            "Setting up fonts-dejavu-extra (2.37-1) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u342-b07-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up libgail18:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u342-b07-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "Setting up x11-utils (7.7+3build1) ...\n",
            "Setting up libgail-common:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up libatk-wrapper-java (0.33.3-20ubuntu0.1) ...\n",
            "Setting up libgtk2.0-bin (2.24.32-1ubuntu1) ...\n",
            "Setting up libatk-wrapper-java-jni:amd64 (0.33.3-20ubuntu0.1) ...\n",
            "Setting up openjdk-8-jre:amd64 (8u342-b07-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/policytool to provide /usr/bin/policytool (policytool) in auto mode\n",
            "Setting up openjdk-8-jdk:amd64 (8u342-b07-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/appletviewer to provide /usr/bin/appletviewer (appletviewer) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.6) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 28.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tweepy<4.0.0 in /usr/local/lib/python3.7/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy<4.0.0) (1.3.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy<4.0.0) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy<4.0.0) (2.23.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy<4.0.0) (3.2.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy<4.0.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy<4.0.0) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy<4.0.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy<4.0.0) (2022.9.24)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy<4.0.0) (1.7.1)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.9.1)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (453 kB)\n",
            "\u001b[K     |████████████████████████████████| 453 kB 93.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.0 konlpy-0.6.0\n",
            "Installing automake (A dependency for mecab-ko)\n",
            "Ign:1 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:4 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:9 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,551 kB]\n",
            "Get:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,329 kB]\n",
            "Get:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:16 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [2,164 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,188 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [3,020 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,230 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,452 kB]\n",
            "Get:21 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,109 kB]\n",
            "Get:22 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [44.0 kB]\n",
            "Get:23 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [50.8 kB]\n",
            "Fetched 16.5 MB in 6s (2,568 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  autoconf autotools-dev libsigsegv2 m4\n",
            "Suggested packages:\n",
            "  autoconf-archive gnu-standards autoconf-doc libtool gettext m4-doc\n",
            "The following NEW packages will be installed:\n",
            "  autoconf automake autotools-dev libsigsegv2 m4\n",
            "0 upgraded, 5 newly installed, 0 to remove and 40 not upgraded.\n",
            "Need to get 1,082 kB of archives.\n",
            "After this operation, 3,994 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsigsegv2 amd64 2.12-1 [14.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 m4 amd64 1.4.18-1 [197 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 autoconf all 2.69-11 [322 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 autotools-dev all 20180224.1 [39.6 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 automake all 1:1.15.1-3ubuntu2 [509 kB]\n",
            "Fetched 1,082 kB in 2s (554 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 5.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libsigsegv2:amd64.\n",
            "(Reading database ... 124513 files and directories currently installed.)\n",
            "Preparing to unpack .../libsigsegv2_2.12-1_amd64.deb ...\n",
            "Unpacking libsigsegv2:amd64 (2.12-1) ...\n",
            "Selecting previously unselected package m4.\n",
            "Preparing to unpack .../archives/m4_1.4.18-1_amd64.deb ...\n",
            "Unpacking m4 (1.4.18-1) ...\n",
            "Selecting previously unselected package autoconf.\n",
            "Preparing to unpack .../autoconf_2.69-11_all.deb ...\n",
            "Unpacking autoconf (2.69-11) ...\n",
            "Selecting previously unselected package autotools-dev.\n",
            "Preparing to unpack .../autotools-dev_20180224.1_all.deb ...\n",
            "Unpacking autotools-dev (20180224.1) ...\n",
            "Selecting previously unselected package automake.\n",
            "Preparing to unpack .../automake_1%3a1.15.1-3ubuntu2_all.deb ...\n",
            "Unpacking automake (1:1.15.1-3ubuntu2) ...\n",
            "Setting up libsigsegv2:amd64 (2.12-1) ...\n",
            "Setting up m4 (1.4.18-1) ...\n",
            "Setting up autotools-dev (20180224.1) ...\n",
            "Setting up autoconf (2.69-11) ...\n",
            "Setting up automake (1:1.15.1-3ubuntu2) ...\n",
            "update-alternatives: using /usr/bin/automake-1.15 to provide /usr/bin/automake (automake) in auto mode\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.6) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Install mecab-ko\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 1381k  100 1381k    0     0   415k      0  0:00:03  0:00:03 --:--:--  822k\n",
            "mecab-0.996-ko-0.9.2/\n",
            "mecab-0.996-ko-0.9.2/example/\n",
            "mecab-0.996-ko-0.9.2/example/example.cpp\n",
            "mecab-0.996-ko-0.9.2/example/example_lattice.cpp\n",
            "mecab-0.996-ko-0.9.2/example/example_lattice.c\n",
            "mecab-0.996-ko-0.9.2/example/example.c\n",
            "mecab-0.996-ko-0.9.2/example/thread_test.cpp\n",
            "mecab-0.996-ko-0.9.2/mecab-config.in\n",
            "mecab-0.996-ko-0.9.2/man/\n",
            "mecab-0.996-ko-0.9.2/man/Makefile.am\n",
            "mecab-0.996-ko-0.9.2/man/mecab.1\n",
            "mecab-0.996-ko-0.9.2/man/Makefile.in\n",
            "mecab-0.996-ko-0.9.2/mecab.iss.in\n",
            "mecab-0.996-ko-0.9.2/config.guess\n",
            "mecab-0.996-ko-0.9.2/README\n",
            "mecab-0.996-ko-0.9.2/COPYING\n",
            "mecab-0.996-ko-0.9.2/CHANGES.md\n",
            "mecab-0.996-ko-0.9.2/README.md\n",
            "mecab-0.996-ko-0.9.2/INSTALL\n",
            "mecab-0.996-ko-0.9.2/config.sub\n",
            "mecab-0.996-ko-0.9.2/configure.in\n",
            "mecab-0.996-ko-0.9.2/swig/\n",
            "mecab-0.996-ko-0.9.2/swig/Makefile\n",
            "mecab-0.996-ko-0.9.2/swig/version.h.in\n",
            "mecab-0.996-ko-0.9.2/swig/version.h\n",
            "mecab-0.996-ko-0.9.2/swig/MeCab.i\n",
            "mecab-0.996-ko-0.9.2/aclocal.m4\n",
            "mecab-0.996-ko-0.9.2/LGPL\n",
            "mecab-0.996-ko-0.9.2/Makefile.am\n",
            "mecab-0.996-ko-0.9.2/configure\n",
            "mecab-0.996-ko-0.9.2/tests/\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/test\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/t9/\n",
            "mecab-0.996-ko-0.9.2/tests/t9/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/t9/ipadic.pl\n",
            "mecab-0.996-ko-0.9.2/tests/t9/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/t9/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/t9/test\n",
            "mecab-0.996-ko-0.9.2/tests/t9/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/t9/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/t9/mkdic.pl\n",
            "mecab-0.996-ko-0.9.2/tests/t9/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/ipa.train\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/ipa.test\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/rewrite.def\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/feature.def\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/run-eval.sh\n",
            "mecab-0.996-ko-0.9.2/tests/run-cost-train.sh\n",
            "mecab-0.996-ko-0.9.2/tests/Makefile.am\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/test\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/eval/\n",
            "mecab-0.996-ko-0.9.2/tests/eval/answer\n",
            "mecab-0.996-ko-0.9.2/tests/eval/system\n",
            "mecab-0.996-ko-0.9.2/tests/eval/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/test\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/mkdic.pl\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/latin/\n",
            "mecab-0.996-ko-0.9.2/tests/latin/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/latin/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/latin/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/latin/test\n",
            "mecab-0.996-ko-0.9.2/tests/latin/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/latin/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/latin/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/test\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/run-dics.sh\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/test\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/Makefile.in\n",
            "mecab-0.996-ko-0.9.2/ltmain.sh\n",
            "mecab-0.996-ko-0.9.2/config.rpath\n",
            "mecab-0.996-ko-0.9.2/config.h.in\n",
            "mecab-0.996-ko-0.9.2/mecabrc.in\n",
            "mecab-0.996-ko-0.9.2/GPL\n",
            "mecab-0.996-ko-0.9.2/Makefile.train\n",
            "mecab-0.996-ko-0.9.2/ChangeLog\n",
            "mecab-0.996-ko-0.9.2/install-sh\n",
            "mecab-0.996-ko-0.9.2/AUTHORS\n",
            "mecab-0.996-ko-0.9.2/doc/\n",
            "mecab-0.996-ko-0.9.2/doc/bindings.html\n",
            "mecab-0.996-ko-0.9.2/doc/posid.html\n",
            "mecab-0.996-ko-0.9.2/doc/unk.html\n",
            "mecab-0.996-ko-0.9.2/doc/learn.html\n",
            "mecab-0.996-ko-0.9.2/doc/format.html\n",
            "mecab-0.996-ko-0.9.2/doc/libmecab.html\n",
            "mecab-0.996-ko-0.9.2/doc/mecab.css\n",
            "mecab-0.996-ko-0.9.2/doc/feature.html\n",
            "mecab-0.996-ko-0.9.2/doc/Makefile.am\n",
            "mecab-0.996-ko-0.9.2/doc/soft.html\n",
            "mecab-0.996-ko-0.9.2/doc/en/\n",
            "mecab-0.996-ko-0.9.2/doc/en/bindings.html\n",
            "mecab-0.996-ko-0.9.2/doc/dic-detail.html\n",
            "mecab-0.996-ko-0.9.2/doc/flow.png\n",
            "mecab-0.996-ko-0.9.2/doc/mecab.html\n",
            "mecab-0.996-ko-0.9.2/doc/index.html\n",
            "mecab-0.996-ko-0.9.2/doc/result.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_a.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/globals_eval.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Tagger-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/functions_vars.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/doxygen.css\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_r.gif\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Lattice.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/functions.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Tagger.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/mecab_8h_source.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tabs.css\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/nav_f.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_b.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/globals.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/nav_h.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_h.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Model.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/globals_func.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/closed.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_l.gif\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__path__t-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/functions_func.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/globals_type.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Lattice-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__node__t.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/namespacemembers_func.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_s.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__dictionary__info__t-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/namespacemembers_type.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Model-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__dictionary__info__t.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/namespaces.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/namespacemembers.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/namespaceMeCab.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__path__t.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/files.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__node__t-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/index.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/annotated.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/globals_defs.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classes.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/mecab_8h-source.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/doxygen.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_b.gif\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/bc_s.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/open.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/mecab_8h.html\n",
            "mecab-0.996-ko-0.9.2/doc/dic.html\n",
            "mecab-0.996-ko-0.9.2/doc/partial.html\n",
            "mecab-0.996-ko-0.9.2/doc/feature.png\n",
            "mecab-0.996-ko-0.9.2/doc/Makefile.in\n",
            "mecab-0.996-ko-0.9.2/missing\n",
            "mecab-0.996-ko-0.9.2/BSD\n",
            "mecab-0.996-ko-0.9.2/NEWS\n",
            "mecab-0.996-ko-0.9.2/mkinstalldirs\n",
            "mecab-0.996-ko-0.9.2/src/\n",
            "mecab-0.996-ko-0.9.2/src/dictionary.h\n",
            "mecab-0.996-ko-0.9.2/src/writer.h\n",
            "mecab-0.996-ko-0.9.2/src/utils.h\n",
            "mecab-0.996-ko-0.9.2/src/string_buffer.cpp\n",
            "mecab-0.996-ko-0.9.2/src/tokenizer.cpp\n",
            "mecab-0.996-ko-0.9.2/src/make.bat\n",
            "mecab-0.996-ko-0.9.2/src/mecab.h\n",
            "mecab-0.996-ko-0.9.2/src/freelist.h\n",
            "mecab-0.996-ko-0.9.2/src/string_buffer.h\n",
            "mecab-0.996-ko-0.9.2/src/learner_tagger.h\n",
            "mecab-0.996-ko-0.9.2/src/dictionary_compiler.cpp\n",
            "mecab-0.996-ko-0.9.2/src/eval.cpp\n",
            "mecab-0.996-ko-0.9.2/src/mecab-system-eval.cpp\n",
            "mecab-0.996-ko-0.9.2/src/darts.h\n",
            "mecab-0.996-ko-0.9.2/src/param.h\n",
            "mecab-0.996-ko-0.9.2/src/char_property.h\n",
            "mecab-0.996-ko-0.9.2/src/learner_node.h\n",
            "mecab-0.996-ko-0.9.2/src/mecab-dict-gen.cpp\n",
            "mecab-0.996-ko-0.9.2/src/mecab-dict-index.cpp\n",
            "mecab-0.996-ko-0.9.2/src/winmain.h\n",
            "mecab-0.996-ko-0.9.2/src/thread.h\n",
            "mecab-0.996-ko-0.9.2/src/context_id.cpp\n",
            "mecab-0.996-ko-0.9.2/src/Makefile.am\n",
            "mecab-0.996-ko-0.9.2/src/connector.h\n",
            "mecab-0.996-ko-0.9.2/src/common.h\n",
            "mecab-0.996-ko-0.9.2/src/dictionary_rewriter.cpp\n",
            "mecab-0.996-ko-0.9.2/src/Makefile.msvc.in\n",
            "mecab-0.996-ko-0.9.2/src/dictionary_rewriter.h\n",
            "mecab-0.996-ko-0.9.2/src/feature_index.h\n",
            "mecab-0.996-ko-0.9.2/src/iconv_utils.cpp\n",
            "mecab-0.996-ko-0.9.2/src/char_property.cpp\n",
            "mecab-0.996-ko-0.9.2/src/mecab-test-gen.cpp\n",
            "mecab-0.996-ko-0.9.2/src/tagger.cpp\n",
            "mecab-0.996-ko-0.9.2/src/mecab-cost-train.cpp\n",
            "mecab-0.996-ko-0.9.2/src/learner.cpp\n",
            "mecab-0.996-ko-0.9.2/src/dictionary.cpp\n",
            "mecab-0.996-ko-0.9.2/src/lbfgs.cpp\n",
            "mecab-0.996-ko-0.9.2/src/ucs.h\n",
            "mecab-0.996-ko-0.9.2/src/writer.cpp\n",
            "mecab-0.996-ko-0.9.2/src/learner_tagger.cpp\n",
            "mecab-0.996-ko-0.9.2/src/lbfgs.h\n",
            "mecab-0.996-ko-0.9.2/src/libmecab.cpp\n",
            "mecab-0.996-ko-0.9.2/src/tokenizer.h\n",
            "mecab-0.996-ko-0.9.2/src/mecab.cpp\n",
            "mecab-0.996-ko-0.9.2/src/utils.cpp\n",
            "mecab-0.996-ko-0.9.2/src/dictionary_generator.cpp\n",
            "mecab-0.996-ko-0.9.2/src/param.cpp\n",
            "mecab-0.996-ko-0.9.2/src/context_id.h\n",
            "mecab-0.996-ko-0.9.2/src/mmap.h\n",
            "mecab-0.996-ko-0.9.2/src/viterbi.h\n",
            "mecab-0.996-ko-0.9.2/src/viterbi.cpp\n",
            "mecab-0.996-ko-0.9.2/src/stream_wrapper.h\n",
            "mecab-0.996-ko-0.9.2/src/feature_index.cpp\n",
            "mecab-0.996-ko-0.9.2/src/nbest_generator.h\n",
            "mecab-0.996-ko-0.9.2/src/ucstable.h\n",
            "mecab-0.996-ko-0.9.2/src/nbest_generator.cpp\n",
            "mecab-0.996-ko-0.9.2/src/iconv_utils.h\n",
            "mecab-0.996-ko-0.9.2/src/connector.cpp\n",
            "mecab-0.996-ko-0.9.2/src/Makefile.in\n",
            "mecab-0.996-ko-0.9.2/src/scoped_ptr.h\n",
            "mecab-0.996-ko-0.9.2/Makefile.in\n",
            "checking for a BSD-compatible install... /usr/bin/install -c\n",
            "checking whether build environment is sane... yes\n",
            "checking for a thread-safe mkdir -p... /bin/mkdir -p\n",
            "checking for gawk... no\n",
            "checking for mawk... mawk\n",
            "checking whether make sets $(MAKE)... yes\n",
            "checking for gcc... gcc\n",
            "checking whether the C compiler works... yes\n",
            "checking for C compiler default output file name... a.out\n",
            "checking for suffix of executables... \n",
            "checking whether we are cross compiling... no\n",
            "checking for suffix of object files... o\n",
            "checking whether we are using the GNU C compiler... yes\n",
            "checking whether gcc accepts -g... yes\n",
            "checking for gcc option to accept ISO C89... none needed\n",
            "checking for style of include used by make... GNU\n",
            "checking dependency style of gcc... none\n",
            "checking for g++... g++\n",
            "checking whether we are using the GNU C++ compiler... yes\n",
            "checking whether g++ accepts -g... yes\n",
            "checking dependency style of g++... none\n",
            "checking how to run the C preprocessor... gcc -E\n",
            "checking for grep that handles long lines and -e... /bin/grep\n",
            "checking for egrep... /bin/grep -E\n",
            "checking whether gcc needs -traditional... no\n",
            "checking whether make sets $(MAKE)... (cached) yes\n",
            "checking build system type... x86_64-unknown-linux-gnu\n",
            "checking host system type... x86_64-unknown-linux-gnu\n",
            "checking how to print strings... printf\n",
            "checking for a sed that does not truncate output... /bin/sed\n",
            "checking for fgrep... /bin/grep -F\n",
            "checking for ld used by gcc... /usr/bin/ld\n",
            "checking if the linker (/usr/bin/ld) is GNU ld... yes\n",
            "checking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -B\n",
            "checking the name lister (/usr/bin/nm -B) interface... BSD nm\n",
            "checking whether ln -s works... yes\n",
            "checking the maximum length of command line arguments... 1572864\n",
            "checking whether the shell understands some XSI constructs... yes\n",
            "checking whether the shell understands \"+=\"... yes\n",
            "checking how to convert x86_64-unknown-linux-gnu file names to x86_64-unknown-linux-gnu format... func_convert_file_noop\n",
            "checking how to convert x86_64-unknown-linux-gnu file names to toolchain format... func_convert_file_noop\n",
            "checking for /usr/bin/ld option to reload object files... -r\n",
            "checking for objdump... objdump\n",
            "checking how to recognize dependent libraries... pass_all\n",
            "checking for dlltool... dlltool\n",
            "checking how to associate runtime and link libraries... printf %s\\n\n",
            "checking for ar... ar\n",
            "checking for archiver @FILE support... @\n",
            "checking for strip... strip\n",
            "checking for ranlib... ranlib\n",
            "checking command to parse /usr/bin/nm -B output from gcc object... ok\n",
            "checking for sysroot... no\n",
            "./configure: line 7378: /usr/bin/file: No such file or directory\n",
            "checking for mt... no\n",
            "checking if : is a manifest tool... no\n",
            "checking for ANSI C header files... yes\n",
            "checking for sys/types.h... yes\n",
            "checking for sys/stat.h... yes\n",
            "checking for stdlib.h... yes\n",
            "checking for string.h... yes\n",
            "checking for memory.h... yes\n",
            "checking for strings.h... yes\n",
            "checking for inttypes.h... yes\n",
            "checking for stdint.h... yes\n",
            "checking for unistd.h... yes\n",
            "checking for dlfcn.h... yes\n",
            "checking for objdir... .libs\n",
            "checking if gcc supports -fno-rtti -fno-exceptions... no\n",
            "checking for gcc option to produce PIC... -fPIC -DPIC\n",
            "checking if gcc PIC flag -fPIC -DPIC works... yes\n",
            "checking if gcc static flag -static works... yes\n",
            "checking if gcc supports -c -o file.o... yes\n",
            "checking if gcc supports -c -o file.o... (cached) yes\n",
            "checking whether the gcc linker (/usr/bin/ld) supports shared libraries... yes\n",
            "checking whether -lc should be explicitly linked in... no\n",
            "checking dynamic linker characteristics... GNU/Linux ld.so\n",
            "checking how to hardcode library paths into programs... immediate\n",
            "checking whether stripping libraries is possible... yes\n",
            "checking if libtool supports shared libraries... yes\n",
            "checking whether to build shared libraries... yes\n",
            "checking whether to build static libraries... yes\n",
            "checking how to run the C++ preprocessor... g++ -E\n",
            "checking for ld used by g++... /usr/bin/ld\n",
            "checking if the linker (/usr/bin/ld) is GNU ld... yes\n",
            "checking whether the g++ linker (/usr/bin/ld) supports shared libraries... yes\n",
            "checking for g++ option to produce PIC... -fPIC -DPIC\n",
            "checking if g++ PIC flag -fPIC -DPIC works... yes\n",
            "checking if g++ static flag -static works... yes\n",
            "checking if g++ supports -c -o file.o... yes\n",
            "checking if g++ supports -c -o file.o... (cached) yes\n",
            "checking whether the g++ linker (/usr/bin/ld) supports shared libraries... yes\n",
            "checking dynamic linker characteristics... (cached) GNU/Linux ld.so\n",
            "checking how to hardcode library paths into programs... immediate\n",
            "checking for library containing strerror... none required\n",
            "checking whether byte ordering is bigendian... no\n",
            "checking for ld used by GCC... /usr/bin/ld\n",
            "checking if the linker (/usr/bin/ld) is GNU ld... yes\n",
            "checking for shared library run path origin... done\n",
            "checking for iconv... yes\n",
            "checking for working iconv... yes\n",
            "checking for iconv declaration... \n",
            "         extern size_t iconv (iconv_t cd, char * *inbuf, size_t *inbytesleft, char * *outbuf, size_t *outbytesleft);\n",
            "checking for ANSI C header files... (cached) yes\n",
            "checking for an ANSI C-conforming const... yes\n",
            "checking whether byte ordering is bigendian... (cached) no\n",
            "checking for string.h... (cached) yes\n",
            "checking for stdlib.h... (cached) yes\n",
            "checking for unistd.h... (cached) yes\n",
            "checking fcntl.h usability... yes\n",
            "checking fcntl.h presence... yes\n",
            "checking for fcntl.h... yes\n",
            "checking for stdint.h... (cached) yes\n",
            "checking for sys/stat.h... (cached) yes\n",
            "checking sys/mman.h usability... yes\n",
            "checking sys/mman.h presence... yes\n",
            "checking for sys/mman.h... yes\n",
            "checking sys/times.h usability... yes\n",
            "checking sys/times.h presence... yes\n",
            "checking for sys/times.h... yes\n",
            "checking for sys/types.h... (cached) yes\n",
            "checking dirent.h usability... yes\n",
            "checking dirent.h presence... yes\n",
            "checking for dirent.h... yes\n",
            "checking ctype.h usability... yes\n",
            "checking ctype.h presence... yes\n",
            "checking for ctype.h... yes\n",
            "checking for sys/types.h... (cached) yes\n",
            "checking io.h usability... no\n",
            "checking io.h presence... no\n",
            "checking for io.h... no\n",
            "checking windows.h usability... no\n",
            "checking windows.h presence... no\n",
            "checking for windows.h... no\n",
            "checking pthread.h usability... yes\n",
            "checking pthread.h presence... yes\n",
            "checking for pthread.h... yes\n",
            "checking for off_t... yes\n",
            "checking for size_t... yes\n",
            "checking size of char... 1\n",
            "checking size of short... 2\n",
            "checking size of int... 4\n",
            "checking size of long... 8\n",
            "checking size of long long... 8\n",
            "checking size of size_t... 8\n",
            "checking for size_t... (cached) yes\n",
            "checking for unsigned long long int... yes\n",
            "checking for stdlib.h... (cached) yes\n",
            "checking for unistd.h... (cached) yes\n",
            "checking for sys/param.h... yes\n",
            "checking for getpagesize... yes\n",
            "checking for working mmap... yes\n",
            "checking for main in -lstdc++... yes\n",
            "checking for pthread_create in -lpthread... yes\n",
            "checking for pthread_join in -lpthread... yes\n",
            "checking for getenv... yes\n",
            "checking for opendir... yes\n",
            "checking whether make is GNU Make... yes\n",
            "checking if g++ supports stl <vector> (required)... yes\n",
            "checking if g++ supports stl <list> (required)... yes\n",
            "checking if g++ supports stl <map> (required)... yes\n",
            "checking if g++ supports stl <set> (required)... yes\n",
            "checking if g++ supports stl <queue> (required)... yes\n",
            "checking if g++ supports stl <functional> (required)... yes\n",
            "checking if g++ supports stl <algorithm> (required)... yes\n",
            "checking if g++ supports stl <string> (required)... yes\n",
            "checking if g++ supports stl <iostream> (required)... yes\n",
            "checking if g++ supports stl <sstream> (required)... yes\n",
            "checking if g++ supports stl <fstream> (required)... yes\n",
            "checking if g++ supports template <class T> (required)... yes\n",
            "checking if g++ supports const_cast<> (required)... yes\n",
            "checking if g++ supports static_cast<> (required)... yes\n",
            "checking if g++ supports reinterpret_cast<> (required)... yes\n",
            "checking if g++ supports namespaces (required) ... yes\n",
            "checking if g++ supports __thread (optional)... yes\n",
            "checking if g++ supports template <class T> (required)... yes\n",
            "checking if g++ supports GCC native atomic operations (optional)... yes\n",
            "checking if g++ supports OSX native atomic operations (optional)... no\n",
            "checking if g++ environment provides all required features... yes\n",
            "configure: creating ./config.status\n",
            "config.status: creating Makefile\n",
            "config.status: creating src/Makefile\n",
            "config.status: creating src/Makefile.msvc\n",
            "config.status: creating man/Makefile\n",
            "config.status: creating doc/Makefile\n",
            "config.status: creating tests/Makefile\n",
            "config.status: creating swig/version.h\n",
            "config.status: creating mecab.iss\n",
            "config.status: creating mecab-config\n",
            "config.status: creating mecabrc\n",
            "config.status: creating config.h\n",
            "config.status: executing depfiles commands\n",
            "config.status: executing libtool commands\n",
            "config.status: executing default commands\n",
            "make  all-recursive\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "Making all in src\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o viterbi.lo viterbi.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c viterbi.cpp  -fPIC -DPIC -o .libs/viterbi.o\n",
            "In file included from \u001b[01m\u001b[Kviterbi.cpp:14:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kparam.h:30:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K'\u001b[01m\u001b[KTarget {anonymous}::lexical_cast(Source) [with Target = std::__cxx11::basic_string<char>; Source = std::__cxx11::basic_string<char>]\u001b[m\u001b[K' defined but not used [\u001b[01;35m\u001b[K-Wunused-function\u001b[m\u001b[K]\n",
            " std::string \u001b[01;35m\u001b[Klexical_cast<std::string, std::string>\u001b[m\u001b[K(std::string arg) {\n",
            "             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c viterbi.cpp -o viterbi.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o tagger.lo tagger.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c tagger.cpp  -fPIC -DPIC -o .libs/tagger.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c tagger.cpp -o tagger.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o utils.lo utils.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c utils.cpp  -fPIC -DPIC -o .libs/utils.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c utils.cpp -o utils.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o eval.lo eval.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c eval.cpp  -fPIC -DPIC -o .libs/eval.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c eval.cpp -o eval.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o iconv_utils.lo iconv_utils.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c iconv_utils.cpp  -fPIC -DPIC -o .libs/iconv_utils.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c iconv_utils.cpp -o iconv_utils.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o dictionary_rewriter.lo dictionary_rewriter.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_rewriter.cpp  -fPIC -DPIC -o .libs/dictionary_rewriter.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_rewriter.cpp -o dictionary_rewriter.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o dictionary_generator.lo dictionary_generator.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_generator.cpp  -fPIC -DPIC -o .libs/dictionary_generator.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_generator.cpp -o dictionary_generator.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o dictionary_compiler.lo dictionary_compiler.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_compiler.cpp  -fPIC -DPIC -o .libs/dictionary_compiler.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_compiler.cpp -o dictionary_compiler.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o context_id.lo context_id.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c context_id.cpp  -fPIC -DPIC -o .libs/context_id.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c context_id.cpp -o context_id.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o connector.lo connector.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c connector.cpp  -fPIC -DPIC -o .libs/connector.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c connector.cpp -o connector.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o nbest_generator.lo nbest_generator.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c nbest_generator.cpp  -fPIC -DPIC -o .libs/nbest_generator.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c nbest_generator.cpp -o nbest_generator.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o writer.lo writer.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c writer.cpp  -fPIC -DPIC -o .libs/writer.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c writer.cpp -o writer.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o string_buffer.lo string_buffer.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c string_buffer.cpp  -fPIC -DPIC -o .libs/string_buffer.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c string_buffer.cpp -o string_buffer.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o param.lo param.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c param.cpp  -fPIC -DPIC -o .libs/param.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c param.cpp -o param.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o tokenizer.lo tokenizer.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c tokenizer.cpp  -fPIC -DPIC -o .libs/tokenizer.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c tokenizer.cpp -o tokenizer.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o char_property.lo char_property.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c char_property.cpp  -fPIC -DPIC -o .libs/char_property.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c char_property.cpp -o char_property.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o dictionary.lo dictionary.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary.cpp  -fPIC -DPIC -o .libs/dictionary.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary.cpp -o dictionary.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o feature_index.lo feature_index.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c feature_index.cpp  -fPIC -DPIC -o .libs/feature_index.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c feature_index.cpp -o feature_index.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o lbfgs.lo lbfgs.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c lbfgs.cpp  -fPIC -DPIC -o .libs/lbfgs.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c lbfgs.cpp -o lbfgs.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o learner_tagger.lo learner_tagger.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c learner_tagger.cpp  -fPIC -DPIC -o .libs/learner_tagger.o\n",
            "\u001b[01m\u001b[Klearner_tagger.cpp:25:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K'\u001b[01m\u001b[Kchar* MeCab::{anonymous}::mystrdup(const string&)\u001b[m\u001b[K' defined but not used [\u001b[01;35m\u001b[K-Wunused-function\u001b[m\u001b[K]\n",
            " char *\u001b[01;35m\u001b[Kmystrdup\u001b[m\u001b[K(const std::string &str) {\n",
            "       \u001b[01;35m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c learner_tagger.cpp -o learner_tagger.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o learner.lo learner.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c learner.cpp  -fPIC -DPIC -o .libs/learner.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c learner.cpp -o learner.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o libmecab.lo libmecab.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c libmecab.cpp  -fPIC -DPIC -o .libs/libmecab.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c libmecab.cpp -o libmecab.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall  -no-undefined -version-info 2:0:0  -o libmecab.la -rpath /usr/local/lib viterbi.lo tagger.lo utils.lo eval.lo iconv_utils.lo dictionary_rewriter.lo dictionary_generator.lo dictionary_compiler.lo context_id.lo connector.lo nbest_generator.lo writer.lo string_buffer.lo param.lo tokenizer.lo char_property.lo dictionary.lo feature_index.lo lbfgs.lo learner_tagger.lo learner.lo libmecab.lo  -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++  -fPIC -DPIC -shared -nostdlib /usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu/crti.o /usr/lib/gcc/x86_64-linux-gnu/7/crtbeginS.o  .libs/viterbi.o .libs/tagger.o .libs/utils.o .libs/eval.o .libs/iconv_utils.o .libs/dictionary_rewriter.o .libs/dictionary_generator.o .libs/dictionary_compiler.o .libs/context_id.o .libs/connector.o .libs/nbest_generator.o .libs/writer.o .libs/string_buffer.o .libs/param.o .libs/tokenizer.o .libs/char_property.o .libs/dictionary.o .libs/feature_index.o .libs/lbfgs.o .libs/learner_tagger.o .libs/learner.o .libs/libmecab.o   -lpthread -L/usr/lib/gcc/x86_64-linux-gnu/7 -L/usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu -L/usr/lib/gcc/x86_64-linux-gnu/7/../../../../lib -L/lib/x86_64-linux-gnu -L/lib/../lib -L/usr/lib/x86_64-linux-gnu -L/usr/lib/../lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/gcc/x86_64-linux-gnu/7/../../.. -lstdc++ -lm -lc -lgcc_s /usr/lib/gcc/x86_64-linux-gnu/7/crtendS.o /usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu/crtn.o  -O3   -Wl,-soname -Wl,libmecab.so.2 -o .libs/libmecab.so.2.0.0\n",
            "libtool: link: (cd \".libs\" && rm -f \"libmecab.so.2\" && ln -s \"libmecab.so.2.0.0\" \"libmecab.so.2\")\n",
            "libtool: link: (cd \".libs\" && rm -f \"libmecab.so\" && ln -s \"libmecab.so.2.0.0\" \"libmecab.so\")\n",
            "libtool: link: ar cru .libs/libmecab.a  viterbi.o tagger.o utils.o eval.o iconv_utils.o dictionary_rewriter.o dictionary_generator.o dictionary_compiler.o context_id.o connector.o nbest_generator.o writer.o string_buffer.o param.o tokenizer.o char_property.o dictionary.o feature_index.o lbfgs.o learner_tagger.o learner.o libmecab.o\n",
            "ar: `u' modifier ignored since `D' is the default (see `U')\n",
            "libtool: link: ranlib .libs/libmecab.a\n",
            "libtool: link: ( cd \".libs\" && rm -f \"libmecab.la\" && ln -s \"../libmecab.la\" \"libmecab.la\" )\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab.o mecab.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab mecab.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab mecab.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-dict-index.o mecab-dict-index.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-dict-index mecab-dict-index.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab-dict-index mecab-dict-index.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-dict-gen.o mecab-dict-gen.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-dict-gen mecab-dict-gen.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab-dict-gen mecab-dict-gen.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-cost-train.o mecab-cost-train.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-cost-train mecab-cost-train.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab-cost-train mecab-cost-train.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-system-eval.o mecab-system-eval.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-system-eval mecab-system-eval.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab-system-eval mecab-system-eval.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-test-gen.o mecab-test-gen.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-test-gen mecab-test-gen.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab-test-gen mecab-test-gen.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "Making all in man\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "make[2]: Nothing to be done for 'all'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "Making all in doc\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "make[2]: Nothing to be done for 'all'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "Making all in tests\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[2]: Nothing to be done for 'all'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "Making check in src\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "make[1]: Nothing to be done for 'check'.\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "Making check in man\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "make[1]: Nothing to be done for 'check'.\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "Making check in doc\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "make[1]: Nothing to be done for 'check'.\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "Making check in tests\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make  check-TESTS\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 177\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 178x178\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 83\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 84x84\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 450\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 162\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 3x3\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 4\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 11\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 1\n",
            "reading ./matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 1\n",
            "reading ./matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "PASS: run-dics.sh\n",
            "PASS: run-eval.sh\n",
            "seed/pos-id.def is not found. minimum setting is used\n",
            "reading seed/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "seed/model.def is not found. skipped.\n",
            "seed/pos-id.def is not found. minimum setting is used\n",
            "reading seed/dic.csv ... 4335\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading seed/matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "reading corpus ...\n",
            "Number of sentences: 34\n",
            "Number of features:  64108\n",
            "eta:                 0.00005\n",
            "freq:                1\n",
            "eval-size:           6\n",
            "unk-eval-size:       4\n",
            "threads:             1\n",
            "charset:             EUC-JP\n",
            "C(sigma^2):          1.00000\n",
            "\n",
            "iter=0 err=1.00000 F=0.35771 target=2406.28355 diff=1.00000\n",
            "iter=1 err=0.97059 F=0.65652 target=1484.25231 diff=0.38318\n",
            "iter=2 err=0.91176 F=0.79331 target=863.32765 diff=0.41834\n",
            "iter=3 err=0.85294 F=0.89213 target=596.72480 diff=0.30881\n",
            "iter=4 err=0.61765 F=0.95467 target=336.30744 diff=0.43641\n",
            "iter=5 err=0.50000 F=0.96702 target=246.53039 diff=0.26695\n",
            "iter=6 err=0.35294 F=0.95472 target=188.93963 diff=0.23361\n",
            "iter=7 err=0.20588 F=0.99106 target=168.62665 diff=0.10751\n",
            "iter=8 err=0.05882 F=0.99777 target=158.64865 diff=0.05917\n",
            "iter=9 err=0.08824 F=0.99665 target=154.14530 diff=0.02839\n",
            "iter=10 err=0.08824 F=0.99665 target=151.94257 diff=0.01429\n",
            "iter=11 err=0.02941 F=0.99888 target=147.20825 diff=0.03116\n",
            "iter=12 err=0.00000 F=1.00000 target=147.34956 diff=0.00096\n",
            "iter=13 err=0.02941 F=0.99888 target=146.32592 diff=0.00695\n",
            "iter=14 err=0.00000 F=1.00000 target=145.77299 diff=0.00378\n",
            "iter=15 err=0.02941 F=0.99888 target=145.24641 diff=0.00361\n",
            "iter=16 err=0.00000 F=1.00000 target=144.96490 diff=0.00194\n",
            "iter=17 err=0.02941 F=0.99888 target=144.90246 diff=0.00043\n",
            "iter=18 err=0.00000 F=1.00000 target=144.75959 diff=0.00099\n",
            "iter=19 err=0.00000 F=1.00000 target=144.71727 diff=0.00029\n",
            "iter=20 err=0.00000 F=1.00000 target=144.66337 diff=0.00037\n",
            "iter=21 err=0.00000 F=1.00000 target=144.61349 diff=0.00034\n",
            "iter=22 err=0.00000 F=1.00000 target=144.62987 diff=0.00011\n",
            "iter=23 err=0.00000 F=1.00000 target=144.60060 diff=0.00020\n",
            "iter=24 err=0.00000 F=1.00000 target=144.59125 diff=0.00006\n",
            "iter=25 err=0.00000 F=1.00000 target=144.58619 diff=0.00004\n",
            "iter=26 err=0.00000 F=1.00000 target=144.58219 diff=0.00003\n",
            "iter=27 err=0.00000 F=1.00000 target=144.58059 diff=0.00001\n",
            "\n",
            "Done! writing model file ... \n",
            "model-ipadic.c1.0.f1.model is not a binary model. reopen it as text mode...\n",
            "reading seed/unk.def ... 40\n",
            "reading seed/dic.csv ... 4335\n",
            "emitting model-ipadic.c1.0.f1.dic/left-id.def/ model-ipadic.c1.0.f1.dic/right-id.def\n",
            "emitting model-ipadic.c1.0.f1.dic/unk.def ... 40\n",
            "emitting model-ipadic.c1.0.f1.dic/dic.csv ... 4335\n",
            "emitting matrix      : 100% |###########################################| \n",
            "copying seed/char.def to model-ipadic.c1.0.f1.dic/char.def\n",
            "copying seed/rewrite.def to model-ipadic.c1.0.f1.dic/rewrite.def\n",
            "copying seed/dicrc to model-ipadic.c1.0.f1.dic/dicrc\n",
            "copying seed/feature.def to model-ipadic.c1.0.f1.dic/feature.def\n",
            "copying model-ipadic.c1.0.f1.model to model-ipadic.c1.0.f1.dic/model.def\n",
            "\n",
            "done!\n",
            "model-ipadic.c1.0.f1.dic/pos-id.def is not found. minimum setting is used\n",
            "reading model-ipadic.c1.0.f1.dic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "model-ipadic.c1.0.f1.dic/pos-id.def is not found. minimum setting is used\n",
            "reading model-ipadic.c1.0.f1.dic/dic.csv ... 4335\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading model-ipadic.c1.0.f1.dic/matrix.def ... 346x346\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "              precision          recall         F\n",
            "LEVEL 0:    12.8959(57/442) 11.8998(57/479) 12.3779\n",
            "LEVEL 1:    12.2172(54/442) 11.2735(54/479) 11.7264\n",
            "LEVEL 2:    11.7647(52/442) 10.8559(52/479) 11.2921\n",
            "LEVEL 4:    11.7647(52/442) 10.8559(52/479) 11.2921\n",
            "PASS: run-cost-train.sh\n",
            "==================\n",
            "All 3 tests passed\n",
            "==================\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "Making install in src\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "test -z \"/usr/local/lib\" || /bin/mkdir -p \"/usr/local/lib\"\n",
            " /bin/bash ../libtool   --mode=install /usr/bin/install -c   libmecab.la '/usr/local/lib'\n",
            "libtool: install: /usr/bin/install -c .libs/libmecab.so.2.0.0 /usr/local/lib/libmecab.so.2.0.0\n",
            "libtool: install: (cd /usr/local/lib && { ln -s -f libmecab.so.2.0.0 libmecab.so.2 || { rm -f libmecab.so.2 && ln -s libmecab.so.2.0.0 libmecab.so.2; }; })\n",
            "libtool: install: (cd /usr/local/lib && { ln -s -f libmecab.so.2.0.0 libmecab.so || { rm -f libmecab.so && ln -s libmecab.so.2.0.0 libmecab.so; }; })\n",
            "libtool: install: /usr/bin/install -c .libs/libmecab.lai /usr/local/lib/libmecab.la\n",
            "libtool: install: /usr/bin/install -c .libs/libmecab.a /usr/local/lib/libmecab.a\n",
            "libtool: install: chmod 644 /usr/local/lib/libmecab.a\n",
            "libtool: install: ranlib /usr/local/lib/libmecab.a\n",
            "libtool: finish: PATH=\"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin:/sbin\" ldconfig -n /usr/local/lib\n",
            "----------------------------------------------------------------------\n",
            "Libraries have been installed in:\n",
            "   /usr/local/lib\n",
            "\n",
            "If you ever happen to want to link against installed libraries\n",
            "in a given directory, LIBDIR, you must either use libtool, and\n",
            "specify the full pathname of the library, or use the `-LLIBDIR'\n",
            "flag during linking and do at least one of the following:\n",
            "   - add LIBDIR to the `LD_LIBRARY_PATH' environment variable\n",
            "     during execution\n",
            "   - add LIBDIR to the `LD_RUN_PATH' environment variable\n",
            "     during linking\n",
            "   - use the `-Wl,-rpath -Wl,LIBDIR' linker flag\n",
            "   - have your system administrator add LIBDIR to `/etc/ld.so.conf'\n",
            "\n",
            "See any operating system documentation about shared libraries for\n",
            "more information, such as the ld(1) and ld.so(8) manual pages.\n",
            "----------------------------------------------------------------------\n",
            "test -z \"/usr/local/bin\" || /bin/mkdir -p \"/usr/local/bin\"\n",
            "  /bin/bash ../libtool   --mode=install /usr/bin/install -c mecab '/usr/local/bin'\n",
            "libtool: install: /usr/bin/install -c .libs/mecab /usr/local/bin/mecab\n",
            "test -z \"/usr/local/libexec/mecab\" || /bin/mkdir -p \"/usr/local/libexec/mecab\"\n",
            "  /bin/bash ../libtool   --mode=install /usr/bin/install -c mecab-dict-index mecab-dict-gen mecab-cost-train mecab-system-eval mecab-test-gen '/usr/local/libexec/mecab'\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-dict-index /usr/local/libexec/mecab/mecab-dict-index\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-dict-gen /usr/local/libexec/mecab/mecab-dict-gen\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-cost-train /usr/local/libexec/mecab/mecab-cost-train\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-system-eval /usr/local/libexec/mecab/mecab-system-eval\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-test-gen /usr/local/libexec/mecab/mecab-test-gen\n",
            "test -z \"/usr/local/include\" || /bin/mkdir -p \"/usr/local/include\"\n",
            " /usr/bin/install -c -m 644 mecab.h '/usr/local/include'\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "Making install in man\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "make[2]: Nothing to be done for 'install-exec-am'.\n",
            "test -z \"/usr/local/share/man/man1\" || /bin/mkdir -p \"/usr/local/share/man/man1\"\n",
            " /usr/bin/install -c -m 644 mecab.1 '/usr/local/share/man/man1'\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "Making install in doc\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "make[2]: Nothing to be done for 'install-exec-am'.\n",
            "make[2]: Nothing to be done for 'install-data-am'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "Making install in tests\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[2]: Nothing to be done for 'install-exec-am'.\n",
            "make[2]: Nothing to be done for 'install-data-am'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "test -z \"/usr/local/bin\" || /bin/mkdir -p \"/usr/local/bin\"\n",
            " /usr/bin/install -c mecab-config '/usr/local/bin'\n",
            "test -z \"/usr/local/etc\" || /bin/mkdir -p \"/usr/local/etc\"\n",
            " /usr/bin/install -c -m 644 mecabrc '/usr/local/etc'\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "Install mecab-ko-dic\n",
            "Install mecab-ko-dic\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 47.4M  100 47.4M    0     0  6746k      0  0:00:07  0:00:07 --:--:-- 11.1M\n",
            "mecab-ko-dic-2.1.1-20180720/\n",
            "mecab-ko-dic-2.1.1-20180720/configure\n",
            "mecab-ko-dic-2.1.1-20180720/COPYING\n",
            "mecab-ko-dic-2.1.1-20180720/autogen.sh\n",
            "mecab-ko-dic-2.1.1-20180720/Place-station.csv\n",
            "mecab-ko-dic-2.1.1-20180720/NNG.csv\n",
            "mecab-ko-dic-2.1.1-20180720/README\n",
            "mecab-ko-dic-2.1.1-20180720/EF.csv\n",
            "mecab-ko-dic-2.1.1-20180720/MAG.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Preanalysis.csv\n",
            "mecab-ko-dic-2.1.1-20180720/NNB.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Person-actor.csv\n",
            "mecab-ko-dic-2.1.1-20180720/VV.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Makefile.in\n",
            "mecab-ko-dic-2.1.1-20180720/matrix.def\n",
            "mecab-ko-dic-2.1.1-20180720/EC.csv\n",
            "mecab-ko-dic-2.1.1-20180720/NNBC.csv\n",
            "mecab-ko-dic-2.1.1-20180720/clean\n",
            "mecab-ko-dic-2.1.1-20180720/ChangeLog\n",
            "mecab-ko-dic-2.1.1-20180720/J.csv\n",
            "mecab-ko-dic-2.1.1-20180720/.keep\n",
            "mecab-ko-dic-2.1.1-20180720/feature.def\n",
            "mecab-ko-dic-2.1.1-20180720/Foreign.csv\n",
            "mecab-ko-dic-2.1.1-20180720/XPN.csv\n",
            "mecab-ko-dic-2.1.1-20180720/EP.csv\n",
            "mecab-ko-dic-2.1.1-20180720/NR.csv\n",
            "mecab-ko-dic-2.1.1-20180720/left-id.def\n",
            "mecab-ko-dic-2.1.1-20180720/Place.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Symbol.csv\n",
            "mecab-ko-dic-2.1.1-20180720/dicrc\n",
            "mecab-ko-dic-2.1.1-20180720/NP.csv\n",
            "mecab-ko-dic-2.1.1-20180720/ETM.csv\n",
            "mecab-ko-dic-2.1.1-20180720/IC.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Place-address.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Group.csv\n",
            "mecab-ko-dic-2.1.1-20180720/model.def\n",
            "mecab-ko-dic-2.1.1-20180720/XSN.csv\n",
            "mecab-ko-dic-2.1.1-20180720/INSTALL\n",
            "mecab-ko-dic-2.1.1-20180720/rewrite.def\n",
            "mecab-ko-dic-2.1.1-20180720/Inflect.csv\n",
            "mecab-ko-dic-2.1.1-20180720/configure.ac\n",
            "mecab-ko-dic-2.1.1-20180720/NNP.csv\n",
            "mecab-ko-dic-2.1.1-20180720/CoinedWord.csv\n",
            "mecab-ko-dic-2.1.1-20180720/XSV.csv\n",
            "mecab-ko-dic-2.1.1-20180720/pos-id.def\n",
            "mecab-ko-dic-2.1.1-20180720/Makefile.am\n",
            "mecab-ko-dic-2.1.1-20180720/unk.def\n",
            "mecab-ko-dic-2.1.1-20180720/missing\n",
            "mecab-ko-dic-2.1.1-20180720/VCP.csv\n",
            "mecab-ko-dic-2.1.1-20180720/install-sh\n",
            "mecab-ko-dic-2.1.1-20180720/Hanja.csv\n",
            "mecab-ko-dic-2.1.1-20180720/MAJ.csv\n",
            "mecab-ko-dic-2.1.1-20180720/XSA.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Wikipedia.csv\n",
            "mecab-ko-dic-2.1.1-20180720/tools/\n",
            "mecab-ko-dic-2.1.1-20180720/tools/add-userdic.sh\n",
            "mecab-ko-dic-2.1.1-20180720/tools/mecab-bestn.sh\n",
            "mecab-ko-dic-2.1.1-20180720/tools/convert_for_using_store.sh\n",
            "mecab-ko-dic-2.1.1-20180720/user-dic/\n",
            "mecab-ko-dic-2.1.1-20180720/user-dic/nnp.csv\n",
            "mecab-ko-dic-2.1.1-20180720/user-dic/place.csv\n",
            "mecab-ko-dic-2.1.1-20180720/user-dic/person.csv\n",
            "mecab-ko-dic-2.1.1-20180720/user-dic/README.md\n",
            "mecab-ko-dic-2.1.1-20180720/NorthKorea.csv\n",
            "mecab-ko-dic-2.1.1-20180720/VX.csv\n",
            "mecab-ko-dic-2.1.1-20180720/right-id.def\n",
            "mecab-ko-dic-2.1.1-20180720/VA.csv\n",
            "mecab-ko-dic-2.1.1-20180720/char.def\n",
            "mecab-ko-dic-2.1.1-20180720/NEWS\n",
            "mecab-ko-dic-2.1.1-20180720/MM.csv\n",
            "mecab-ko-dic-2.1.1-20180720/ETN.csv\n",
            "mecab-ko-dic-2.1.1-20180720/AUTHORS\n",
            "mecab-ko-dic-2.1.1-20180720/Person.csv\n",
            "mecab-ko-dic-2.1.1-20180720/XR.csv\n",
            "mecab-ko-dic-2.1.1-20180720/VCN.csv\n",
            "Looking in current directory for macros.\n",
            "configure.ac:2: warning: AM_INIT_AUTOMAKE: two- and three-arguments forms are deprecated.  For more info, see:\n",
            "configure.ac:2: http://www.gnu.org/software/automake/manual/automake.html#Modernize-AM_005fINIT_005fAUTOMAKE-invocation\n",
            "checking for a BSD-compatible install... /usr/bin/install -c\n",
            "checking whether build environment is sane... yes\n",
            "/tmp/mecab-ko-dic-2.1.1-20180720/missing: Unknown `--is-lightweight' option\n",
            "Try `/tmp/mecab-ko-dic-2.1.1-20180720/missing --help' for more information\n",
            "configure: WARNING: 'missing' script is too old or missing\n",
            "checking for a thread-safe mkdir -p... /bin/mkdir -p\n",
            "checking for gawk... no\n",
            "checking for mawk... mawk\n",
            "checking whether make sets $(MAKE)... yes\n",
            "checking whether make supports nested variables... yes\n",
            "checking for mecab-config... /usr/local/bin/mecab-config\n",
            "checking that generated files are newer than configure... done\n",
            "configure: creating ./config.status\n",
            "config.status: creating Makefile\n",
            "/usr/local/lib\n",
            "/usr/local/libexec/mecab/mecab-dict-index -d . -o . -f UTF-8 -t UTF-8\n",
            "reading ./unk.def ... 13\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./Inflect.csv ... 44820\n",
            "reading ./NNBC.csv ... 677\n",
            "reading ./EC.csv ... 2547\n",
            "reading ./Place.csv ... 30303\n",
            "reading ./ETM.csv ... 133\n",
            "reading ./XSN.csv ... 124\n",
            "reading ./Person-actor.csv ... 99230\n",
            "reading ./MAG.csv ... 14242\n",
            "reading ./Foreign.csv ... 11690\n",
            "reading ./MAJ.csv ... 240\n",
            "reading ./Hanja.csv ... 125750\n",
            "reading ./NR.csv ... 482\n",
            "reading ./MM.csv ... 453\n",
            "reading ./Group.csv ... 3176\n",
            "reading ./Preanalysis.csv ... 5\n",
            "reading ./Place-address.csv ... 19301\n",
            "reading ./Place-station.csv ... 1145\n",
            "reading ./NP.csv ... 342\n",
            "reading ./EF.csv ... 1820\n",
            "reading ./VV.csv ... 7331\n",
            "reading ./VX.csv ... 125\n",
            "reading ./Wikipedia.csv ... 36762\n",
            "reading ./EP.csv ... 51\n",
            "reading ./NNP.csv ... 2371\n",
            "reading ./XR.csv ... 3637\n",
            "reading ./J.csv ... 416\n",
            "reading ./CoinedWord.csv ... 148\n",
            "reading ./VCP.csv ... 9\n",
            "reading ./NorthKorea.csv ... 3\n",
            "reading ./IC.csv ... 1305\n",
            "reading ./XPN.csv ... 83\n",
            "reading ./VA.csv ... 2360\n",
            "reading ./NNG.csv ... 208524\n",
            "reading ./Person.csv ... 196459\n",
            "reading ./VCN.csv ... 7\n",
            "reading ./XSA.csv ... 19\n",
            "reading ./ETN.csv ... 14\n",
            "reading ./XSV.csv ... 23\n",
            "reading ./NNB.csv ... 140\n",
            "reading ./Symbol.csv ... 16\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 3822x2693\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "echo To enable dictionary, rewrite /usr/local/etc/mecabrc as \\\"dicdir = /usr/local/lib/mecab/dic/mecab-ko-dic\\\"\n",
            "To enable dictionary, rewrite /usr/local/etc/mecabrc as \"dicdir = /usr/local/lib/mecab/dic/mecab-ko-dic\"\n",
            "make[1]: Entering directory '/tmp/mecab-ko-dic-2.1.1-20180720'\n",
            "make[1]: Nothing to be done for 'install-exec-am'.\n",
            " /bin/mkdir -p '/usr/local/lib/mecab/dic/mecab-ko-dic'\n",
            " /usr/bin/install -c -m 644 model.bin matrix.bin char.bin sys.dic unk.dic left-id.def right-id.def rewrite.def pos-id.def dicrc '/usr/local/lib/mecab/dic/mecab-ko-dic'\n",
            "make[1]: Leaving directory '/tmp/mecab-ko-dic-2.1.1-20180720'\n",
            "Install mecab-python\n",
            "/tmp /tmp/mecab-ko-dic-2.1.1-20180720\n",
            "Cloning into 'mecab-python-0.996'...\n",
            "Unpacking objects: 100% (17/17), done.\n",
            "/tmp/mecab-ko-dic-2.1.1-20180720\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /tmp/mecab-python-0.996\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Building wheels for collected packages: mecab-python\n",
            "  Building wheel for mecab-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mecab-python: filename=mecab_python-0.996_ko_0.9.2-cp37-cp37m-linux_x86_64.whl size=141808 sha256=ffea691d1f90913e519b269e87fba017c567ec09a5f7ef1b6d28e15156b29794\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/7b/9f/2922869bef86c3354ae7034f7a3647c573ee1997c2dad0290a\n",
            "\u001b[33m  WARNING: Built wheel for mecab-python is invalid: Metadata 1.2 mandates PEP 440 version, but '0.996-ko-0.9.2' is not\u001b[0m\n",
            "Failed to build mecab-python\n",
            "Installing collected packages: mecab-python\n",
            "    Running setup.py install for mecab-python ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  DEPRECATION: mecab-python was installed using the legacy 'setup.py install' method, because a wheel could not be built for it. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368.\u001b[0m\n",
            "Successfully installed mecab-python-0.996-ko-0.9.2\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "! pip install datasets #설치 \n",
        "! pip install transformers\n",
        "! apt-get install -y openjdk-8-jdk python3-dev\n",
        "! pip install konlpy \"tweepy<4.0.0\"\n",
        "! /bin/bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparing\n",
        "1. data load\n",
        "\n",
        "2. data preprocessing\n",
        "\n",
        "    -형태소 분석\n",
        "\n",
        "    -tokenizing\n",
        "# Data Load\n",
        "데이터를 로드하고, parsing 해서 필요한 데이터만 뽑아주는 모듈 KoMRC"
      ],
      "metadata": {
        "id": "rQQ9DfmdCW08"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Tuple, Dict, Any\n",
        "import json\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "class KoMRC:\n",
        "    def __init__(self, data, indices: List[Tuple[int, int, int]], mode=None): #, tokenizer=None):\n",
        "        self._data = data\n",
        "        self._indices = indices \n",
        "        self._preprocessed_data = None\n",
        "\n",
        "    # Json을 불러오는 메소드\n",
        "    @classmethod\n",
        "    def load(cls, file_path):\n",
        "        with open(file_path, 'r', encoding='utf-8') as fd:\n",
        "            data = json.load(fd)\n",
        "\n",
        "        indices = []\n",
        "        for d_id, document in enumerate(data['data']):\n",
        "            for p_id, paragraph in enumerate(document['paragraphs']):\n",
        "                for q_id, _ in enumerate(paragraph['qas']):\n",
        "                    indices.append((d_id, p_id, q_id))\n",
        "        \n",
        "        return cls(data, indices)\n",
        "\n",
        "    # 데이터 셋을 잘라내는 메소드\n",
        "    @classmethod\n",
        "    def split(cls, dataset, eval_ratio: float=.1, seed=42, mode='mecab'): #, tokenizer=None):\n",
        "        indices = list(dataset._indices)\n",
        "        random.seed(seed)\n",
        "        random.shuffle(indices)\n",
        "        train_indices = indices[int(len(indices) * eval_ratio):]\n",
        "        eval_indices = indices[:int(len(indices) * eval_ratio)]\n",
        "\n",
        "        return cls(dataset._data, train_indices, mode=mode), cls(dataset._data, eval_indices, mode=mode)#, tokenizer=tokenizer)\n",
        "\n",
        "#-----------------------------------------------------------------------------------\n",
        "\n",
        "    def __getitem__(self, slices):   # index 대신 slice?\n",
        "        if not self._preprocessed_data :\n",
        "          self._preprocessed_data = self.__parse_rawdata(self._indices)\n",
        "\n",
        "\n",
        "        if isinstance(slices, (int, np.int64)):\n",
        "          # row \n",
        "          return {\n",
        "              'guid': self._preprocessed_data['guid'][slices],\n",
        "              'context': self._preprocessed_data['context'][slices],\n",
        "              'answers': self._preprocessed_data['answers'][slices],\n",
        "              'question': self._preprocessed_data['question'][slices]\n",
        "          }\n",
        "        elif isinstance(slices, str):\n",
        "          return self._preprocessed_data[slices]\n",
        "        elif isinstance(slices, slice):\n",
        "          return {\n",
        "              'guid': [self._preprocessed_data['guid'][i] for i in range(slices.start, slices.stop)],\n",
        "              'context': [self._preprocessed_data['context'][i] for i in range(slices.start, slices.stop)],\n",
        "              'answers': [self._preprocessed_data['answers'][i] for i in range(slices.start, slices.stop)],\n",
        "              'question': [self._preprocessed_data['question'][i] for i in range(slices.start, slices.stop)]\n",
        "          }\n",
        "        raise ValueError(f'unhanled slices : {slices}, type={type(slices)}')\n",
        "\n",
        "\n",
        "    def __parse_rawdata(self, indices) -> dict:\n",
        "\n",
        "        _indices = {'question':[], 'answers':[], \n",
        "                    'context':[], 'guid':[]}\n",
        "\n",
        "        for index, indice in enumerate(indices):\n",
        "          d_id, p_id, q_id = indice\n",
        "          paragraph = self._data['data'][d_id]['paragraphs'][p_id]\n",
        "\n",
        "          qa = paragraph['qas'][q_id]\n",
        "          _indices['guid'].append(qa['guid'])\n",
        "\n",
        "          _indices['question'].append(qa['question'])\n",
        "          _indices['answers'].append(qa['answers']) \n",
        "          _indices['context'].append(paragraph['context'])\n",
        "\n",
        "        print(len(_indices['question']))\n",
        "        return _indices\n",
        "\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self._indices)"
      ],
      "metadata": {
        "id": "7o0W3Yg0Cv0i"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 위치 (저장하신 위치에 따라 바꿔주세요)\n",
        "train_file = '/content/train.json'\n",
        "test_file = '/content/test.json'\n",
        "dataset = KoMRC.load(train_file)\n",
        "train_dataset, dev_dataset = KoMRC.split(dataset)\n",
        "print(\"Number of Train Samples:\", len(train_dataset))\n",
        "print(\"Number of Dev Samples:\", len(dev_dataset))\n",
        "\n",
        "print(dev_dataset[0])\n",
        "print(dev_dataset[0]['answers'])\n",
        "print(dev_dataset[0]['context'].split('.')[0])\n",
        "print(dev_dataset['answers'])\n",
        "print(len(dev_dataset['answers']))\n",
        "print(dev_dataset['question'])\n",
        "print(len(dev_dataset['question']))\n",
        "print(dev_dataset[0:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzKoL7keC3S3",
        "outputId": "11e68350-4dfe-486c-d9e4-0d695c98cbd9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Train Samples: 10834\n",
            "Number of Dev Samples: 1203\n",
            "1203\n",
            "{'guid': '844e22ab28924c1697d5ac28801b34c1', 'context': '지난해 주요 연극상을 나눠 가졌던 세 편의 작품이 올봄에 나란히 앙코르 무대를 갖는다. 대한민국연극대상 연기·무대예술상, 동아연극상 작품·희곡·연기상 등을 수상한 ‘알리바이 연대기’(17~20일 대학로 아르코예술극장 대극장, 25일~5월11일 서계동 국립극단 백성희장민호극장), 연극대상에서 대상과 희곡상을 받은 ‘여기가 집이다’(18일~5월22일 대학로 연우소극장), 연극대상 작품·연출상과 김상열연극상 수상작인 ‘황금용’(5월9~18일 서강대 메리홀 대극장)이다. 초연 당시 짧은 상연 기간과 낮은 인지도 등으로 공연을 놓친 연극팬에겐 평단으로부터 작품성을 인정받은 수작을 관람할 수 있는 기회다. ‘알리바이 연대기’는 희곡을 쓰고 연출한 김재엽의 가족사에 근거한 다큐멘터리 드라마다. 1930년에 태어난 한 개인의 사적인 연대기를 바탕으로 그 사이를 파고드는 역사적 순간들을 정밀하게 조명한다. 연출가는 “공적인 권력이 사적인 권리를 지켜주기보다 억압하기 일쑤였던 한국 현대사 속에서 개인은 언제나 무죄를 입증하며 하루하루 자신을 지켜내야 하는 ‘알리바이의 연대기’ 속에서 살아왔다”고 말한다.한국연극평론가협회는 이 작품을 ‘2013년 올해의 연극 베스트3’로 선정하며 “촘촘하고 세세하게 삶에 천착해 개인과 역사에 대한 이분법적 관점을 극복한다. 정치극에 대한 새로운 가능성을 보여줬다”고 평했다. 이 작품으로 연기상을 휩쓴 남명렬을 비롯해 지춘성 정원조 등 초연 배우들이 그대로 출연한다.‘여기가 집이다’는 허름하고 볼품 없는 ‘20년 전통’의 고시원에 모여 사는 사람들의 절망과 희망을 그린 작품. ‘차력사와 아코디언’ ‘택배 왔어요’를 만든 극단 이와삼의 장우재 대표가 직접 대본을 쓰고 연출했다. 나름의 규칙을 가지고 평화로웠던 고시원에 새로운 주인으로 등장한 ‘20세 고등학생’ 동교가 “이제부터 고시원 식구들에게 월세를 받지 않겠다”고 선언하면서 갑작스런 변화의 바람이 분다.날것 그대로의 직설 화법으로 풀어 놓는 풍성한 인생 이야기와 생동감 넘치는 극적 구조로 ‘집’의 본원적 의미와 삶에 대한 성찰의 기회를 제공한다는 평가를 받았다. 재연에서는 중견 배우 김세동이 장씨 역으로 출연해 박무영 김충근 한동규 류제승 김정민 등 초연 배우들과 호흡을 맞춘다.독일 극작가 롤란트 시멜페니히가 쓴 현대극 ‘황금용’은 독일 소도시에 있는 아시아계 간이식당을 배경으로 현대 물질사회와 세계화 속에 가려진 욕망과 폭력, 소외를 그린다. 치통을 앓지만 불법 체류자 신분으로 치과에 가지 못하는 한 젊은 중국인 요리사는 결국 비참한 최후를 맞는다.작품을 연출한 윤광진 용인대 교수는 “극의 배경은 유럽의 한 소도시이지만 서울이나 경기 안산의 어느 거리에서 일어나는 듯 우리에게 가깝게 다가오는 작품”이라며 “지하철에서 마주치는 외국인 근로자들, 그 옆에서 졸고 있는 우리의 이야기”라고 말했다. 이호성 남미정 이동근 한덕호 방현숙 등 초연 배우들이 다시 뭉친다.', 'answers': [{'text': '서강대 메리홀 대극장', 'answer_start': 246}], 'question': '윤광진 교수가 연출한 연극이 앙코르 공연을 하는 장소는 어디인가?'}\n",
            "[{'text': '서강대 메리홀 대극장', 'answer_start': 246}]\n",
            "지난해 주요 연극상을 나눠 가졌던 세 편의 작품이 올봄에 나란히 앙코르 무대를 갖는다\n",
            "[[{'text': '서강대 메리홀 대극장', 'answer_start': 246}], [{'text': '저축은행중앙회', 'answer_start': 345}, {'text': '중앙회', 'answer_start': 774}], [{'text': '구문론', 'answer_start': 521}], [{'text': '1956년', 'answer_start': 634}, {'text': '1956', 'answer_start': 634}], [{'text': '1부', 'answer_start': 187}], [{'text': '이베이', 'answer_start': 889}], [{'text': '50개', 'answer_start': 65}], [{'text': '‘쿠리어’', 'answer_start': 43}, {'text': '쿠리어', 'answer_start': 44}], [{'text': '스타일태그', 'answer_start': 561}], [{'text': '‘은행 계좌이동제’', 'answer_start': 386}, {'text': '은행 계좌이동제', 'answer_start': 387}, {'text': '계좌이동제', 'answer_start': 390}, {'text': '계좌이동제', 'answer_start': 1405}, {'text': '계좌이동제', 'answer_start': 1436}], [{'text': '‘최종면접에서의 역량 부족’', 'answer_start': 733}, {'text': '최종면접에서의 역량 부족', 'answer_start': 734}], [{'text': '바트러첸코 이반', 'answer_start': 21}], [{'text': '게라심 콜라파코프스키', 'answer_start': 340}], [{'text': '경북대', 'answer_start': 46}], [{'text': '은관문화훈장', 'answer_start': 350}], [{'text': '19명', 'answer_start': 240}, {'text': '19', 'answer_start': 240}], [{'text': '9월', 'answer_start': 216}, {'text': '9', 'answer_start': 216}], [{'text': '2011년부터', 'answer_start': 611}], [{'text': '1년7개월', 'answer_start': 264}], [{'text': '‘중간저장’', 'answer_start': 969}, {'text': '중간저장', 'answer_start': 970}], [{'text': '6000만달러', 'answer_start': 156}], [{'text': '10월1일', 'answer_start': 307}], [{'text': '사운드클라우드', 'answer_start': 462}], [{'text': '정부', 'answer_start': 319}], [{'text': '최낙정 해양수산부 장관', 'answer_start': 610}, {'text': '최낙정', 'answer_start': 610}, {'text': '최 장관', 'answer_start': 644}], [{'text': '템퍼', 'answer_start': 212}, {'text': '템퍼코리아', 'answer_start': 349}], [{'text': '1사1병영 캠페인', 'answer_start': 331}, {'text': '1사1병영 운동', 'answer_start': 555}], [{'text': '파란색', 'answer_start': 1376}], [{'text': '‘골드 올리브’', 'answer_start': 308}, {'text': '골드 올리브', 'answer_start': 309}], [{'text': '강북구', 'answer_start': 548}], [{'text': '동아시아정상회의(EAS)', 'answer_start': 139}, {'text': '동아시아정상회의', 'answer_start': 139}, {'text': 'EAS', 'answer_start': 525}], [{'text': '5달러', 'answer_start': 257}], [{'text': '형사', 'answer_start': 492}], [{'text': '기획재정부', 'answer_start': 253}], [{'text': '11월', 'answer_start': 558}], [{'text': '4천 명', 'answer_start': 585}], [{'text': '헨리 H. 빙엄', 'answer_start': 1454}, {'text': '헨리 H. 빙엄 대위', 'answer_start': 1454}, {'text': '빙엄', 'answer_start': 1460}, {'text': '빙엄 대위', 'answer_start': 1460}], [{'text': '진나라에 저항', 'answer_start': 720}], [{'text': '제주도 SH공사', 'answer_start': 300}], [{'text': '광고 모델', 'answer_start': 364}], [{'text': '3년', 'answer_start': 94}], [{'text': '이윤혜', 'answer_start': 75}], [{'text': '아케디아', 'answer_start': 500}], [{'text': '블랙 핸드', 'answer_start': 519}], [{'text': '대구고검장', 'answer_start': 582}], [{'text': '제네바', 'answer_start': 99}], [{'text': '‘광명역 지웰 에스테이트’', 'answer_start': 859}, {'text': '광명역 지웰 에스테이트', 'answer_start': 860}], [{'text': '금융위기', 'answer_start': 589}], [{'text': '450억달러', 'answer_start': 288}, {'text': '450억달러(약 52조2720억원)', 'answer_start': 288}, {'text': '약 52조2720억원', 'answer_start': 295}], [{'text': '말랑카우', 'answer_start': 627}], [{'text': '조대식', 'answer_start': 470}], [{'text': '이승현', 'answer_start': 72}], [{'text': '36세', 'answer_start': 702}, {'text': '36', 'answer_start': 702}], [{'text': '한덕희 대표', 'answer_start': 1133}, {'text': '한덕희', 'answer_start': 1133}], [{'text': '서일본 고속도로', 'answer_start': 1489}], [{'text': '포스코', 'answer_start': 331}], [{'text': '2003년', 'answer_start': 559}, {'text': '2003', 'answer_start': 559}], [{'text': '멀리사 스넬 (Melissa Snell)', 'answer_start': 665}, {'text': '멀리사 스넬', 'answer_start': 665}, {'text': 'Melissa Snell', 'answer_start': 673}], [{'text': '《완전한 죽음》', 'answer_start': 581}, {'text': '완전한 죽음', 'answer_start': 582}], [{'text': '난류', 'answer_start': 745}], [{'text': '스웨덴', 'answer_start': 1326}], [{'text': '금리 눈속임', 'answer_start': 515}], [{'text': '민우혁', 'answer_start': 974}], [{'text': '7명', 'answer_start': 408}, {'text': '7', 'answer_start': 408}], [{'text': '감사원', 'answer_start': 1345}], [{'text': '‘랜덤 업그레이드 배차’', 'answer_start': 274}, {'text': '랜덤 업그레이드 배차', 'answer_start': 275}], [{'text': '철기', 'answer_start': 130}], [{'text': '95인치', 'answer_start': 133}], [{'text': '최대주주', 'answer_start': 303}], [{'text': '케냐의 우간다 정교회', 'answer_start': 613}, {'text': '우간다 정교회', 'answer_start': 617}], [{'text': '3.8%', 'answer_start': 271}], [{'text': '7일', 'answer_start': 166}], [{'text': '엘리엇', 'answer_start': 1101}], [{'text': '우윤근', 'answer_start': 399}], [{'text': '3억8000만원', 'answer_start': 853}], [{'text': '넷마블', 'answer_start': 395}], [{'text': '박종훈', 'answer_start': 134}], [{'text': '27일', 'answer_start': 9}], [{'text': '벡스코', 'answer_start': 21}], [{'text': '신청자의 사연', 'answer_start': 994}, {'text': '사연', 'answer_start': 999}], [{'text': '동림저수지', 'answer_start': 197}], [{'text': '태국', 'answer_start': 334}], [{'text': '세례당', 'answer_start': 577}], [{'text': '일제강점기', 'answer_start': 367}], [{'text': '인간', 'answer_start': 840}], [{'text': '철퇴', 'answer_start': 476}], [{'text': '‘애플케어플러스(AppleCare+)’', 'answer_start': 588}, {'text': '애플케어플러스(AppleCare+)', 'answer_start': 589}, {'text': '애플케어플러스', 'answer_start': 589}, {'text': 'AppleCare+', 'answer_start': 597}], [{'text': '60개', 'answer_start': 348}, {'text': '60', 'answer_start': 348}], [{'text': '윌키파&갤러거 크리스토퍼 지안카를로', 'answer_start': 228}], [{'text': '허갑범', 'answer_start': 305}], [{'text': '구례 화엄사 각황전 앞 석등(국보 제12호)', 'answer_start': 657}, {'text': '구례 화엄사 각황전 앞 석등', 'answer_start': 657}, {'text': '국보 제12호', 'answer_start': 673}], [{'text': '몸체', 'answer_start': 166}], [{'text': '삼성물산', 'answer_start': 389}], [{'text': '내위성', 'answer_start': 251}], [{'text': '11.6㎞/L', 'answer_start': 592}], [{'text': '‘대구 북죽곡 삼정그린코아 더 베스트’', 'answer_start': 1111}, {'text': '대구 북죽곡 삼정그린코아 더 베스트', 'answer_start': 1112}], [{'text': '라젠드라 1세', 'answer_start': 838}], [{'text': '1만명', 'answer_start': 446}], [{'text': '1521년', 'answer_start': 5}], [{'text': '총 9차례', 'answer_start': 434}, {'text': '9차례', 'answer_start': 436}, {'text': '9', 'answer_start': 436}], [{'text': '28일', 'answer_start': 133}], [{'text': '6개', 'answer_start': 222}, {'text': '6', 'answer_start': 222}], [{'text': '한여름', 'answer_start': 381}, {'text': '여름', 'answer_start': 382}], [{'text': '비무장지대(DMZ) 관광 활성화', 'answer_start': 33}], [{'text': '대령', 'answer_start': 182}], [{'text': '가까운 미래의 지구', 'answer_start': 422}], [{'text': '금융위원회', 'answer_start': 0}], [{'text': '유승선', 'answer_start': 1238}], [{'text': '프로페서 코브라', 'answer_start': 1391}, {'text': '코브라', 'answer_start': 1751}], [{'text': '대선 공약', 'answer_start': 376}], [{'text': '‘K-POP MTCamp’', 'answer_start': 413}, {'text': 'K-POP MTCamp', 'answer_start': 414}], [{'text': '스탈린', 'answer_start': 297}], [{'text': '서울드래곤시티 2층 아케이드', 'answer_start': 398}], [{'text': '신형 제네시스', 'answer_start': 1643}], [{'text': '장기근속 공제제도', 'answer_start': 498}, {'text': '장기근속 공제', 'answer_start': 498}], [{'text': '알자베르 가문', 'answer_start': 290}], [{'text': '360배', 'answer_start': 468}, {'text': '360', 'answer_start': 468}], [{'text': '740억원', 'answer_start': 717}, {'text': '740억원가량', 'answer_start': 717}], [{'text': '네우손 바르보자', 'answer_start': 1281}], [{'text': '한국', 'answer_start': 445}], [{'text': '코로나19', 'answer_start': 1040}, {'text': '코로나', 'answer_start': 1040}], [{'text': '창작자', 'answer_start': 379}], [{'text': '조선', 'answer_start': 471}, {'text': '조선시대', 'answer_start': 471}], [{'text': '500동', 'answer_start': 389}, {'text': '500', 'answer_start': 389}], [{'text': '프랑스', 'answer_start': 87}], [{'text': '징계위원회', 'answer_start': 170}], [{'text': '1919년', 'answer_start': 166}, {'text': '1919', 'answer_start': 166}], [{'text': '오전 5시', 'answer_start': 377}, {'text': '5시', 'answer_start': 380}], [{'text': '천안', 'answer_start': 113}], [{'text': '애경그룹', 'answer_start': 426}, {'text': '애경', 'answer_start': 426}], [{'text': '정주영', 'answer_start': 294}], [{'text': '클레오메네스', 'answer_start': 813}], [{'text': '5년', 'answer_start': 774}], [{'text': '1999년', 'answer_start': 410}, {'text': '1999', 'answer_start': 410}], [{'text': '『협동조합에 관하여』', 'answer_start': 310}, {'text': '협동조합에 관하여', 'answer_start': 311}], [{'text': '은평구', 'answer_start': 489}], [{'text': '‘신상출시 편스토랑’', 'answer_start': 726}, {'text': '신상출시 편스토랑', 'answer_start': 727}], [{'text': '신동주', 'answer_start': 606}], [{'text': '2.5단계', 'answer_start': 690}, {'text': '2.5', 'answer_start': 690}], [{'text': '상인', 'answer_start': 548}], [{'text': '조양호', 'answer_start': 1285}], [{'text': '롯데면세점', 'answer_start': 183}], [{'text': '스페인', 'answer_start': 140}], [{'text': '2020', 'answer_start': 937}, {'text': '2020년', 'answer_start': 937}], [{'text': '중국', 'answer_start': 585}], [{'text': '1998년', 'answer_start': 417}, {'text': '1998', 'answer_start': 417}], [{'text': '기업은행', 'answer_start': 735}], [{'text': '1조6299억원', 'answer_start': 633}], [{'text': '1610년', 'answer_start': 43}], [{'text': '이탈리아군', 'answer_start': 583}], [{'text': '9월', 'answer_start': 884}, {'text': '9', 'answer_start': 884}], [{'text': '10월 4일', 'answer_start': 161}], [{'text': '986억달러', 'answer_start': 131}], [{'text': 'B블록', 'answer_start': 689}, {'text': 'B', 'answer_start': 689}], [{'text': '1897년', 'answer_start': 41}, {'text': '1897', 'answer_start': 41}], [{'text': '대의제도', 'answer_start': 401}], [{'text': '칠곡', 'answer_start': 988}], [{'text': '에스톡', 'answer_start': 55}], [{'text': '악사 홍선종', 'answer_start': 160}, {'text': '홍선종', 'answer_start': 163}], [{'text': '1988년', 'answer_start': 260}, {'text': '1988', 'answer_start': 260}], [{'text': '조선 순조 9년(1809)', 'answer_start': 268}, {'text': '조선 순조 9년', 'answer_start': 268}, {'text': '1809', 'answer_start': 277}], [{'text': '토니 그윈', 'answer_start': 588}], [{'text': '2010년', 'answer_start': 308}], [{'text': '동양적인 부드러움', 'answer_start': 153}], [{'text': '서방 총대주교', 'answer_start': 322}], [{'text': '인도네시아 발리', 'answer_start': 182}, {'text': '발리', 'answer_start': 188}], [{'text': '가장자리', 'answer_start': 111}], [{'text': '23개', 'answer_start': 382}, {'text': '23', 'answer_start': 382}], [{'text': '삼종지도', 'answer_start': 358}, {'text': '삼종지도(三從之道)', 'answer_start': 358}, {'text': '三從之道', 'answer_start': 363}], [{'text': '2023t', 'answer_start': 979}], [{'text': '46개', 'answer_start': 700}, {'text': '46', 'answer_start': 700}], [{'text': '페니파싱', 'answer_start': 16}], [{'text': '‘봄날’', 'answer_start': 454}, {'text': '봄날', 'answer_start': 455}], [{'text': '신분보장 조항의 입법', 'answer_start': 168}], [{'text': '겐로쿠 지진', 'answer_start': 130}], [{'text': '전산교체 과정 의혹', 'answer_start': 396}], [{'text': '산업포장', 'answer_start': 570}], [{'text': '항공사진', 'answer_start': 347}], [{'text': '7만5000원', 'answer_start': 404}], [{'text': '서울', 'answer_start': 202}], [{'text': '와카야마 제4고로', 'answer_start': 618}], [{'text': '사건 자체의 의미', 'answer_start': 1096}], [{'text': 'NVMe 방식', 'answer_start': 448}, {'text': 'NVMe', 'answer_start': 448}], [{'text': '‘설날’', 'answer_start': 383}, {'text': '설날', 'answer_start': 384}], [{'text': '두 개', 'answer_start': 574}, {'text': '두', 'answer_start': 574}], [{'text': '방어대장군', 'answer_start': 316}], [{'text': '나미', 'answer_start': 220}], [{'text': '스페인', 'answer_start': 168}], [{'text': '아일린 그레이', 'answer_start': 536}], [{'text': '박세준', 'answer_start': 36}], [{'text': '인스타그램', 'answer_start': 972}], [{'text': '암회색', 'answer_start': 402}], [{'text': '8만 4,337명', 'answer_start': 719}, {'text': '8만 4,337', 'answer_start': 719}], [{'text': '무료', 'answer_start': 199}], [{'text': '보건복지부', 'answer_start': 313}], [{'text': '170cm', 'answer_start': 68}], [{'text': '에어팟 프로', 'answer_start': 1184}], [{'text': '한문 교사', 'answer_start': 381}, {'text': '교사', 'answer_start': 384}], [{'text': '서대문 경교장', 'answer_start': 1074}], [{'text': '‘분리과세 하이일드펀드’', 'answer_start': 1125}, {'text': '분리과세 하이일드펀드', 'answer_start': 1126}], [{'text': '뮤직박스 음악', 'answer_start': 326}], [{'text': '기초노령연금', 'answer_start': 130}], [{'text': '29일', 'answer_start': 213}], [{'text': '820만채', 'answer_start': 51}, {'text': '820만', 'answer_start': 51}], [{'text': '150', 'answer_start': 324}, {'text': '150편', 'answer_start': 324}], [{'text': '1939년', 'answer_start': 15}, {'text': '1939', 'answer_start': 15}], [{'text': '2016년', 'answer_start': 198}], [{'text': '최관호', 'answer_start': 203}], [{'text': '1.6%', 'answer_start': 211}], [{'text': '채무자', 'answer_start': 45}], [{'text': '테헤란', 'answer_start': 428}], [{'text': '14.4%', 'answer_start': 708}], [{'text': '베르나르도 총대주교', 'answer_start': 522}, {'text': '베르나르도', 'answer_start': 522}], [{'text': '23조6000억원', 'answer_start': 355}], [{'text': '40억원', 'answer_start': 233}], [{'text': '강재섭', 'answer_start': 386}], [{'text': '9510가구', 'answer_start': 274}, {'text': '9510', 'answer_start': 274}], [{'text': '암', 'answer_start': 279}], [{'text': '스카이 해븐 사원', 'answer_start': 552}], [{'text': '동성상고', 'answer_start': 195}], [{'text': '‘플립보드’', 'answer_start': 336}, {'text': '플립보드', 'answer_start': 337}], [{'text': '1996년', 'answer_start': 56}, {'text': '1996', 'answer_start': 56}], [{'text': '고등학교를 보다 일찍 졸업하기 위한 수단', 'answer_start': 690}], [{'text': '투시노', 'answer_start': 0}], [{'text': '2개', 'answer_start': 399}, {'text': '2', 'answer_start': 399}], [{'text': '2005년', 'answer_start': 358}], [{'text': '소프트웨어 모듈', 'answer_start': 108}], [{'text': '순자격식(循資格式)', 'answer_start': 279}, {'text': '순자격식', 'answer_start': 279}, {'text': '循資格式', 'answer_start': 284}], [{'text': '뉴캐슬', 'answer_start': 609}], [{'text': '4년', 'answer_start': 865}], [{'text': '조선중앙일보', 'answer_start': 0}], [{'text': '148조6000억원', 'answer_start': 715}], [{'text': '미시코바강', 'answer_start': 394}], [{'text': 'SM엔터테인먼트', 'answer_start': 200}, {'text': 'SM', 'answer_start': 200}], [{'text': '크리세스', 'answer_start': 12}], [{'text': '페이스북', 'answer_start': 818}], [{'text': '제우스', 'answer_start': 588}], [{'text': '해운조합', 'answer_start': 708}], [{'text': '중앙대', 'answer_start': 836}, {'text': '중앙', 'answer_start': 836}], [{'text': '갈리아', 'answer_start': 376}], [{'text': '\"경찰과 국민은 하나\"', 'answer_start': 347}, {'text': '경찰과 국민은 하나', 'answer_start': 348}], [{'text': '다양한 소비자들의 취향을 반영', 'answer_start': 778}, {'text': '다양한 소비자들의 취향을 반영하기 위해', 'answer_start': 778}], [{'text': '슈퍼세이브에 ‘재가입’하는 회원들', 'answer_start': 35}, {'text': '슈퍼세이브에 ‘재가입’하는 회원', 'answer_start': 35}, {'text': '슈퍼세이브에 가입한 이력이 있는 회원', 'answer_start': 98}], [{'text': '91명', 'answer_start': 841}, {'text': '91', 'answer_start': 841}], [{'text': '싱가포르', 'answer_start': 883}], [{'text': '‘자동 Wake-up’', 'answer_start': 249}, {'text': '자동 Wake-up', 'answer_start': 250}], [{'text': '암으로 죽어간다는 믿음', 'answer_start': 478}, {'text': '암으로 죽어간다는 믿음 때문에', 'answer_start': 478}], [{'text': '1억원', 'answer_start': 271}], [{'text': '표트르 슈체틴킨', 'answer_start': 1780}], [{'text': '에어워셔 ‘숨’', 'answer_start': 353}, {'text': '숨', 'answer_start': 359}], [{'text': '국무총리', 'answer_start': 119}], [{'text': '자동차', 'answer_start': 38}], [{'text': '2015년', 'answer_start': 555}, {'text': '2015', 'answer_start': 555}], [{'text': '통인 주기', 'answer_start': 159}, {'text': '주기', 'answer_start': 162}], [{'text': '세인트루이스', 'answer_start': 460}], [{'text': '50인', 'answer_start': 896}, {'text': '50', 'answer_start': 896}], [{'text': '충청권 과학비즈니스벨트 사업', 'answer_start': 110}], [{'text': '개인화된 경험', 'answer_start': 864}, {'text': '개인화된 경험들', 'answer_start': 864}], [{'text': '463억원', 'answer_start': 897}], [{'text': '‘플라스마 화학증착(CVD)’ 법', 'answer_start': 331}, {'text': '플라스마 화학증착(CVD)', 'answer_start': 332}, {'text': '플라스마 화학증착', 'answer_start': 332}, {'text': 'CVD', 'answer_start': 342}], [{'text': '32명', 'answer_start': 461}, {'text': '32', 'answer_start': 461}], [{'text': '둘째 아들', 'answer_start': 71}], [{'text': '영국', 'answer_start': 26}], [{'text': '에메랄드', 'answer_start': 757}, {'text': '에메랄드 컬러', 'answer_start': 757}], [{'text': '레스토랑', 'answer_start': 657}], [{'text': '아베노믹스', 'answer_start': 140}], [{'text': '소루트비히', 'answer_start': 379}], [{'text': '4일', 'answer_start': 626}], [{'text': '1770만도즈', 'answer_start': 401}], [{'text': '‘신한PWM 라운지’', 'answer_start': 1223}, {'text': '신한PWM 라운지', 'answer_start': 1224}], [{'text': '‘Risk Management Award’', 'answer_start': 763}, {'text': 'Risk Management Award', 'answer_start': 764}], [{'text': '60억원', 'answer_start': 130}], [{'text': '5%', 'answer_start': 632}], [{'text': '후쿠오카 임시 법원', 'answer_start': 819}], [{'text': '개화역', 'answer_start': 445}], [{'text': '2층', 'answer_start': 146}, {'text': '2', 'answer_start': 146}], [{'text': '1.08달러', 'answer_start': 474}], [{'text': '1727', 'answer_start': 231}, {'text': '1727년', 'answer_start': 231}], [{'text': '경건주의', 'answer_start': 69}], [{'text': '이기석', 'answer_start': 927}], [{'text': '독도', 'answer_start': 638}], [{'text': 'Talent X Junior+', 'answer_start': 673}], [{'text': '장제스', 'answer_start': 1384}], [{'text': '한정대', 'answer_start': 322}], [{'text': '10만원', 'answer_start': 202}], [{'text': 'MLP펀드', 'answer_start': 288}], [{'text': '70%', 'answer_start': 421}], [{'text': '11월17일', 'answer_start': 627}], [{'text': '로열 콘세르트허바우 오케스트라(RCO)', 'answer_start': 143}, {'text': '로열 콘세르트허바우 오케스트라', 'answer_start': 143}, {'text': 'RCO', 'answer_start': 160}], [{'text': '일관', 'answer_start': 210}], [{'text': '6월', 'answer_start': 297}, {'text': '6', 'answer_start': 297}], [{'text': '제비초리', 'answer_start': 251}], [{'text': '민족문제연구소', 'answer_start': 33}], [{'text': '인천국제공항 귀빈실', 'answer_start': 281}, {'text': '인천국제공항', 'answer_start': 281}], [{'text': '8%', 'answer_start': 283}, {'text': '8', 'answer_start': 283}], [{'text': '9월4~6일', 'answer_start': 612}], [{'text': '(주)한라', 'answer_start': 401}, {'text': '한라', 'answer_start': 404}], [{'text': '두 명', 'answer_start': 31}], [{'text': '회칠', 'answer_start': 13}], [{'text': '기독교에 대한 탄압', 'answer_start': 886}], [{'text': '85㎡', 'answer_start': 267}, {'text': '85㎡ 이하', 'answer_start': 267}], [{'text': '연세대', 'answer_start': 231}], [{'text': '상암동', 'answer_start': 18}], [{'text': '국제통화기금(IMF)', 'answer_start': 411}, {'text': '국제통화기금', 'answer_start': 411}, {'text': 'IMF', 'answer_start': 418}], [{'text': '1998년', 'answer_start': 244}, {'text': '1998년 외환위기 당시', 'answer_start': 244}, {'text': '외환위기 당시', 'answer_start': 250}], [{'text': '포스코건설', 'answer_start': 49}], [{'text': '미세플라스틱', 'answer_start': 444}], [{'text': '강남 3구', 'answer_start': 407}], [{'text': '1864년', 'answer_start': 131}], [{'text': '\"공유지의 비극\"', 'answer_start': 270}, {'text': '공유지의 비극', 'answer_start': 271}], [{'text': '칸막이', 'answer_start': 282}], [{'text': '26일', 'answer_start': 172}], [{'text': '2009년', 'answer_start': 334}, {'text': '2009', 'answer_start': 334}], [{'text': '김영수', 'answer_start': 80}], [{'text': '출장 잦은 건축가', 'answer_start': 412}, {'text': '건축가', 'answer_start': 418}], [{'text': '이효상 의장', 'answer_start': 106}, {'text': '이효상', 'answer_start': 106}], [{'text': '1982년', 'answer_start': 54}, {'text': '1982', 'answer_start': 54}], [{'text': '정재정', 'answer_start': 207}], [{'text': '700만원', 'answer_start': 628}], [{'text': '‘e편한세상 신촌’', 'answer_start': 294}, {'text': 'e편한세상 신촌', 'answer_start': 295}], [{'text': '웅기탁', 'answer_start': 737}], [{'text': '서울 신당동 동대문패션비즈센터', 'answer_start': 248}, {'text': '신당동 동대문패션비즈센터', 'answer_start': 251}, {'text': '동대문패션비즈센터', 'answer_start': 255}], [{'text': 'D1세션', 'answer_start': 487}, {'text': 'D1', 'answer_start': 487}], [{'text': '두 달', 'answer_start': 180}], [{'text': '약 30년', 'answer_start': 302}, {'text': '30년', 'answer_start': 304}], [{'text': '‘카사델타코’', 'answer_start': 1573}], [{'text': '50%', 'answer_start': 480}, {'text': '50', 'answer_start': 480}], [{'text': '2011년', 'answer_start': 622}, {'text': '2011', 'answer_start': 622}], [{'text': '주벌 얼리의 보병부대', 'answer_start': 498}], [{'text': '지난달 10일', 'answer_start': 225}, {'text': '10일', 'answer_start': 229}], [{'text': '로컬스티치', 'answer_start': 624}], [{'text': '‘내비둬 콘서트’', 'answer_start': 147}, {'text': '내비둬 콘서트', 'answer_start': 148}], [{'text': '2만1979원', 'answer_start': 159}], [{'text': '버진아일랜드', 'answer_start': 872}], [{'text': '팝 발라드', 'answer_start': 414}], [{'text': '이영희 막달레나', 'answer_start': 165}, {'text': '이영희', 'answer_start': 165}], [{'text': '아루에', 'answer_start': 156}], [{'text': '100여개', 'answer_start': 683}], [{'text': '미국', 'answer_start': 439}], [{'text': '2년', 'answer_start': 215}], [{'text': '60여년', 'answer_start': 205}], [{'text': '4만 9천원', 'answer_start': 446}], [{'text': '48.27%', 'answer_start': 1816}], [{'text': '혁명적공산주의자동맹', 'answer_start': 512}], [{'text': '이완구', 'answer_start': 396}], [{'text': '중소기업', 'answer_start': 645}], [{'text': '2007년', 'answer_start': 128}, {'text': '2007', 'answer_start': 128}], [{'text': '대학교의 의학 교수', 'answer_start': 162}, {'text': '의학 교수', 'answer_start': 167}], [{'text': '‘라이언 킹’', 'answer_start': 741}, {'text': '라이언 킹', 'answer_start': 742}], [{'text': '뱅크샐러드 송금 서비스 런칭 이벤트', 'answer_start': 568}], [{'text': '5월 29일', 'answer_start': 454}], [{'text': '벌레와 꽃, 그리고 새들을 노래한 시집', 'answer_start': 392}, {'text': '시집', 'answer_start': 411}], [{'text': '2,418건', 'answer_start': 314}, {'text': '2,418', 'answer_start': 314}], [{'text': '총 5000대', 'answer_start': 1460}, {'text': '5000대', 'answer_start': 1462}], [{'text': '최경환', 'answer_start': 0}], [{'text': '‘소회의실’', 'answer_start': 901}, {'text': '‘소회의실’ 기능', 'answer_start': 901}, {'text': '소회의실', 'answer_start': 902}], [{'text': '저출산고령사회위원회', 'answer_start': 517}], [{'text': '23일', 'answer_start': 120}, {'text': '23', 'answer_start': 120}], [{'text': '‘중항삼성생명보험유한공사’', 'answer_start': 322}, {'text': '중항삼성생명보험유한공사', 'answer_start': 323}, {'text': '중항삼성', 'answer_start': 355}, {'text': '삼성생명', 'answer_start': 605}], [{'text': '경제개혁조치', 'answer_start': 53}], [{'text': '5000만원', 'answer_start': 526}], [{'text': '54개', 'answer_start': 399}, {'text': '54', 'answer_start': 399}], [{'text': '마케도니아의 장군 알렉산더 3세', 'answer_start': 399}, {'text': '알렉산더 3세', 'answer_start': 409}], [{'text': '7조9576억원', 'answer_start': 1260}], [{'text': '현대건설', 'answer_start': 310}], [{'text': '황도철학이라는 어용 학문을 연구해 다수의 논설을 발표한 일', 'answer_start': 320}], [{'text': '보병 기사(말에서 내린 기사)', 'answer_start': 490}, {'text': '보병 기사', 'answer_start': 490}, {'text': '말에서 내린 기사', 'answer_start': 496}], [{'text': '히브리 백성', 'answer_start': 436}], [{'text': '2009년', 'answer_start': 179}], [{'text': '12%', 'answer_start': 904}, {'text': '12', 'answer_start': 904}], [{'text': '중재위원회', 'answer_start': 358}], [{'text': '1748억원', 'answer_start': 510}], [{'text': '<옥자>', 'answer_start': 812}, {'text': '옥자', 'answer_start': 813}], [{'text': '유동성 부족', 'answer_start': 738}], [{'text': '서울', 'answer_start': 311}], [{'text': '9월 1일', 'answer_start': 259}], [{'text': '23만개', 'answer_start': 452}], [{'text': '전략총괄이사', 'answer_start': 549}], [{'text': '‘메탈 그라운드’', 'answer_start': 276}, {'text': '메탈 그라운드', 'answer_start': 277}], [{'text': '대나라', 'answer_start': 166}], [{'text': '지난 2월4일', 'answer_start': 196}], [{'text': '2.9%', 'answer_start': 561}, {'text': '2.9', 'answer_start': 561}], [{'text': '아테나이', 'answer_start': 530}], [{'text': '라치오', 'answer_start': 549}], [{'text': '갤럭시S6', 'answer_start': 322}], [{'text': '1905년', 'answer_start': 748}, {'text': '1905', 'answer_start': 748}], [{'text': '한국', 'answer_start': 1312}], [{'text': '유로콥터', 'answer_start': 419}], [{'text': '2500여점', 'answer_start': 213}, {'text': '2500', 'answer_start': 213}], [{'text': '중국', 'answer_start': 714}], [{'text': '보코하람 테러리스트들', 'answer_start': 217}, {'text': '보코하람 테러리스트', 'answer_start': 217}], [{'text': '‘불평등은 어떻게 성장을 촉발시키나’', 'answer_start': 254}, {'text': '불평등은 어떻게 성장을 촉발시키나', 'answer_start': 255}], [{'text': '바리오 아덴트로 미션', 'answer_start': 485}], [{'text': '어린이날', 'answer_start': 369}], [{'text': '6000원', 'answer_start': 544}], [{'text': '‘화성침공’', 'answer_start': 664}, {'text': '화성침공', 'answer_start': 665}], [{'text': '샌디훅초등학교에서 발생한 총기 난사 사건', 'answer_start': 81}], [{'text': '9조7198억원', 'answer_start': 307}], [{'text': '어머니', 'answer_start': 372}], [{'text': '비단', 'answer_start': 232}], [{'text': '16일', 'answer_start': 47}], [{'text': '메이저 릿지', 'answer_start': 583}], [{'text': '강신명', 'answer_start': 635}], [{'text': '서울', 'answer_start': 105}], [{'text': '성벽에 목이 매달리는 교수형', 'answer_start': 1088}, {'text': '교수형', 'answer_start': 1100}], [{'text': '정부서울청사', 'answer_start': 241}], [{'text': '학생규약', 'answer_start': 636}], [{'text': '69조원', 'answer_start': 331}], [{'text': '성균관대', 'answer_start': 879}, {'text': '성균관', 'answer_start': 879}], [{'text': '4월15일', 'answer_start': 764}], [{'text': '반신화적인 인물인 우파', 'answer_start': 84}, {'text': '우파', 'answer_start': 94}], [{'text': '‘순간’', 'answer_start': 500}, {'text': '순간', 'answer_start': 501}], [{'text': '사적기업설립권', 'answer_start': 115}], [{'text': '11월', 'answer_start': 650}, {'text': '11', 'answer_start': 650}], [{'text': '김자봉', 'answer_start': 63}], [{'text': '21일', 'answer_start': 693}], [{'text': '1993년', 'answer_start': 208}], [{'text': '가수', 'answer_start': 463}], [{'text': '‘구글 킵(keep)’', 'answer_start': 13}, {'text': '구글 킵', 'answer_start': 14}, {'text': '구글 킵(keep)', 'answer_start': 14}, {'text': 'keep', 'answer_start': 19}], [{'text': '무역보험공사', 'answer_start': 70}, {'text': '무보', 'answer_start': 99}], [{'text': '2층', 'answer_start': 377}, {'text': '2', 'answer_start': 377}], [{'text': '460억달러', 'answer_start': 214}], [{'text': '1811년', 'answer_start': 318}, {'text': '1811', 'answer_start': 318}], [{'text': '6만23', 'answer_start': 661}, {'text': '6만23대', 'answer_start': 661}], [{'text': '컴퓨터', 'answer_start': 437}], [{'text': '29일', 'answer_start': 106}, {'text': '29', 'answer_start': 106}], [{'text': '21일', 'answer_start': 510}, {'text': '21', 'answer_start': 510}], [{'text': '에어로바이런먼트', 'answer_start': 225}], [{'text': '4발기 제작 경험', 'answer_start': 99}], [{'text': '거치대', 'answer_start': 184}], [{'text': '기원전 451년', 'answer_start': 237}], [{'text': '농협중앙회', 'answer_start': 739}], [{'text': '과학', 'answer_start': 522}, {'text': '과학적 측면', 'answer_start': 522}], [{'text': '일본', 'answer_start': 477}], [{'text': '뇌출혈', 'answer_start': 168}], [{'text': '28일', 'answer_start': 12}], [{'text': '28개', 'answer_start': 276}, {'text': '28', 'answer_start': 276}], [{'text': '‘안정적’', 'answer_start': 123}, {'text': '안정적', 'answer_start': 124}], [{'text': '롯데', 'answer_start': 653}], [{'text': '1907년', 'answer_start': 873}, {'text': '1907', 'answer_start': 873}], [{'text': '비선형 광학 현상', 'answer_start': 197}], [{'text': '철도박물관', 'answer_start': 271}, {'text': '철도 박물관', 'answer_start': 353}], [{'text': '200여명', 'answer_start': 271}], [{'text': '이종호', 'answer_start': 367}], [{'text': '마라(麻辣)', 'answer_start': 205}, {'text': '마라', 'answer_start': 205}, {'text': '麻辣', 'answer_start': 208}], [{'text': '미켈란젤로', 'answer_start': 591}], [{'text': '자장율사', 'answer_start': 60}], [{'text': '아트워터흙파는쥐', 'answer_start': 165}], [{'text': '《칼의 노래》', 'answer_start': 267}, {'text': '칼의 노래', 'answer_start': 268}], [{'text': '듀얼키', 'answer_start': 164}], [{'text': '인도', 'answer_start': 796}], [{'text': '형태에 있어 거의 혹은 전혀 자유가 없어 다양한 번역을 창조해내기가 불가능하고 시구 구조에서도 다른 여지를 찾기 어려운 탓이다.', 'answer_start': 328}], [{'text': '로젠바움', 'answer_start': 347}], [{'text': '영국', 'answer_start': 1642}], [{'text': '리버리', 'answer_start': 178}], [{'text': '《탐사기획 스트레이트》', 'answer_start': 101}, {'text': '탐사기획 스트레이트', 'answer_start': 102}], [{'text': '촉매', 'answer_start': 237}], [{'text': '24시간', 'answer_start': 696}, {'text': '24', 'answer_start': 696}], [{'text': '유니레버', 'answer_start': 1507}], [{'text': '인체의 치수', 'answer_start': 310}], [{'text': '레흐 카친스키', 'answer_start': 373}, {'text': '레흐', 'answer_start': 373}], [{'text': '3400건', 'answer_start': 350}, {'text': '3400', 'answer_start': 350}], [{'text': '그랜드하얏트호텔', 'answer_start': 255}, {'text': '그랜드하얏트', 'answer_start': 255}], [{'text': '케빈 G. 린치', 'answer_start': 773}], [{'text': '레오 6세의 전임자인 요한 10세', 'answer_start': 240}, {'text': '요한 10세', 'answer_start': 252}], [{'text': '750억원', 'answer_start': 221}], [{'text': '분만직전', 'answer_start': 211}], [{'text': '8307', 'answer_start': 151}, {'text': '8307가구', 'answer_start': 151}], [{'text': '1916년', 'answer_start': 824}, {'text': '1916', 'answer_start': 824}], [{'text': '1525년까지', 'answer_start': 55}, {'text': '1525년', 'answer_start': 55}, {'text': '1525', 'answer_start': 55}], [{'text': '마이클 무어', 'answer_start': 554}], [{'text': '징역 또는 금고의 형을 선고받고 형기의 3분의 1을 마친 모범 수형자', 'answer_start': 365}], [{'text': '4대 2', 'answer_start': 764}], [{'text': '엠큐브씨어터', 'answer_start': 510}], [{'text': '공훈의 보상', 'answer_start': 1779}, {'text': '보상', 'answer_start': 1783}], [{'text': '표준화질', 'answer_start': 512}, {'text': '표준화질(SD)', 'answer_start': 512}, {'text': 'SD', 'answer_start': 517}], [{'text': '20km', 'answer_start': 83}], [{'text': '건과류', 'answer_start': 707}], [{'text': '여성소비자연합', 'answer_start': 520}], [{'text': '신계륜 위원장', 'answer_start': 148}, {'text': '신계륜', 'answer_start': 148}, {'text': '신 위원장', 'answer_start': 210}], [{'text': '전문 성우들', 'answer_start': 184}, {'text': '전문 성우', 'answer_start': 184}], [{'text': '27일', 'answer_start': 1384}], [{'text': '충칭', 'answer_start': 562}], [{'text': 'f(x)', 'answer_start': 394}], [{'text': '지안시', 'answer_start': 105}], [{'text': '고동우', 'answer_start': 23}], [{'text': '리플리컨트', 'answer_start': 430}], [{'text': '세월호 참사', 'answer_start': 456}, {'text': '세월호', 'answer_start': 456}], [{'text': '영화배우', 'answer_start': 385}], [{'text': '아웃도어 브랜드 트렉스타', 'answer_start': 106}, {'text': '트렉스타', 'answer_start': 115}], [{'text': '감정', 'answer_start': 39}], [{'text': '혼묘지', 'answer_start': 249}, {'text': '혼묘지(本妙寺)', 'answer_start': 249}, {'text': '本妙寺', 'answer_start': 253}], [{'text': '15명', 'answer_start': 426}, {'text': '15', 'answer_start': 426}], [{'text': '‘조드가 불어오는 곳’', 'answer_start': 139}, {'text': '조드가 불어오는 곳', 'answer_start': 140}], [{'text': '112만8000여명', 'answer_start': 496}], [{'text': '7일', 'answer_start': 830}], [{'text': '사라센인', 'answer_start': 783}], [{'text': '70%', 'answer_start': 470}], [{'text': '청나라 때', 'answer_start': 24}, {'text': '청나라', 'answer_start': 24}], [{'text': '금융 공기업 부채', 'answer_start': 0}], [{'text': '일본 도야마', 'answer_start': 934}, {'text': '도야마', 'answer_start': 937}], [{'text': '김복영', 'answer_start': 532}], [{'text': '자본주의적 농업 소유 구조', 'answer_start': 167}], [{'text': '진주교대', 'answer_start': 410}], [{'text': '말', 'answer_start': 482}], [{'text': '기독교복음침례회', 'answer_start': 233}, {'text': '기독교복음침례회(구원파)', 'answer_start': 233}, {'text': '구원파', 'answer_start': 242}], [{'text': '25일', 'answer_start': 110}, {'text': '25', 'answer_start': 110}], [{'text': '개척시대의 부락회의(타운 미팅)', 'answer_start': 426}, {'text': '부락회의(타운 미팅)', 'answer_start': 432}, {'text': '부락회의', 'answer_start': 432}, {'text': '타운 미팅', 'answer_start': 437}], [{'text': '김치스탈', 'answer_start': 142}], [{'text': '장자 유비(劉肥)', 'answer_start': 315}, {'text': '장자 유비', 'answer_start': 315}, {'text': '유비', 'answer_start': 318}, {'text': '유비(劉肥)', 'answer_start': 318}, {'text': '劉肥', 'answer_start': 321}], [{'text': '‘몬스터’', 'answer_start': 556}, {'text': '몬스터', 'answer_start': 557}], [{'text': '기원전 310년의 전멸 이후', 'answer_start': 614}, {'text': '기원전 310년', 'answer_start': 614}], [{'text': '17개', 'answer_start': 7}, {'text': '17', 'answer_start': 7}], [{'text': '5개', 'answer_start': 260}], [{'text': '현대자동차', 'answer_start': 76}, {'text': '현대차', 'answer_start': 184}], [{'text': '롯데홀딩스', 'answer_start': 757}], [{'text': '5000만원', 'answer_start': 1095}], [{'text': '부산센텀점', 'answer_start': 472}], [{'text': '16,100원', 'answer_start': 220}], [{'text': '리틀 포크 교회', 'answer_start': 576}], [{'text': '최영애', 'answer_start': 49}], [{'text': '1913년', 'answer_start': 881}], [{'text': '‘배틀 포인트’', 'answer_start': 273}, {'text': '배틀 포인트', 'answer_start': 274}], [{'text': '‘꿈의 숲 SK뷰’', 'answer_start': 147}, {'text': '꿈의 숲 SK뷰', 'answer_start': 488}], [{'text': '1947년', 'answer_start': 0}], [{'text': '비센테 델 보스케 감독', 'answer_start': 1123}, {'text': '비센테 델 보스케', 'answer_start': 1123}, {'text': '델 보스케 감독', 'answer_start': 1127}, {'text': '델 보스케', 'answer_start': 1127}], [{'text': '3년', 'answer_start': 443}], [{'text': '16세기', 'answer_start': 227}], [{'text': '롯데카드', 'answer_start': 663}], [{'text': '<<종횡무진 한국경제>>', 'answer_start': 941}, {'text': '종횡무진 한국경제', 'answer_start': 943}], [{'text': '독일', 'answer_start': 653}], [{'text': '하리수', 'answer_start': 399}], [{'text': '나카지마 하루오', 'answer_start': 63}], [{'text': '‘코드 감사’', 'answer_start': 463}, {'text': '코드 감사', 'answer_start': 464}], [{'text': '정우택 충북지사', 'answer_start': 674}, {'text': '정우택', 'answer_start': 674}], [{'text': '2015년 초', 'answer_start': 220}, {'text': '2015년', 'answer_start': 220}], [{'text': '휘주상인', 'answer_start': 397}], [{'text': '9개', 'answer_start': 564}, {'text': '9', 'answer_start': 564}], [{'text': '국회의 비준동의', 'answer_start': 471}], [{'text': '이경훈', 'answer_start': 376}], [{'text': '이상호', 'answer_start': 8}], [{'text': '이라크', 'answer_start': 266}], [{'text': '총 3925가구', 'answer_start': 224}, {'text': '3925가구', 'answer_start': 226}, {'text': '3925', 'answer_start': 226}], [{'text': '\"배낭의 남자\"', 'answer_start': 384}, {'text': '배낭의 남자', 'answer_start': 385}], [{'text': '공개 키 암호 방식(public key) 토큰', 'answer_start': 258}, {'text': '공개 열쇠 암호 토큰', 'answer_start': 331}], [{'text': 'SK텔레콤', 'answer_start': 96}, {'text': 'SK', 'answer_start': 124}], [{'text': '프린스턴', 'answer_start': 89}, {'text': '프린스턴대', 'answer_start': 89}], [{'text': '통의동', 'answer_start': 121}], [{'text': '갤럭시S4', 'answer_start': 952}], [{'text': '가지안테프', 'answer_start': 6}], [{'text': '티무르 왕조', 'answer_start': 273}], [{'text': '김용태', 'answer_start': 578}], [{'text': '베이다황그룹', 'answer_start': 379}], [{'text': '1053', 'answer_start': 166}], [{'text': '9월', 'answer_start': 106}], [{'text': '2.9%', 'answer_start': 137}], [{'text': '1944년', 'answer_start': 582}, {'text': '1944', 'answer_start': 582}], [{'text': '1945년 11월 11일', 'answer_start': 61}], [{'text': '이희국', 'answer_start': 98}], [{'text': '부리', 'answer_start': 188}], [{'text': '인종주의', 'answer_start': 639}], [{'text': '다산 정약용', 'answer_start': 296}, {'text': '정약용', 'answer_start': 299}], [{'text': '세션Ⅰ', 'answer_start': 405}, {'text': 'Ⅰ', 'answer_start': 407}], [{'text': '4731억원', 'answer_start': 259}], [{'text': '박민식', 'answer_start': 202}], [{'text': '‘비츠(Biits)’', 'answer_start': 396}, {'text': '비츠(Biits)', 'answer_start': 397}, {'text': '비츠', 'answer_start': 397}, {'text': 'Biits', 'answer_start': 400}], [{'text': '‘수능 완성’', 'answer_start': 1652}, {'text': '수능 완성', 'answer_start': 1653}], [{'text': '센리 선', 'answer_start': 7}], [{'text': '원자력 발전', 'answer_start': 203}], [{'text': '웨어러블 스마트 디바이스', 'answer_start': 288}], [{'text': '현대삼호중공업', 'answer_start': 646}], [{'text': '고케닌', 'answer_start': 377}], [{'text': '식중독', 'answer_start': 599}], [{'text': '4위', 'answer_start': 1258}, {'text': '4', 'answer_start': 1258}], [{'text': '3년', 'answer_start': 116}], [{'text': 'iHQ', 'answer_start': 800}], [{'text': '충북 충주', 'answer_start': 17}], [{'text': '50%', 'answer_start': 311}], [{'text': '순수 그리스인', 'answer_start': 118}], [{'text': '3개', 'answer_start': 599}, {'text': '3개 등급', 'answer_start': 599}, {'text': '3', 'answer_start': 599}], [{'text': '‘그림자 금융’', 'answer_start': 569}, {'text': '그림자 금융', 'answer_start': 570}], [{'text': '연꽃잎', 'answer_start': 450}], [{'text': '주벌 얼리 장군', 'answer_start': 1128}, {'text': '주벌 얼리', 'answer_start': 1128}], [{'text': '160만명', 'answer_start': 312}, {'text': '160만', 'answer_start': 312}], [{'text': '사영기업', 'answer_start': 954}], [{'text': '‘서비스드 레지던스’', 'answer_start': 323}, {'text': '서비스드 레지던스', 'answer_start': 324}], [{'text': '64.6%', 'answer_start': 446}, {'text': '64.6', 'answer_start': 446}], [{'text': '18일', 'answer_start': 20}, {'text': '18', 'answer_start': 20}], [{'text': '러시아', 'answer_start': 229}], [{'text': '미국', 'answer_start': 857}], [{'text': '휴온스', 'answer_start': 742}], [{'text': '샤를 기욤 르 노르망 데티올', 'answer_start': 369}], [{'text': '스위스', 'answer_start': 1934}], [{'text': '6조8631억원', 'answer_start': 617}], [{'text': '직각자자리 은하단', 'answer_start': 98}, {'text': '우리은하에서 약 2억 5000만 광년 떨어진 거대 은하 집합체', 'answer_start': 113}, {'text': '약 2억 5000만 광년 떨어진 거대 은하 집합체', 'answer_start': 120}, {'text': '2억 5000만 광년 떨어진 거대 은하 집합체', 'answer_start': 122}, {'text': '거대 은하 집합체', 'answer_start': 138}], [{'text': '이방 그리스도 교인', 'answer_start': 66}], [{'text': '1974년', 'answer_start': 400}, {'text': '1974', 'answer_start': 400}], [{'text': '라미스테카', 'answer_start': 136}], [{'text': '대우건설', 'answer_start': 112}], [{'text': '관광진흥법', 'answer_start': 379}], [{'text': '핀란드 헬싱키', 'answer_start': 6}, {'text': '핀란드', 'answer_start': 6}, {'text': '헬싱키', 'answer_start': 10}], [{'text': '독일 행정부', 'answer_start': 252}, {'text': '행정부', 'answer_start': 255}], [{'text': '8500만원', 'answer_start': 481}], [{'text': '양성윤', 'answer_start': 73}], [{'text': '미국', 'answer_start': 233}], [{'text': '5억 년', 'answer_start': 599}, {'text': '5억', 'answer_start': 599}], [{'text': '2008년', 'answer_start': 366}, {'text': '2008', 'answer_start': 366}], [{'text': '4.6%', 'answer_start': 461}], [{'text': '박수현', 'answer_start': 504}], [{'text': '2013년', 'answer_start': 428}], [{'text': '182만2601CGT', 'answer_start': 1160}], [{'text': '픽톨로지', 'answer_start': 24}, {'text': '픽톨로지(PICTOLOGI)', 'answer_start': 24}, {'text': '(PICTOLOGI)', 'answer_start': 28}, {'text': 'PICTOLOGI', 'answer_start': 29}], [{'text': '감', 'answer_start': 207}], [{'text': '‘BlueStacks Inside for Steam’', 'answer_start': 570}, {'text': 'BlueStacks Inside for Steam', 'answer_start': 571}], [{'text': '고준석', 'answer_start': 166}], [{'text': '최영익', 'answer_start': 249}], [{'text': '6명', 'answer_start': 623}, {'text': '6', 'answer_start': 623}], [{'text': '카카오 간편 결제 서비스', 'answer_start': 447}], [{'text': '갈라바 성', 'answer_start': 493}], [{'text': '10.8%', 'answer_start': 464}, {'text': '10.8', 'answer_start': 464}], [{'text': '러시아', 'answer_start': 395}], [{'text': '현대자동차그룹', 'answer_start': 519}], [{'text': '골든 리트리버', 'answer_start': 90}], [{'text': '문자', 'answer_start': 776}], [{'text': '펀드별 장기 누적 수익률', 'answer_start': 321}], [{'text': '아랍에미리트(UAE) 수의진단센터', 'answer_start': 727}], [{'text': '칼 레빈', 'answer_start': 291}, {'text': '레빈', 'answer_start': 857}], [{'text': '삼성전자', 'answer_start': 1214}], [{'text': '1045년', 'answer_start': 601}], [{'text': '캐나다', 'answer_start': 51}], [{'text': '100%', 'answer_start': 303}], [{'text': '기아자동차', 'answer_start': 324}, {'text': '기아차', 'answer_start': 420}], [{'text': '외부의 공적기관', 'answer_start': 603}, {'text': '공적기관', 'answer_start': 607}], [{'text': '연기', 'answer_start': 179}], [{'text': '굵은 바늘', 'answer_start': 16}], [{'text': '군의(軍毅)', 'answer_start': 703}, {'text': '군의', 'answer_start': 703}, {'text': '軍毅', 'answer_start': 706}], [{'text': '잠재성장률', 'answer_start': 118}], [{'text': '며느리', 'answer_start': 889}], [{'text': 'DCF-PYL', 'answer_start': 477}], [{'text': '나가시노 전투', 'answer_start': 319}], [{'text': '국제전기전자기술인협회 유럽 안테나 앤드 프로퍼게이션 컨퍼런스', 'answer_start': 486}, {'text': '국제전기전자기술인협회 유럽 안테나 앤드 프로퍼게이션 컨퍼런스 (IEEE European Conference on Antennas and Propagation, EuCAP 2020)', 'answer_start': 486}, {'text': '(IEEE European Conference on Antennas and Propagation, EuCAP 2020)', 'answer_start': 520}, {'text': 'IEEE European Conference on Antennas and Propagation, EuCAP 2020', 'answer_start': 521}], [{'text': 'LG유플러스', 'answer_start': 360}], [{'text': '크리스토퍼 기스트', 'answer_start': 524}], [{'text': '22일', 'answer_start': 90}], [{'text': '엔지니어', 'answer_start': 1124}], [{'text': '전북 정읍', 'answer_start': 249}, {'text': '전북', 'answer_start': 249}, {'text': '정읍', 'answer_start': 252}], [{'text': '‘2017년 이후’', 'answer_start': 457}, {'text': '2017년 이후', 'answer_start': 458}], [{'text': '2019년 12월 31일', 'answer_start': 88}], [{'text': '77%', 'answer_start': 181}], [{'text': '11명', 'answer_start': 123}, {'text': '11', 'answer_start': 123}], [{'text': '네이버', 'answer_start': 0}], [{'text': '23개', 'answer_start': 519}, {'text': '23', 'answer_start': 519}], [{'text': '평택성모병원', 'answer_start': 339}], [{'text': '이곤', 'answer_start': 120}], [{'text': '현장 면접', 'answer_start': 867}], [{'text': '보신주의', 'answer_start': 687}], [{'text': '9호선', 'answer_start': 242}], [{'text': '4개', 'answer_start': 1076}, {'text': '4', 'answer_start': 1076}], [{'text': '베르디', 'answer_start': 120}], [{'text': '18일', 'answer_start': 13}, {'text': '18', 'answer_start': 13}], [{'text': '중형 일개미들이 가져온 잎', 'answer_start': 450}, {'text': '일개미들이 가져온 잎', 'answer_start': 453}], [{'text': '벨라암', 'answer_start': 516}], [{'text': '4년', 'answer_start': 358}, {'text': '4', 'answer_start': 358}], [{'text': '1순위', 'answer_start': 197}, {'text': '1', 'answer_start': 197}], [{'text': '웨스트민스터 궁', 'answer_start': 417}], [{'text': '홍준표', 'answer_start': 523}], [{'text': '게즈어', 'answer_start': 1623}], [{'text': '벤더', 'answer_start': 203}], [{'text': '공산당', 'answer_start': 253}], [{'text': '과태료', 'answer_start': 316}], [{'text': '신세계백화점', 'answer_start': 0}, {'text': '신세계', 'answer_start': 0}], [{'text': '독일', 'answer_start': 270}], [{'text': '최근의 반도의 경제사범 \\xad국민의 신경제 윤리의 파악을 위하여\\xad', 'answer_start': 318}], [{'text': '30%', 'answer_start': 738}], [{'text': '영어', 'answer_start': 368}], [{'text': '고구려', 'answer_start': 208}], [{'text': '아시아', 'answer_start': 988}], [{'text': '라이헨바르 전투', 'answer_start': 665}], [{'text': '391', 'answer_start': 352}, {'text': '391명', 'answer_start': 352}], [{'text': '‘내일은 미스터트롯’ 우승', 'answer_start': 429}], [{'text': '140억원', 'answer_start': 288}], [{'text': '부산', 'answer_start': 316}], [{'text': '김주현', 'answer_start': 624}], [{'text': '《라쇼몽》', 'answer_start': 464}, {'text': '라쇼몽', 'answer_start': 465}], [{'text': '‘유니티 개발자의 날’', 'answer_start': 1069}, {'text': '유니티 개발자의 날', 'answer_start': 1070}], [{'text': '60%', 'answer_start': 367}, {'text': '60', 'answer_start': 367}], [{'text': '한국', 'answer_start': 1584}], [{'text': '화재', 'answer_start': 461}, {'text': '화재로 인한 사망자가 많았기 때문에', 'answer_start': 461}, {'text': '화재로 인한 사망자가 많았기 때문', 'answer_start': 461}], [{'text': '562가구', 'answer_start': 399}, {'text': '562', 'answer_start': 399}], [{'text': '지장보살', 'answer_start': 231}], [{'text': '개선사례', 'answer_start': 149}], [{'text': '에르빈 롬멜', 'answer_start': 380}, {'text': '롬멜', 'answer_start': 384}], [{'text': '로젠이사', 'answer_start': 910}], [{'text': '리비우스', 'answer_start': 54}], [{'text': '레이쥔 최고경영자(CEO)', 'answer_start': 91}, {'text': '레이쥔 최고경영자', 'answer_start': 91}, {'text': '레이쥔', 'answer_start': 91}], [{'text': '자문 분야', 'answer_start': 346}, {'text': '자문', 'answer_start': 346}], [{'text': '엠넷의 공개 오디션 프로그램 슈퍼스타K 2', 'answer_start': 80}, {'text': '엠넷의 공개 오디션 프로그램', 'answer_start': 80}, {'text': '슈퍼스타K 2', 'answer_start': 96}, {'text': '슈퍼스타K', 'answer_start': 96}], [{'text': '국민연금', 'answer_start': 460}], [{'text': '5.7%', 'answer_start': 217}, {'text': '5.7', 'answer_start': 217}], [{'text': '25%', 'answer_start': 939}, {'text': '25', 'answer_start': 939}], [{'text': '경상남도에서 출토되었다는 점', 'answer_start': 627}], [{'text': '아오모리현', 'answer_start': 546}], [{'text': '16%', 'answer_start': 209}, {'text': '16', 'answer_start': 209}], [{'text': '전동기', 'answer_start': 224}], [{'text': '1억원', 'answer_start': 401}], [{'text': '일본정책투자은행(DBJ) 캐피털 디렉터(총괄부장)', 'answer_start': 1061}, {'text': '캐피털 디렉터(총괄부장)', 'answer_start': 1075}, {'text': '총괄부장', 'answer_start': 1083}], [{'text': '전용갑 부사장', 'answer_start': 228}, {'text': '전용갑', 'answer_start': 228}], [{'text': '부산', 'answer_start': 542}], [{'text': '미국', 'answer_start': 177}], [{'text': 'B급 영화', 'answer_start': 96}, {'text': '영화', 'answer_start': 99}], [{'text': '스마트 크루즈 컨트롤', 'answer_start': 160}, {'text': '스마트 크루즈 컨트롤(SCC)', 'answer_start': 160}, {'text': 'SCC', 'answer_start': 390}], [{'text': '지난달 30일', 'answer_start': 98}, {'text': '30일', 'answer_start': 102}], [{'text': '‘EMS’', 'answer_start': 190}, {'text': 'EMS', 'answer_start': 191}], [{'text': '중소 프랜차이즈', 'answer_start': 22}], [{'text': '위안화', 'answer_start': 705}], [{'text': '1946년', 'answer_start': 252}, {'text': '1946', 'answer_start': 252}], [{'text': '금호산업', 'answer_start': 569}], [{'text': '조선총독부', 'answer_start': 123}], [{'text': '에지캐피털', 'answer_start': 563}], [{'text': '트로츠키', 'answer_start': 859}], [{'text': '숲과나눔 강당', 'answer_start': 77}, {'text': '강당', 'answer_start': 82}], [{'text': '2009년', 'answer_start': 976}], [{'text': '프랑스', 'answer_start': 128}], [{'text': '재발 위험', 'answer_start': 108}], [{'text': '11개', 'answer_start': 979}, {'text': '11', 'answer_start': 979}, {'text': '1', 'answer_start': 1704}], [{'text': '두 명', 'answer_start': 359}], [{'text': '수학적 귀납법', 'answer_start': 706}, {'text': '귀납법', 'answer_start': 710}], [{'text': '1937년', 'answer_start': 590}, {'text': '1937', 'answer_start': 590}], [{'text': '이명박', 'answer_start': 312}], [{'text': '카메라', 'answer_start': 490}], [{'text': '오는 27일', 'answer_start': 392}, {'text': '27일', 'answer_start': 395}], [{'text': '말', 'answer_start': 490}], [{'text': '임영록 KB금융지주 회장', 'answer_start': 20}, {'text': '임영록', 'answer_start': 20}, {'text': '임영록 KB금융지주 회장 내정자', 'answer_start': 20}, {'text': '임 내정자', 'answer_start': 225}], [{'text': '미국 중앙은행(Fed)의 양적완화 규모 축소', 'answer_start': 140}], [{'text': '4', 'answer_start': 845}, {'text': '4월', 'answer_start': 845}], [{'text': '도봉구', 'answer_start': 374}], [{'text': '경영진단 컨설팅', 'answer_start': 693}], [{'text': '1978년', 'answer_start': 855}, {'text': '1978', 'answer_start': 855}], [{'text': '1792년', 'answer_start': 115}, {'text': '1792', 'answer_start': 115}], [{'text': '노이즈 캔슬링', 'answer_start': 136}], [{'text': '1996년', 'answer_start': 430}], [{'text': '한국프레스센터', 'answer_start': 46}], [{'text': '‘컴투스프로야구2021’', 'answer_start': 563}, {'text': '컴투스프로야구2021', 'answer_start': 564}], [{'text': '1977년', 'answer_start': 361}], [{'text': '인터넷TV(IPTV)', 'answer_start': 108}, {'text': '인터넷TV', 'answer_start': 108}, {'text': 'IPTV', 'answer_start': 114}], [{'text': '사회 비판', 'answer_start': 298}], [{'text': '야당', 'answer_start': 384}, {'text': '공화당', 'answer_start': 388}], [{'text': '85층', 'answer_start': 287}], [{'text': '미래에셋생명', 'answer_start': 441}], [{'text': '16일', 'answer_start': 48}], [{'text': '항공모함', 'answer_start': 529}], [{'text': '7월 6일', 'answer_start': 289}], [{'text': '파키스탄', 'answer_start': 190}], [{'text': '스히폴 국제공항', 'answer_start': 15}], [{'text': '금융투자협회', 'answer_start': 541}], [{'text': '광주전남혁신도시', 'answer_start': 272}], [{'text': '보험 상품', 'answer_start': 1071}, {'text': '보험', 'answer_start': 1071}], [{'text': '5000억원', 'answer_start': 370}], [{'text': '빌트루디스', 'answer_start': 819}], [{'text': '고리키 공장', 'answer_start': 281}], [{'text': '‘세인트헤이븐 가이드 퀘스트’', 'answer_start': 311}, {'text': '세인트헤이븐 가이드 퀘스트', 'answer_start': 312}], [{'text': '《예루살렘의 아이히만》', 'answer_start': 582}, {'text': '예루살렘의 아이히만', 'answer_start': 583}], [{'text': '8월 29일', 'answer_start': 540}], [{'text': '0.4%', 'answer_start': 233}], [{'text': '이틀', 'answer_start': 641}], [{'text': '5만', 'answer_start': 356}, {'text': '5만개', 'answer_start': 356}], [{'text': '1920년', 'answer_start': 116}], [{'text': '약 2098억달러', 'answer_start': 188}], [{'text': '안톤 실루아노프', 'answer_start': 588}, {'text': '안톤 실루아노프 재무장관', 'answer_start': 588}, {'text': '안톤', 'answer_start': 588}, {'text': '실루아노프 재무장관', 'answer_start': 591}, {'text': '실루아노프', 'answer_start': 591}], [{'text': '5건', 'answer_start': 439}, {'text': '5', 'answer_start': 439}], [{'text': '오는 13일', 'answer_start': 967}, {'text': '13일', 'answer_start': 970}], [{'text': '프라이스에이리어', 'answer_start': 902}], [{'text': '5000만원', 'answer_start': 342}], [{'text': '폴', 'answer_start': 914}], [{'text': '캄보디아인민당(CPP)', 'answer_start': 215}], [{'text': '박종복', 'answer_start': 963}], [{'text': '34년', 'answer_start': 274}, {'text': '34', 'answer_start': 274}], [{'text': '도쿄', 'answer_start': 376}], [{'text': '한국', 'answer_start': 750}], [{'text': '5만원권', 'answer_start': 360}, {'text': '5만원', 'answer_start': 360}], [{'text': '교육부', 'answer_start': 596}], [{'text': '과일 등 농산물', 'answer_start': 276}, {'text': '농산물', 'answer_start': 281}], [{'text': '슈베르트', 'answer_start': 714}], [{'text': '22개', 'answer_start': 1105}, {'text': '22', 'answer_start': 1105}], [{'text': '모든 관직을 거친 대과 급제자', 'answer_start': 174}], [{'text': '12만원+1500만원 초과액의 0.14%', 'answer_start': 343}], [{'text': '지난해 2학기', 'answer_start': 1325}], [{'text': '시·도지사 승인', 'answer_start': 396}], [{'text': '47개', 'answer_start': 577}, {'text': '47', 'answer_start': 577}], [{'text': '교육부', 'answer_start': 515}], [{'text': '‘해외가 낫다’', 'answer_start': 578}, {'text': '해외가 낫다', 'answer_start': 579}], [{'text': '기원전 제2천년기', 'answer_start': 11}], [{'text': '2억2200만원', 'answer_start': 139}], [{'text': '금속', 'answer_start': 498}], [{'text': '사장', 'answer_start': 538}], [{'text': '경기 김포 한강신도시', 'answer_start': 38}, {'text': '김포 한강신도시', 'answer_start': 41}, {'text': '한강신도시', 'answer_start': 44}], [{'text': '11개', 'answer_start': 615}, {'text': '11', 'answer_start': 615}], [{'text': '중국', 'answer_start': 240}], [{'text': '선친의 산소', 'answer_start': 122}], [{'text': '일본', 'answer_start': 554}], [{'text': '강호갑', 'answer_start': 13}], [{'text': '파비아', 'answer_start': 110}], [{'text': '12년', 'answer_start': 146}, {'text': '12년 만', 'answer_start': 146}], [{'text': '바닷물', 'answer_start': 246}], [{'text': '스콧 케이스 스타트업아메리카 최고경영자(CEO)', 'answer_start': 37}, {'text': '스콧 케이스', 'answer_start': 37}, {'text': '케이스 CEO', 'answer_start': 233}, {'text': '케이스', 'answer_start': 233}], [{'text': '6개', 'answer_start': 572}, {'text': '6', 'answer_start': 572}], [{'text': '노령연금', 'answer_start': 226}, {'text': '기초노령연금', 'answer_start': 585}], [{'text': '1A ~ 5A', 'answer_start': 97}], [{'text': '스키', 'answer_start': 307}], [{'text': '70%', 'answer_start': 645}], [{'text': '제수씨', 'answer_start': 307}], [{'text': '한샘', 'answer_start': 106}], [{'text': '사츠키', 'answer_start': 516}], [{'text': '서울 그랜드인터컨티넨탈호텔 그랜드볼룸', 'answer_start': 68}, {'text': '서울 그랜드인터컨티넨탈호텔', 'answer_start': 68}, {'text': '그랜드인터컨티넨탈호텔 그랜드볼룸', 'answer_start': 71}, {'text': '그랜드인터컨티넨탈호텔', 'answer_start': 71}, {'text': '그랜드볼룸', 'answer_start': 83}], [{'text': '미국 휴스턴', 'answer_start': 136}, {'text': '휴스턴', 'answer_start': 139}], [{'text': 'CPU 시간', 'answer_start': 137}], [{'text': '세월호 참사', 'answer_start': 222}], [{'text': '1984년', 'answer_start': 666}], [{'text': '에너지법 제4조 5항', 'answer_start': 393}], [{'text': '허나라', 'answer_start': 911}], [{'text': '이홍균', 'answer_start': 413}], [{'text': '629년', 'answer_start': 0}], [{'text': '1752년', 'answer_start': 1414}], [{'text': '알리페이', 'answer_start': 186}], [{'text': '17일', 'answer_start': 622}], [{'text': '34층', 'answer_start': 530}, {'text': '34', 'answer_start': 530}], [{'text': '‘쉐취팡(學區房)’', 'answer_start': 681}, {'text': '쉐취팡', 'answer_start': 682}, {'text': '쉐취팡(學區房)', 'answer_start': 682}, {'text': '學區房', 'answer_start': 686}], [{'text': '‘신안인스빌 리베라2차’', 'answer_start': 360}, {'text': '신안인스빌 리베라2차', 'answer_start': 361}], [{'text': '잉그보르그 벵츠도터', 'answer_start': 71}], [{'text': '핸드볼', 'answer_start': 47}], [{'text': '김원겸', 'answer_start': 371}], [{'text': '미국', 'answer_start': 246}], [{'text': '김경숙', 'answer_start': 402}], [{'text': '독일', 'answer_start': 105}], [{'text': '한국', 'answer_start': 876}], [{'text': '김서룡', 'answer_start': 971}], [{'text': '서울 삼성동', 'answer_start': 194}, {'text': '삼성동', 'answer_start': 197}], [{'text': '뉴턴', 'answer_start': 290}], [{'text': '한국외국어대', 'answer_start': 65}], [{'text': '제일모직', 'answer_start': 73}], [{'text': '이사회', 'answer_start': 245}], [{'text': '김진호 사장', 'answer_start': 249}, {'text': '최고경영자(CEO)', 'answer_start': 309}, {'text': '최고경영자', 'answer_start': 309}, {'text': 'CEO', 'answer_start': 315}, {'text': '김 사장', 'answer_start': 405}], [{'text': '아프리카', 'answer_start': 992}], [{'text': '실버종합물류', 'answer_start': 405}], [{'text': '경기 과천', 'answer_start': 355}, {'text': '과천', 'answer_start': 358}], [{'text': '‘오페라의 유령’', 'answer_start': 20}, {'text': '오페라의 유령', 'answer_start': 21}], [{'text': '21', 'answer_start': 5}, {'text': '21일', 'answer_start': 5}], [{'text': '6억7500만원', 'answer_start': 278}], [{'text': '광공업생산', 'answer_start': 129}], [{'text': '프란츠 (프란체스코)', 'answer_start': 129}, {'text': '프란츠', 'answer_start': 129}, {'text': '프란체스코', 'answer_start': 134}], [{'text': '대법관', 'answer_start': 29}], [{'text': '업무 집행', 'answer_start': 417}, {'text': '집행', 'answer_start': 420}, {'text': '집행 기능', 'answer_start': 486}], [{'text': '첸나이', 'answer_start': 349}], [{'text': '신라 경문왕', 'answer_start': 618}, {'text': '경문왕', 'answer_start': 621}], [{'text': '8곳', 'answer_start': 141}, {'text': '8', 'answer_start': 141}], [{'text': '‘초서’', 'answer_start': 142}, {'text': '초서', 'answer_start': 143}], [{'text': '36%', 'answer_start': 506}, {'text': '36', 'answer_start': 506}], [{'text': '전체 산업생산', 'answer_start': 546}], [{'text': '오니기리', 'answer_start': 164}], [{'text': '소리바다 주식', 'answer_start': 193}, {'text': '소리바다', 'answer_start': 193}], [{'text': '한전', 'answer_start': 421}], [{'text': '창', 'answer_start': 143}], [{'text': '윌리엄 S. 하니 준장', 'answer_start': 10}, {'text': '윌리엄 S. 하니', 'answer_start': 10}], [{'text': '개봉작이란 타이틀을 얻기 위해서다', 'answer_start': 1119}, {'text': '개봉작이란 타이틀을 얻기 위해서', 'answer_start': 1119}, {'text': '개봉작이란 타이틀을 얻기 위해', 'answer_start': 1119}], [{'text': '서구 기독교 국가들', 'answer_start': 151}, {'text': '서구 기독교 국가', 'answer_start': 151}], [{'text': '3956억달러', 'answer_start': 1427}], [{'text': '니콜라 1세 왕실기', 'answer_start': 128}], [{'text': '남원 진기리 느티나무', 'answer_start': 537}], [{'text': '뇌일혈', 'answer_start': 679}], [{'text': '2608㎡', 'answer_start': 250}, {'text': '2608', 'answer_start': 250}], [{'text': '8명', 'answer_start': 453}, {'text': '8', 'answer_start': 453}], [{'text': '이상백', 'answer_start': 334}], [{'text': '적외선 복사 현상', 'answer_start': 220}], [{'text': '김 변호사', 'answer_start': 186}], [{'text': '1979년', 'answer_start': 527}, {'text': '1979', 'answer_start': 527}], [{'text': '쉐보레HHR', 'answer_start': 811}], [{'text': '미국 주재 조선일보', 'answer_start': 172}, {'text': '조선일보', 'answer_start': 178}], [{'text': '현삼과', 'answer_start': 560}], [{'text': '유방암의 진단', 'answer_start': 185}], [{'text': '마르쿠스 안토니우스', 'answer_start': 76}], [{'text': '2월 초', 'answer_start': 578}], [{'text': '2015년', 'answer_start': 370}, {'text': '2015', 'answer_start': 370}], [{'text': '정오', 'answer_start': 59}], [{'text': '5일', 'answer_start': 124}, {'text': '5', 'answer_start': 124}], [{'text': '젠하이저(Sennheiser)', 'answer_start': 1278}, {'text': '젠하이저', 'answer_start': 1278}, {'text': 'Sennheiser', 'answer_start': 1283}], [{'text': '특별법', 'answer_start': 733}, {'text': '특별법(일명 원샷법)', 'answer_start': 733}, {'text': '원샷법', 'answer_start': 740}], [{'text': '베링', 'answer_start': 695}], [{'text': '‘와팝(WAPOP)’', 'answer_start': 200}, {'text': '와팝', 'answer_start': 201}, {'text': '와팝(WAPOP)', 'answer_start': 201}, {'text': 'WAPOP', 'answer_start': 204}], [{'text': '《무정》', 'answer_start': 298}, {'text': '무정', 'answer_start': 299}], [{'text': '3.5%', 'answer_start': 184}], [{'text': '2015년', 'answer_start': 515}], [{'text': '‘모란문표형주전자’', 'answer_start': 64}, {'text': '모란문표형주전자', 'answer_start': 65}], [{'text': '91 cm 구경의 굴절망원경', 'answer_start': 42}, {'text': '굴절망원경', 'answer_start': 52}], [{'text': '박 대통령 사열', 'answer_start': 504}], [{'text': '10월', 'answer_start': 411}], [{'text': '상업용 부동산 개발', 'answer_start': 534}, {'text': '상업용 부동산', 'answer_start': 534}], [{'text': '2011년', 'answer_start': 187}, {'text': '2011', 'answer_start': 187}], [{'text': '해조류', 'answer_start': 495}, {'text': '해조류 성분', 'answer_start': 495}], [{'text': '아야스디', 'answer_start': 580}], [{'text': '갈색세포종', 'answer_start': 57}], [{'text': '2000만원', 'answer_start': 192}, {'text': '2000만원', 'answer_start': 1479}], [{'text': '오후 2시', 'answer_start': 226}], [{'text': '서천화력발전 2호기', 'answer_start': 237}], [{'text': '마늘 재고', 'answer_start': 482}, {'text': '재고', 'answer_start': 485}], [{'text': '지방세분석과장', 'answer_start': 338}], [{'text': 'Unity 2020.2', 'answer_start': 684}], [{'text': '전북 군산', 'answer_start': 131}, {'text': '군산', 'answer_start': 134}], [{'text': '게오르크 벨(Georg Bell)', 'answer_start': 530}, {'text': '게오르크 벨', 'answer_start': 530}, {'text': 'Georg Bell', 'answer_start': 537}], [{'text': '박혜윤', 'answer_start': 913}], [{'text': '약 2% 정도', 'answer_start': 73}, {'text': '약 2%', 'answer_start': 73}], [{'text': '구글', 'answer_start': 290}], [{'text': '80%', 'answer_start': 415}, {'text': '80', 'answer_start': 415}], [{'text': '국민은행', 'answer_start': 675}], [{'text': '2년 반', 'answer_start': 424}], [{'text': '몽골', 'answer_start': 66}], [{'text': '추기경', 'answer_start': 515}], [{'text': '손석현', 'answer_start': 258}], [{'text': '애덤 램버트', 'answer_start': 1118}], [{'text': '4.5%', 'answer_start': 69}], [{'text': '싱가포르 셸', 'answer_start': 872}], [{'text': '80%', 'answer_start': 898}], [{'text': '2011년', 'answer_start': 370}, {'text': '2011', 'answer_start': 370}], [{'text': '바레인', 'answer_start': 427}], [{'text': '뮤코펩티드', 'answer_start': 767}, {'text': '뮤코펩티드라는 화합물', 'answer_start': 767}], [{'text': '언더우드 박사 집', 'answer_start': 82}], [{'text': '시메온 1세', 'answer_start': 226}], [{'text': '시리아킬리키아 포에니케 (Syria-Cilicia Phoenice)', 'answer_start': 460}, {'text': '시리아킬리키아 포에니케', 'answer_start': 460}, {'text': 'Syria-Cilicia Phoenice', 'answer_start': 474}], [{'text': '창업진흥원·경기창조경제혁신센터', 'answer_start': 225}], [{'text': '국세공무원교육원', 'answer_start': 210}], [{'text': '‘잡포스팅 존(job posting zone)’', 'answer_start': 499}, {'text': '잡포스팅 존(job posting zone)', 'answer_start': 500}, {'text': '잡포스팅 존', 'answer_start': 500}, {'text': 'job posting zone', 'answer_start': 507}], [{'text': '‘가요(kayo)’', 'answer_start': 171}, {'text': '가요(kayo)', 'answer_start': 172}, {'text': '가요', 'answer_start': 172}, {'text': 'kayo', 'answer_start': 175}], [{'text': '9일', 'answer_start': 205}], [{'text': '자국 병사', 'answer_start': 681}], [{'text': '최종현', 'answer_start': 253}], [{'text': '제50화', 'answer_start': 272}, {'text': '제50화(최종화)', 'answer_start': 272}, {'text': '50', 'answer_start': 273}, {'text': '50화', 'answer_start': 273}, {'text': '최종화', 'answer_start': 277}], [{'text': '‘밀크’', 'answer_start': 930}, {'text': '밀크', 'answer_start': 931}], [{'text': '2조7000억달러', 'answer_start': 307}], [{'text': '5년', 'answer_start': 80}], [{'text': '3300억원', 'answer_start': 464}], [{'text': '장남인 한스', 'answer_start': 651}, {'text': '한스', 'answer_start': 655}], [{'text': '27일', 'answer_start': 452}], [{'text': '1603년', 'answer_start': 163}], [{'text': '미국', 'answer_start': 99}], [{'text': '프랑스', 'answer_start': 226}], [{'text': '절연체 재료', 'answer_start': 385}, {'text': '절연체', 'answer_start': 385}, {'text': '재료', 'answer_start': 389}, {'text': '원재료', 'answer_start': 478}], [{'text': '1.2%', 'answer_start': 116}], [{'text': '신춘문예공모전', 'answer_start': 382}], [{'text': '숭실대', 'answer_start': 756}, {'text': '숭실대 법학과', 'answer_start': 756}], [{'text': '일본', 'answer_start': 363}], [{'text': '신한일전기', 'answer_start': 42}], [{'text': '독일', 'answer_start': 658}], [{'text': '랄라웨티카', 'answer_start': 198}], [{'text': '삼성토탈', 'answer_start': 763}], [{'text': '33층', 'answer_start': 1505}, {'text': '33', 'answer_start': 1505}], [{'text': '미국 의과학학술지(BBRC)', 'answer_start': 278}, {'text': '미국 의과학학술지', 'answer_start': 278}, {'text': '미국 의과학학술지(BBRC) 11월호', 'answer_start': 278}, {'text': 'BBRC', 'answer_start': 288}], [{'text': '제러미 코빈', 'answer_start': 181}], [{'text': '65%', 'answer_start': 742}, {'text': '65', 'answer_start': 742}], [{'text': '12%', 'answer_start': 411}], [{'text': '밧지 공화국', 'answer_start': 58}, {'text': '밧지', 'answer_start': 58}], [{'text': '기획재정부', 'answer_start': 114}], [{'text': '영국', 'answer_start': 409}], [{'text': '미래창조과학부', 'answer_start': 371}], [{'text': 'MD', 'answer_start': 563}], [{'text': '6394만원', 'answer_start': 99}], [{'text': '오는 30일', 'answer_start': 171}, {'text': '30일', 'answer_start': 174}], [{'text': 'SK텔링크', 'answer_start': 108}], [{'text': '당대의 바빌로니아 기록들이 현재까지 별로 많이 남아있지 않기 때문', 'answer_start': 65}], [{'text': '국가자연사연구종합정보시스템', 'answer_start': 187}], [{'text': '정기영', 'answer_start': 228}], [{'text': '플라스틱보다 강도가 높기 때문에', 'answer_start': 1083}, {'text': '플라스틱보다 강도가 높기 때문', 'answer_start': 1083}], [{'text': '자녀가 부모를 모시고 10년 이상 함께 산 ‘동거 주택’을 상속받는 경우', 'answer_start': 343}], [{'text': '상용특허', 'answer_start': 559}], [{'text': '르로클', 'answer_start': 27}, {'text': '르로클(Le Locle)', 'answer_start': 27}, {'text': 'Le Locle', 'answer_start': 31}], [{'text': '서울 관악구', 'answer_start': 41}, {'text': '서울', 'answer_start': 41}, {'text': '관악구', 'answer_start': 44}], [{'text': '영국', 'answer_start': 0}], [{'text': '61.2%', 'answer_start': 512}], [{'text': '일본', 'answer_start': 774}], [{'text': '촘베', 'answer_start': 376}], [{'text': '최하부 지층', 'answer_start': 749}], [{'text': '나가모리 시게노부', 'answer_start': 90}], [{'text': '트레뻬제 부대', 'answer_start': 333}], [{'text': '5.8%', 'answer_start': 543}], [{'text': '사외 이사', 'answer_start': 651}, {'text': '사외이사', 'answer_start': 754}], [{'text': '독일', 'answer_start': 241}], [{'text': '보스', 'answer_start': 111}], [{'text': '‘아임에잇’', 'answer_start': 1401}, {'text': '아임에잇', 'answer_start': 1402}], [{'text': '‘집사광익(集思廣益)’', 'answer_start': 461}, {'text': '집사광익(集思廣益)', 'answer_start': 462}, {'text': '집사광익', 'answer_start': 462}, {'text': '集思廣益', 'answer_start': 467}], [{'text': '헤르만 폰 잘차', 'answer_start': 136}], [{'text': '지난 1월', 'answer_start': 539}], [{'text': '‘페인스크램블러’', 'answer_start': 1405}, {'text': '페인스크램블러', 'answer_start': 1406}], [{'text': '이승만', 'answer_start': 235}], [{'text': '오후 7시30분', 'answer_start': 874}], [{'text': '후군', 'answer_start': 67}], [{'text': '선착순', 'answer_start': 1211}], [{'text': '11곳', 'answer_start': 325}], [{'text': 'AIA생명보험', 'answer_start': 420}], [{'text': '‘드라이빙 마일리지제’', 'answer_start': 825}, {'text': '드라이빙 마일리지제', 'answer_start': 826}], [{'text': '2008년', 'answer_start': 213}], [{'text': '중형화물차', 'answer_start': 256}], [{'text': '교황 율리오 2세', 'answer_start': 285}, {'text': '율리오 2세', 'answer_start': 288}], [{'text': '26일', 'answer_start': 159}], [{'text': '300SPM', 'answer_start': 362}], [{'text': '시민과 동등한 세금 부담의 특권(이소테레이아)', 'answer_start': 408}, {'text': '시민과 동등한 세금 부담의 특권', 'answer_start': 408}, {'text': '이소테레이아', 'answer_start': 426}], [{'text': '포스카르네트', 'answer_start': 388}], [{'text': '경춘선 갈매역', 'answer_start': 318}, {'text': '갈매역', 'answer_start': 322}], [{'text': '2000년', 'answer_start': 483}, {'text': '2000', 'answer_start': 483}], [{'text': '적립식 재형저축', 'answer_start': 1230}, {'text': '재형저축', 'answer_start': 1234}], [{'text': '2016년', 'answer_start': 513}, {'text': '2016년', 'answer_start': 1543}], [{'text': '윌리 텔라비 총리', 'answer_start': 394}, {'text': '윌리 텔라비', 'answer_start': 394}], [{'text': '노엘 클라크', 'answer_start': 568}], [{'text': '53만3000t', 'answer_start': 739}], [{'text': '2010년', 'answer_start': 242}], [{'text': '성왕', 'answer_start': 432}], [{'text': '고영테크놀로지', 'answer_start': 256}], [{'text': '하나은행 분당중앙지점', 'answer_start': 720}], [{'text': '박용만', 'answer_start': 784}, {'text': '박용만 회장', 'answer_start': 784}], [{'text': '김현묵', 'answer_start': 403}], [{'text': '시스템반도체 사업', 'answer_start': 1373}], [{'text': '10년 이하', 'answer_start': 507}], [{'text': '오세정', 'answer_start': 348}], [{'text': '119,000원', 'answer_start': 420}], [{'text': '네오프톨레모스', 'answer_start': 655}], [{'text': '‘다다익선 할인’', 'answer_start': 486}, {'text': '다다익선 할인', 'answer_start': 487}], [{'text': '1만1662.52엔', 'answer_start': 922}], [{'text': '샐러드', 'answer_start': 556}], [{'text': '서울', 'answer_start': 369}], [{'text': 'LG상사', 'answer_start': 622}], [{'text': '205조5000억원', 'answer_start': 749}], [{'text': '31일', 'answer_start': 399}, {'text': '31', 'answer_start': 399}], [{'text': '한국', 'answer_start': 445}], [{'text': '1000억원', 'answer_start': 445}], [{'text': '지상에 가족이 없었기 때문', 'answer_start': 118}], [{'text': '55개', 'answer_start': 999}, {'text': '55', 'answer_start': 999}], [{'text': '일본', 'answer_start': 636}], [{'text': 'Monster Movie', 'answer_start': 899}], [{'text': '1986년', 'answer_start': 93}], [{'text': '현대백화점', 'answer_start': 203}], [{'text': '5개', 'answer_start': 201}, {'text': '5', 'answer_start': 201}], [{'text': '6년 반', 'answer_start': 581}], [{'text': '21년 상반기', 'answer_start': 207}], [{'text': '‘GR8’', 'answer_start': 431}, {'text': 'GR8', 'answer_start': 432}], [{'text': '실리콘', 'answer_start': 854}], [{'text': '1853년', 'answer_start': 910}, {'text': '1853', 'answer_start': 910}], [{'text': \"'메테오스의 탑'\", 'answer_start': 155}, {'text': '메테오스의 탑', 'answer_start': 156}], [{'text': '뮤지컬 팬들', 'answer_start': 376}], [{'text': '신민계', 'answer_start': 381}], [{'text': '성기사 카드 팩', 'answer_start': 1677}], [{'text': '영·유아', 'answer_start': 15}], [{'text': '호텔면세사업부', 'answer_start': 261}], [{'text': '300SPM', 'answer_start': 362}], [{'text': '수원화성행궁점', 'answer_start': 674}], [{'text': '김현웅', 'answer_start': 1136}], [{'text': '신소재사업단', 'answer_start': 657}], [{'text': '자누비아', 'answer_start': 500}], [{'text': '자유무역지역법', 'answer_start': 271}], [{'text': '1차면접', 'answer_start': 301}, {'text': '1차', 'answer_start': 301}, {'text': '1', 'answer_start': 301}], [{'text': '초월적인 존재(신)', 'answer_start': 64}, {'text': '초월적인 존재', 'answer_start': 64}, {'text': '(신)', 'answer_start': 71}, {'text': '신', 'answer_start': 72}], [{'text': '대한법률구조공단', 'answer_start': 89}], [{'text': '신학자 반디넬리', 'answer_start': 132}, {'text': '반디넬리', 'answer_start': 136}], [{'text': '나구모 주이치(南雲忠一) 중장', 'answer_start': 501}, {'text': '나구모 주이치', 'answer_start': 501}, {'text': '南雲忠一', 'answer_start': 509}], [{'text': '와츠', 'answer_start': 412}], [{'text': '민간', 'answer_start': 38}], [{'text': '2014년', 'answer_start': 348}, {'text': '2014', 'answer_start': 348}], [{'text': '러셀', 'answer_start': 519}], [{'text': '아웃도어&여행채널 ONT(오앤티)', 'answer_start': 759}, {'text': 'ONT(오앤티)', 'answer_start': 769}, {'text': 'ONT', 'answer_start': 769}, {'text': '오앤티', 'answer_start': 773}], [{'text': '12월', 'answer_start': 3}, {'text': '12', 'answer_start': 3}], [{'text': '공민왕', 'answer_start': 234}], [{'text': '광주교도소', 'answer_start': 534}], [{'text': '각종 수신(受信) 문서들', 'answer_start': 378}, {'text': '각종 수신(受信) 문서', 'answer_start': 378}, {'text': '수신(受信) 문서들', 'answer_start': 381}, {'text': '수신(受信) 문서', 'answer_start': 381}], [{'text': '‘인어왕자: 너를 만지다’', 'answer_start': 156}, {'text': '인어왕자: 너를 만지다', 'answer_start': 157}], [{'text': '하이랜더 연대', 'answer_start': 179}], [{'text': '김소유', 'answer_start': 3}], [{'text': '네빌 체임벌린', 'answer_start': 770}, {'text': '네빌 체임벌린 총리', 'answer_start': 770}], [{'text': '왕우', 'answer_start': 293}], [{'text': '세선각 기법', 'answer_start': 735}], [{'text': '중앙행정기관이 이전', 'answer_start': 453}], [{'text': '부천아이파크', 'answer_start': 108}], [{'text': '12명', 'answer_start': 1040}, {'text': '12', 'answer_start': 1040}], [{'text': '식후 졸림증', 'answer_start': 194}], [{'text': '지난해 7월', 'answer_start': 134}], [{'text': '군사 원조', 'answer_start': 318}], [{'text': '복합형 오피스텔', 'answer_start': 48}], [{'text': '임수정', 'answer_start': 268}], [{'text': '나영묵', 'answer_start': 193}, {'text': '나영묵 현대건설 상무', 'answer_start': 193}], [{'text': '4544가구', 'answer_start': 246}, {'text': '4544', 'answer_start': 246}], [{'text': '성남시청소년재단 중원청소년수련관', 'answer_start': 523}, {'text': '중원청소년수련관', 'answer_start': 532}], [{'text': '웨이퍼 두께', 'answer_start': 739}, {'text': '두께', 'answer_start': 743}], [{'text': '김영대', 'answer_start': 195}], [{'text': '이명박', 'answer_start': 600}], [{'text': '2월28일', 'answer_start': 422}, {'text': '28일', 'answer_start': 424}], [{'text': '손정의', 'answer_start': 169}], [{'text': '‘트로이의 목마’', 'answer_start': 659}, {'text': '트로이의 목마', 'answer_start': 660}], [{'text': '14개', 'answer_start': 357}, {'text': '14', 'answer_start': 357}], [{'text': '‘힐스테이트 영통’', 'answer_start': 462}, {'text': '힐스테이트 영통', 'answer_start': 463}], [{'text': '2004년의 국방부 보고서', 'answer_start': 167}], [{'text': '88%', 'answer_start': 318}, {'text': '88', 'answer_start': 318}], [{'text': '4월9일(수)', 'answer_start': 20}, {'text': '4월9일', 'answer_start': 20}], [{'text': '부여현감(扶餘縣監)', 'answer_start': 184}, {'text': '부여현감', 'answer_start': 184}, {'text': '扶餘縣監', 'answer_start': 189}], [{'text': '27년', 'answer_start': 119}], [{'text': '2008년', 'answer_start': 285}, {'text': '2008', 'answer_start': 285}], [{'text': '20일', 'answer_start': 1173}, {'text': '20', 'answer_start': 1173}], [{'text': '메그', 'answer_start': 158}], [{'text': '일본 전국시대', 'answer_start': 82}, {'text': '전국시대', 'answer_start': 85}], [{'text': '‘수요회’', 'answer_start': 536}, {'text': '수요회', 'answer_start': 537}], [{'text': '2000만원', 'answer_start': 460}], [{'text': '15명', 'answer_start': 107}, {'text': '15', 'answer_start': 107}], [{'text': '12월 24일', 'answer_start': 88}], [{'text': '5일', 'answer_start': 15}], [{'text': '터키 이스탄불', 'answer_start': 250}], [{'text': '25일', 'answer_start': 78}], [{'text': '구글', 'answer_start': 1072}], [{'text': '길피', 'answer_start': 1109}, {'text': '길피 (Kjartan Bjargmundsson)', 'answer_start': 1109}, {'text': 'Kjartan Bjargmundsson', 'answer_start': 1113}], [{'text': '12월 17일(목)', 'answer_start': 778}, {'text': '12월 17일', 'answer_start': 778}], [{'text': '‘원칙이 바로 선 시장경제 질서 확립’', 'answer_start': 369}, {'text': '원칙이 바로 선 시장경제 질서 확립', 'answer_start': 370}], [{'text': '조류인플루엔자', 'answer_start': 55}, {'text': '조류인플루엔자(AI)', 'answer_start': 55}, {'text': 'AI', 'answer_start': 63}], [{'text': '베를린', 'answer_start': 694}], [{'text': '306만1000대', 'answer_start': 131}], [{'text': '7억8100만명', 'answer_start': 741}, {'text': '7억8100만', 'answer_start': 741}], [{'text': '네이트 실버', 'answer_start': 857}], [{'text': '서초동', 'answer_start': 60}], [{'text': '992가구', 'answer_start': 903}, {'text': '992', 'answer_start': 903}], [{'text': 'TD-LTE', 'answer_start': 443}], [{'text': '로마 제국의 카를 5세', 'answer_start': 540}, {'text': '카를 5세', 'answer_start': 547}], [{'text': '‘교동반점 짬뽕’', 'answer_start': 408}, {'text': '교동반점 짬뽕', 'answer_start': 409}], [{'text': '1기', 'answer_start': 349}], [{'text': '12월 30일', 'answer_start': 1121}], [{'text': '2002년', 'answer_start': 711}, {'text': '2002', 'answer_start': 711}], [{'text': '마케팅', 'answer_start': 666}], [{'text': '콜럼버스', 'answer_start': 1263}], [{'text': '1949년 12월 경', 'answer_start': 923}, {'text': '1949년 12월', 'answer_start': 923}], [{'text': '파주', 'answer_start': 322}], [{'text': '문무일', 'answer_start': 329}], [{'text': '뛰어난 그립력', 'answer_start': 213}, {'text': '그립력', 'answer_start': 217}], [{'text': '주택경기 활성화 정책', 'answer_start': 391}], [{'text': '문경은', 'answer_start': 938}], [{'text': '‘디지털 쇼룸’', 'answer_start': 480}, {'text': '디지털 쇼룸', 'answer_start': 481}], [{'text': '파시즘', 'answer_start': 94}], [{'text': '마법', 'answer_start': 430}], [{'text': '지난해 4월', 'answer_start': 1045}, {'text': '지난해', 'answer_start': 1045}], [{'text': '9월 5일', 'answer_start': 758}], [{'text': '134만명', 'answer_start': 227}, {'text': '134만', 'answer_start': 227}], [{'text': '‘불가리’', 'answer_start': 502}, {'text': '불가리', 'answer_start': 503}], [{'text': '박은주', 'answer_start': 638}], [{'text': '김효재 전 청와대 정무수석', 'answer_start': 154}, {'text': '김효재', 'answer_start': 154}, {'text': '전 청와대 정무수석', 'answer_start': 158}], [{'text': '‘MMA 응원보드’ 이벤트', 'answer_start': 1023}, {'text': '‘MMA 응원보드’', 'answer_start': 1023}, {'text': 'MMA 응원보드', 'answer_start': 1024}], [{'text': '1753년', 'answer_start': 499}], [{'text': \"'사채회사'\", 'answer_start': 530}, {'text': '사채회사', 'answer_start': 531}], [{'text': '심야시간', 'answer_start': 155}], [{'text': '그레이슨 페리', 'answer_start': 426}], [{'text': '‘지오송지오’', 'answer_start': 276}, {'text': '지오송지오', 'answer_start': 277}], [{'text': '호주 맥쿼리', 'answer_start': 414}, {'text': '맥쿼리', 'answer_start': 417}], [{'text': '수직 안정체', 'answer_start': 707}], [{'text': '22.2%', 'answer_start': 208}], [{'text': '아버지', 'answer_start': 32}], [{'text': '11월 19일', 'answer_start': 409}], [{'text': '경기 안성경찰서', 'answer_start': 263}, {'text': '안성경찰서', 'answer_start': 266}], [{'text': '건강질의서', 'answer_start': 572}], [{'text': '원유 시추', 'answer_start': 248}], [{'text': '이해인', 'answer_start': 194}, {'text': '이해인 수녀', 'answer_start': 194}], [{'text': '천주교 수사', 'answer_start': 173}, {'text': '수사', 'answer_start': 177}], [{'text': '1413만원', 'answer_start': 75}], [{'text': '외곽순환도로', 'answer_start': 1175}], [{'text': '집정관', 'answer_start': 450}], [{'text': '김한길', 'answer_start': 13}], [{'text': '서울 궁정동', 'answer_start': 486}, {'text': '궁정동', 'answer_start': 489}], [{'text': '임상심리사', 'answer_start': 1134}], [{'text': '대우조선해양', 'answer_start': 107}], [{'text': '존 맥스웰', 'answer_start': 428}], [{'text': '11월', 'answer_start': 1344}], [{'text': '순천향대', 'answer_start': 361}], [{'text': '1,990만 원(세금 및 봉사료 포함)', 'answer_start': 663}, {'text': '1,990만 원', 'answer_start': 663}], [{'text': '96억5500만원', 'answer_start': 321}], [{'text': '단백질', 'answer_start': 707}], [{'text': '로린 마젤', 'answer_start': 1027}, {'text': '마젤', 'answer_start': 1102}], [{'text': '월머 해안', 'answer_start': 252}], [{'text': '21일', 'answer_start': 631}], [{'text': '4%', 'answer_start': 248}, {'text': '4', 'answer_start': 248}], [{'text': '2030년', 'answer_start': 161}, {'text': '2030', 'answer_start': 161}], [{'text': '250억원', 'answer_start': 350}], [{'text': '‘반값등록금’', 'answer_start': 481}, {'text': '반값등록금', 'answer_start': 482}], [{'text': '‘카이스트 AI 대학원’', 'answer_start': 508}, {'text': '카이스트 AI 대학원', 'answer_start': 754}], [{'text': '8조1823억원', 'answer_start': 173}], [{'text': '‘부루마블’', 'answer_start': 19}, {'text': '부루마블', 'answer_start': 20}], [{'text': '통합형', 'answer_start': 220}], [{'text': '5', 'answer_start': 323}, {'text': '5개', 'answer_start': 323}], [{'text': '1962년', 'answer_start': 0}, {'text': '1962', 'answer_start': 0}], [{'text': '고문', 'answer_start': 293}], [{'text': '4만5800원', 'answer_start': 721}], [{'text': '‘브릭오븐’', 'answer_start': 283}, {'text': '브릭오븐', 'answer_start': 284}], [{'text': '중국 후룬연구소', 'answer_start': 366}, {'text': '후룬연구소', 'answer_start': 369}], [{'text': '9만150마리', 'answer_start': 431}], [{'text': '변동', 'answer_start': 866}, {'text': '변동금리', 'answer_start': 866}], [{'text': '대우건설', 'answer_start': 220}], [{'text': '기아', 'answer_start': 197}], [{'text': '6일', 'answer_start': 276}, {'text': '6', 'answer_start': 276}, {'text': '6일(금)', 'answer_start': 276}], [{'text': 'E1', 'answer_start': 186}], [{'text': '언더우드(Underwood)박사', 'answer_start': 1262}, {'text': '언더우드', 'answer_start': 1262}, {'text': '언더우드(Underwood)', 'answer_start': 1262}, {'text': '(Underwood)', 'answer_start': 1266}, {'text': 'Underwood', 'answer_start': 1267}], [{'text': '도쿠시마대', 'answer_start': 699}, {'text': '도쿠시마', 'answer_start': 699}, {'text': '도쿠시마대 대학원', 'answer_start': 699}], [{'text': '10곳', 'answer_start': 251}, {'text': '10', 'answer_start': 251}], [{'text': '뒤쪽', 'answer_start': 162}], [{'text': '첸쉬안퉁', 'answer_start': 43}], [{'text': '1865년 1월 7일이후', 'answer_start': 334}], [{'text': '35%', 'answer_start': 873}]]\n",
            "1203\n",
            "['윤광진 교수가 연출한 연극이 앙코르 공연을 하는 장소는 어디인가?', '자체 신용평가시스템이 없는 저축은행은 어느 기관의 시스템을 따르는가?', '한 언어를 다른 언어로 번역하기 위해 필요하며, 의미론, 사전학, 화용론을 이해해야 하는 문법은?', '소비에트 연방이 수정주의를 도입한 해는?', '돈키호테의 하이라이트를 볼 수 있는 것은 몇 부인가?', '폴란드인의 과시욕을 만족시키지 못해 폴란드 시장에서 실패한 전자거래소는?', '이번 해에 증가될 국내 맥도날드 가맹점 수는?', 'MS에서 개발한 태블릿PC 이름은?', '의류의 사진을 찍고 업로드하면, 그 제품을 바로 찾아낼 수 있는 콘텐츠는?', '자동이체에 관한 소비자의 불편을 해소할 수 있게해 주는 것의 명칭은?', 'K씨가 면접에서 떨어진 공식 이유는?', '항암치료와 검사를 위해 정기적으로 한국에 오는 외국인의 이름은?', '동투르키스탄을 식민지로 삼아야 한다고 주장한 사람은?', '2년째 등록금이 동일한 지방대는?', '천경자 화백이 수상한 적이 있는 훈장은?', '염수정 추기경의 서임식이 있었던 날 함께 추기경이 된 사람의 수는?', '힐이 사관학교 병원에서 임질의 치료를 받은 때는 몇 월이었나요?', '정모씨(30)가 대포폰을 만들기 시작한 시기는?', '아르켈스텐 의원이 중도당의 수장으로 일했던 기간은?', '사용후핵연료 처리 방식 중 물질을 지상에서 보관하는 방식은 무엇인가?', '녹십자가 작년에 수출한 백신은 총 얼마치인가?', '삼양그룹이 세워진 날은 언제인가?', \"navigation'이 올라온 사이트는?\", '농가의 보험료 부담을 가장 많이 덜어 주는 기관은?', '총리의 건의로 해임된 첫 번째 장관은 누구인가?', '2011년, 한국에 진출한 매트리스 업체는?', '어떤 활동을 통해 군부대의 TV가 교체되었는가?', '창의력을 향상시키기 위해선 방을 무슨 색으로 도배해야하나?', '상품 9개를 선물받을 수 있는 올리브영 등급은?', '개정법이 통과되면 전체 아파트 중 98%가 취득세율이 1%로 감소하는 지역은?', '박근혜와 반기문이 만날 수 있는 회의는?', '대통령 표창을 받은 기업의 샘플 분석 가격은?', '앨리스에서 주원이 연기한 인물의 직업은?', '가장 먼저 영문 명칭이 수정되어야 하는 부처는 어디인가?', '광공업 생산이 전월보다 1.3% 증가한 달은 언제인가?', '요동도행군의 선발 기병부대 숫자는?', '조지 피켓의 여단을 지휘한 장교의 소식을 핸콕에게 전한 사람은 누구인가?', '진왕 정의 말을 전해 들은 후 제왕 건은 어떤 행동을 취할 것이라고 다짐하였나?', '씨티스케이프에 참여 예정인 한국 공기업 이름은?', \"레몬'의 뮤직비디오에서 손재원이 연기한 역할의 직업은?\", '지드래곤은 \"One Of A Kind\"로 얼마만에 솔로로 무대에 복귀하는가?', '샌프란시스코 소방국장에게 영웅이라고 칭송 받는 인물의 이름은?', '수행에 대해 근본적으로 의문을 제기함으로써 영적 수행자의 수행 의지를 갉아먹는 것은 무엇인가?', '마르시온이 노드 형제단을 배신한 후 결성한 단체는?', '교체되지 않는 검찰 내 고검장급은?', '루카치가 부다페스트 대학에 복귀한 이듬해 참석한 국제회의가 열린 도시는?', 'KTX광명역에서 5분 거리에 있는 아파트의 이름은?', '언제 이후로 투자은행들이 인재들의 고된 업무 강도를 보상해주지 못하게 되었나?', '전세계 억만장자들의 자선액 중 가장 큰 금액은 얼마인가?', '매출이, SNS에서 공유된 레시피로 인해 크게 오른 제품의 이름은?', '투명 경영을 강화하기 위해 SK그룹이 이사로 선임한 사람의 이름은?', '축구로써 회사생활을 극복했다고 언급한 인물의 이름은?', '남명혁 부인의 사망 당시 나이는?', '리모델링과 재건축을 비교하여 리모델링의 이점을 강조한 사람은?', '시미즈 건설이 기밀을 발설하여 공사에 대한 입찰을 하지 않았던 집단은?', '주식 전량 매각 시 가격이 높은 순으로 10개의 주식 중 유일하게 상승한 종목은?', '김홍석 작가가 베니스 비엔날레에 처음으로 작품을 출품한 연도는?', '병으로 인해 피렌체의 수많은 사람들이 죽어갔음을 언급한 사람은?', '<구해줘> 바로 이전에 출간된 책은?', '예측할 수 없는 대류의 움직임 때문에 발생하게 되는 것은?', \"화학적 거세'가 세계 최초로 실시된 나라는 어디인가?\", '여신전문업체들이 할부 금리를 속이고 취급수수료를 받아 내는 행위를 무엇이라 하는가?', '그 어느 때보다 의미 있는 공연이 될 것 같다는 인터뷰를 남긴 사람의 이름은?', '신체에 령주를 새긴 마술사는 몇 명인가?', '인허가 관련 결정에 관해 사후 감사를 실시하는 기관은?', '업그레이드에 대한 추가 비용을 받지 않는 이벤트는?', '고구려 연맹장들이 세력을 키우고 집권화하는 데 중요한 역할을 한 도구는?', \"삼성이 'CES 2014'에서 첫 선을 보이는 LFD의 사이즈는?\", '회사가 자사주를 많이 가진 경우 의결권 행사가 유리해지는 사람은?', '강제 수용소에 갔던 성직자들의 소속은?', '작년 예상했던 올해의 원래 경제성장률은?', '제12회 대통령배 아마추어 e스포츠대회’가 개최되는 날짜는?', '삼성물산과 제일모직의 합병에 반대하는 주주 중 가장 지분율이 높은 주주는?', '통진당을 해산시킨 결정을 인정한다고 직접 말한 인물은?', '강원랜드가 금품과 향응을 받아 해임된 임직원들에게 지급한 퇴직금은 총 얼마인가?', '네이버에게 게임 마케팅 플랫폼의 역할을 맡긴 회사는?', '원격의료와 삼성을 엮는 것을 비판한 사람의 이름은?', '대구시장이 광주시청에서 교환특강을 실시한 날짜는?', '부산 글로벌 MICE 포럼이 열린 장소는?', \"선배'가 선배 박람회 참가자를 뽑을 때 고려하는 것은?\", '전라북도가 방역초소를 더 만든 곳은?', '2009년 미얀마 전기생산량의 25배인 나라는?', '르네상스 시대에 세례대를 관리하던 곳의 명칭은?', '탑에 시멘트를 바른 것은 언제인가?', '리치몬드 발렌타인이 제작한 칩은 무엇을 파괴하기 위해 만들어졌나요?', '궁예가 석총을 살인할 때 사용한 무기는?', '기본 혜택 이외의 여러 혜택을 받기 위해서 아이폰 SE 이외에 추가적으로 사야하는 것은 무엇인가?', '블룸버그가 파악한 이번 년도 세계 시가총액 500대 기업에 중국 기업은 몇 개가 포함되어 있는가?', \"디지털 달러 프로젝트'를 운영하고 있는 사람의 이름은 무엇인가?\", '대통령 주치의로 처음 발탁된 연세대 의대 출신 의사의 이름은?', '관촉사 앞뜰의 4각 석등보다 큰 것은 무엇인가요?', '흥왕사명 청동은입사향완에서 갈대가 새겨진 부분은?', '제일모직은 어느 그룹도 합병하여 호텔과 수목원을 지을 계힉인가?', '해왕성 동기 궤도 안쪽에 있는 위성들을 무엇이라고 부르는가?', '혼다가 만든 SUV의 연비는?', '최고 60.6 대 1의 경쟁률을 기록한 아파트 이름은?', '강가이콘다 촐라푸람을 수도로 지정한 황제는?', '27일에 한국전문대학교육협의회가 주최한 엑스포를 방문한 최소인원은?', '루터가 보름스 청문회에 참여한 해는 언제인가요?', 'TV 토론 참가자가 하게 될 TV토론회의 횟수는?', '포스트 VRICI가 언급되었던 것은 언제인가요?', '코소보의 새 국기에 있는 하얀 별의 갯수는?', \"강남 오렌지 에일'의 맛과 향에 걸맞는 계절은?\", '문화체육관광부와 한국관광공사가 주최한 캠페인의 목적은?', '1835년 선출된 텍사스 지원군 지휘관이 제임스 보이에게 임명한 직책은?', '사이버펑크에 주로 등장하는 시간적 공간적 배경은?', '은행의 혁신성을 순위나 등급으로 평가하는 기관은?', '<오래된 신발> 저자와 결혼한 사람의 이름은?', '체력부족으로 은퇴한 인물이 손을 잡은 인물은?', '복지부가 예비타당성 절차 없이 시행을 요구한 사업의 출처는?', '참가자 모집에 3,000여 명이 응모한 프로그램명은?', '쿠즈네초프는 누구의 명령을 거역하였나요?', '장기 투숙 고객의 호콕을 도울 시설이 있는 장소는?', '현대자동차가 이듬해에 유럽에서 출시할 차종은?', '중소기업이 장기 근속자 인센티브 목적으로 기금을 모으면 세제혜택을 주는 정책은 무엇인가?', '알사바 전 부총리가 속한 가문의 이름은?', '인형에서 불임과 정자 수 감소를 유발하는 물질이 기준치 대비 최고 몇 배까지 나왔는가?', '지금까지 LIG그룹이 피해자들에게 보상한 대략적인 금액은?', '브라질의 신임 재무장관 이름은?', '안중근 의사 기념관 참배를 추진중인 국가는?', '젠서 관계자에 따르면 젠서의 해외사업에 지장을 준 요소는?', '정해진 기간동안 목표 금액에 도달하지 못할 경우 돈을 받지 못하는 사람은?', '도천사지 내에서 발견되는 와편은 어느 나라 때 만들어진 것인가?', '4년전 정기점검에서 A등급으로 평가된 건물 동은 어디인가?', '대통령 포로셴코가 푸틴을 처음 마주한 나라는 어디인가?', '전교조 미복귀 전임자의 징계처분에 관한 의결을 담당하는 교육청 의결기관은?', '장춘단 터가 공원으로 바뀐 해는?', '캘리포니아에서 쿡이 크래머에게 답장을 보낸 시각은?', '다음달 8일, 한화 클래식 공연을 관람할 수 있는 도시는?', '엄부영 본부장이 제주항공 전에 다녔던 회사는?', 'SAP ERP 시스템을 업그레이드 한 프로젝트를 발표한 인물의 이름은?', '기원전 227년에 군사혁명을 일으켜 에포로스를 살해한 인물은?', '부당하게 쫓겨나는 임차인 보호를 위해 상가임대차보호법에서 보장해 주는 영업기간은?', 'SBT가 급여를 6개월 간 주지 못했던 해는 몇 년도인가?', '레닌이 출간한 책 중 농민의 자발적 참여에 대한 내용이 포함되어있는 것은?', '전셋값 상승률이 두 번째로 높은 서울의 지역구는?', '오윤아가 가족과 함께 출연한 프로그램은 무엇인가?', '롯데쇼핑 2대주주의 이름은?', '스플안심스팟은 사회적 거리두기 몇 단계 동안 유지될 계획인가?', '영자초를 진귀한 재화라 평가한 사람의 직업는?', '작년 가장 일하고 싶은 비제조업 기업 2위였던 곳의 회장은?', '국내 1위 면세점 사업자는 어느 기업인가?', '삼성전자가 갤럭시S6 공개 이벤트를 진행한 나라는?', '선저우 10호 발사국이 독자적인 우주정거장을 보유하고자자 하는 해는?', '타이젠폰의 두 번째 출시국은?', '일곱 성당 이야기가 현지에서 출간된 연도는?', '특성화고 출신 직원의 대학교 학비를 대신 부담해주는 은행은?', '삼성중공업과 삼성엔지니어링의 합병을 반대하는 주주들의 주식매수청구금액 총액은 얼마인가?', '갈릴레이가 이오와 유로파를 하나의 천체로 관측한 것은 몇 년도였나요?', '참호 속에 무기와 장비를 버리고 도주한 집단은?', '몇 월에 하나은행과 외환은행의 합병이 이루어지는가?', \"2020 추석 장사씨름대회'가 폐막하는 날은 언제인가?\", '미국 대형은행들의 주주들이 받은 배당금은?', '역북지구 공공주택지 중 아직 팔리지 않은 블록은?', '포겐도르프가 <물리학사>를 출간한 년도는?', '상류 부르주아의 정치 독점을 불러일으킨 체계는?', '검찰이 처음부터 죽이려는 고의를 인정하지 않은 사건이 발생한 지역은?', '쇄자갑이나 판금갑을 파훼하기 위해 개발된 무기는?', '1561년, 안상에게 합자보를 수정하라고 지시받은 인물은?', '김수천 사장의 입사년도는?', '김정희가 청나라에 간 해는?', '뮤지얼보다 더 높은 점수로 경기를 그만 둔 인물은?', '퍼 스티니우스가 컨설팅 회사를 창립한 연도는?', '주인공 노바는 어떤 느낌을 지닌 캐릭터로 바뀌었나요?', '이탈리아 수석 대주교의 직함 중 없어진 것은?', \"7일 '발리 패키지'를 통과시킨 회의가 열린 도시는?\", '모란이 수놓아진 부분 중 녹색 연화문단으로 만들어진 것은 유물의 어느 부분인가?', '토이저러스 매출이 1500억원을 돌파한 해에 토이저러스 매장 수는?', '대가족제도에서 차별의식을 더욱 강화시켰던 문화는?', '세월호 사고 당시 세월호의 적정 평형수는?', '삼성SDI 해외영업소의 수는?', '큰 앞바퀴와 작은 뒷바퀴를 가진 자전거는 무엇인가?', '조회수가 가장 크게 증가한 방탄소년단 뮤직비디오의 이름은 무엇인가?', '지미 카더는 선거 공약으로 무엇을 내세웠는가?', '간토 대지진 외에 사가미 해곡 지진에 해당되는 지진은?', '국민은행 감사위원들이 거부로 구체적으로 다루지 못한 건은?', '한국농어촌공사가 추천해서 받을 수 있는 상은?', '서울시를 3D 모델로 나타내기 위해서 사용된 2D 이미지는?', '파워레인저 다이너 포스의 정식 가격은 얼마인가?', '인수위원회 위원 중 가장 많은 비율을 차지하는 지역은?', '역사상 가장 오랫동안 이용된 용광로는?', '엔트로피에서 배제하는 것은?', '3차원 낸드플래시를 탑재한 SSD에 사용된 데이터 전송 규격은?', '윤극영 선생이 처음으로 만든 노래의 이름은?', '코보의 제품중에 마우저에서 구매할 수 있는 모듈은 몇 개인가?', '서천리 당산의 남자 돌장승의 이름은?', '김옥균이 히라노초를 갔을 당시 믿고 의지했던 인물은?', 'SK회장이 중화권 국가 다음으로 방문한 나라는?', '크리스티 경매에서 가장 높은 금액에 낙찰된 디자인 작품의 디자이너는?', '특강의 멘토로 참여하는 기업의 대표 이름은 무엇인가?', '아이머게이머 챌린지에 참가하기 위해 글을 업로드 해야 하는 SNS는 무엇인가?', '황녹색의 유약이 있는 겉부분이 없어지면 무슨색을 띄는가?', '2018년 1월부터 2020년 8월까지 연령이 60대 이상인 서울시 주택구매자는 몇 명인가?', '음식 메뉴를 번역하는 데 드는 비용은?', '전일제 지원의 대상을 맞벌이 부부로 한정할 것이라고 주장한 사람의 부처는?', '경희대학교에 들어가 수비를 전담하게 된 선수의 키는?', '올레tv와 인터넷을 처음 가입하면 공짜로 받을 수 있는 것은?', '송경애 사장이 처음으로 갖게되었던 직업은 무엇인가?', '여운형이 김구에 의해 몸수색을 지시받은 장소는?', '공모주 물량의 10%를 우선 배정받는 펀드의 이름은?', '민석이 잠을 자기위해 반드시 청취해야 하는 것은?', '소득에 따라서만 수급여부가 결정되는 연금의 이름은?', '중흥S클래스 리버티에 언제부터 청약 신청이 가능한가?', '일본에 있는 주택 중에 사람이 살고있지 않은 집은 몇 채인가?', '한국유학 2000년사에 활용된 논문 수는 대략 몇 개 인가?', '차홍녀와 황철이 만든 극단이 설립되었던 해는?', '쌍용자동차를 시험 주행할 수 있도록 허가해준 기준이 되는 제도가 시행되기 시작한 연도는?', '2012년 게임산업협회장을 맡았던 사람의 이름은?', '일본 2분기 GDP의 전분기 대비 감소율을 연율로 나타내면?', '보증금은 누가 납입하는가?', '멘데스가 요원들을 구하기 위해 간 도시는 어디인가?', '가장 낮은 응답률을 보인 복권 구입 빈도 항목의 응답률은?', '로제르에게 안티오키아가 적으로부터 안전한 이유를 전한 사람은?', '삼성물산이 기대하는 2020년 건설사업 매출액은?', '포스코가 정강섭씨에게 지급한 기술료는?', '권영모가 예전에 모시던 사람의 이름은?', '송파 헬리오시티엔 총 몇 세대가 입주할 수 있는가?', '조수호 회장의 사망 원인은?', '플레이어와 블레이드가 알두인에 맞서 싸울 수 있는 힌트를 얻은 장소는?', '동성상업학교 교장으로 직무를 수행하기 전 장면의 직장은?', '새 서비스는 어떤 잡지의 구조와 유사할 것이라 예상되는가?', '중소기업 전용 주식시장 이전 주식시장이 출범했던 년도는?', '학교형태의 평생교육시설이 어떠한 목적으로 이용되는 것을 막아야 하는가?', '가짜 드미트리가 정부를 건립한 곳은?', '꿈카 스테이션이 시범 운영되는 시설은 몇 개인가?', '박근혜 씨가 국회 국방위원으로 활동한 해는 언제인가?', '호출에 의해 동적인 상태로 변환되는 소프트웨어 구성요소는?', '권력이 강한 가문 출신 사람들이 빠르게 승진하는 문제를 해결하기 위해 신돈이 실시한 정책은?', '페터 스토이베산트가 포트 캐지미어를 세웠던 장소의 현재 이름은 무엇인가?', '한진 중공업 노조가 변화하기까지 걸린 기간은?', '여운형이 여러 소일을 하기전에 일했던 곳은?', '무형자산 4조원을 가지고 있는 회사의 사내유보금은 얼마인가?', '제6장갑사단이 어디로 가는 도중 소련군 증원부대와 마주쳤나요?', 'MCM과 협업하여 상품을 제작한 회사는?', '일리아드 첫 장면에 나오는 것은 누구인가?', '봉봉 유입이 가장 많은 SNS는?', '아폴론에게 예언을 주관하는 힘을 준 이는?', '선박 안전 관리에 관한 책임을 지고 있는 기관은?', '가정교육과를 폐지한 대학은?', '카이사르는 브리튼의 추운 날씨로 인해 어디로 후퇴했는가?', '경찰들이 시위대에 합류하면서 한 말은?', '지유가 12월에 진행하는 콜라보레이션의 목적은?', '티몬에게 반값 할인 쿠폰을 받을 수 있는 고객은?', \"수정의 밤'사건으로 사망한 유대인들은 최소 몇 명인가요?\", 'SK이노베이션이 정유 시장에서 중점을 두는 국가는?', '스마트폰을 가까이 가져감으로써 출입이 가능한 ADT캡스 서비스명은?', '샘 슈만이 죽은 원인은 무엇인가?', '정부가 가계부채 증가 속도를 늦추기 위한 방안을 추진하기 전, DTI 적용을 피할 수 있는 대출 최대 금액은?', '웅게른슈테른베르크가 포로로 붙잡혔던 유격대의 리더는 누구였나요?', '세균을 제거하는데 탁월한 능력을 보여준 제품은?', '새만금을 관광명소로 만드는 내용을 내놓은 회의의 중심이 된 사람의 직책은?', '신시내티에서 노면전차의 승객 수를 감소시킨 교통 수단은?', '에스비비테크가 HDS사 독점 공급 부품의 양산에 성공한 연도는?', '아랑을 살해한 사람은?', \"유리동물원'에서 이야기 속 사건들이 일어나는 도시는 어디인가?\", '노이즈 캔슬링에 대한 미션을 이행하는 참여자는 몇 명인가요?', '추가경정예산을 통과시키기 위해 마지막으로 논의 된 사항은?', '하임 레빗이 통찰한 현 시대 사람들이 가치있게 여기는 것은?', '자동차 엔진 공기유입 부품을 제조하는 회사의 올해 2분기 영업이익은?', 'LED소자의 기능 상실을 방지하기 위해 사용한 방법은?', '프로젝트 결과물을 평가받은 사람 수는?', '남종삼이 사망할 당시 유일하게 살아남은 인물은?', '잉글랜드 요리는 어느 나라 요리에 속하나요?', '니모 FD의 컬러 중 이번에 새로 나온 색은?', '한국맥도날드 본사에서 근무하는 직원들 중 50% 정도가 어디에서 근무를 시작했는가?', '일본의 총리가 만든 경제 관련 정책의 이름은?', '루트비히 2세의 사망 이후, 동프랑크 왕국의 중북부 지방의 땅을 물려받은 인물은?', '유창근 사장이 남미지역 회의에 참석하는 날짜는?', '산발적 백신 품귀 현상이 발생한 해, 제조사가 공급한 백신 물량은?', '신한 은행에서 직접 캐피털의 대출 상품을 판매하기 위해 만든 것은?', '현대카드가 Visa에서 2018년에 수상한 상은?', '의정부경전철의 환승 할인에 의한 손해와 환승 시스템을 구축하는 데 드는 비용의 총합은 얼마인가?', '애플과 NTT도코모가 손잡은 후 일본시장에서 삼성전자 점유율은 얼마인가?', '이마무라와 다스다에게 참수형을 선고한 기관은?', '박인용이 급행열차로 갈아타기 전에 들른 역은?', '디지털정보센터에서 전자책을 이용할 수 있는 공간은 몇 층인가?', '양적완화를 시작한 9일에 유로화 가치는 얼마였는가?', '밀풍군 탄의 아들이 김씨의 양자가 된 해는?', '교회 개혁을 추진하는 사상은 무엇인가?', '처음으로 수액제가 국내에서 생산될 수 있도록 만든 사람의 이름은?', '개별 토지의 단위 면적당 가격이 3년 연속 상승한 곳은?', '직원 가족 대상 프로그램 중 참여인원이 명시되어 있는 프로그램의 이름은 무엇인가?', '두위밍을 불러 들인 사람은?', '한 분야의 전문기업으로 사회적 역할을 강조한 인물의 이름은?', 'T끼리 요금제의 최대 가격은 얼마인가요?', '미국의 에너지 운송 인프라 기업에 집중 투자하는 펀드는?', '보험료율이 14%인 집단의 소득대체율은?', '주태석의 기념전은 언제까지 열리는가?', '시즌 마지막마다 베토벤 교향곡을 연주하는 곳은?', '오윤부의 이름 앞에 붙었던 칭호는?', '처리시한을 넘긴 동의안을 국회에 제출한 달은 몇 월인가?', '어피인장함의 뒷면에 붙은 경첩은 무엇의 형태인가?', '임헌영은 어느 기관에 소속되어 있는가?', '박 회장 측이 요청한 면담이 이루어진 장소는?', '앙리 지스카르 데스탱은 클럽메드의 지분을 몇 퍼센트 갖게 되는가?', '수능 응시유형 변경 가능 기간은?', '현대아울렛 가산점은 이제부터 어떤 기업이 맡게 될 예정인가?', '하나금융지주 회장의 비서로 일하는 사람은 몇 명인가?', '벽에 천녀를 그리기 전에 하는 밑작업은?', '프랑스가 베트남을 공격한 명분은?', '준공공임대주택은 전용면적이 얼마 이하여야 되는가?', '3번째로 스타트업 대표를 가장 많이 배출한 대학은 어디인가?', '우리나라에서 처음으로 기부금으로 지어지는 병원이 들어설 동네는?', '1.8%의 브라질 경제성장률을 예측한 기관은?', '파견법이 제정된 시기는?', '올해 가장 높은 청약 경쟁률을 보인 아파트의 건설사는 어디인가?', '국순당에서 참여한 환경보존 기술은 무엇을 줄이기 위해 실시되는가?', '서울에서 매매 거래량이 가장 많이 증가한 지역은?', '영국 해군이 다시 전장식으로 돌아가기를 결정했던 때는?', '경제학의 어떤 개념을 통해 개방경지제의 공동 방목지가 능률이 떨어지는 이유를 이해할 수 있는가?', '부처 간 협의를 강조하면서 정총리가 없애고자 한 것은?', '신형 제네시스의 정확한 가격을 알 수 있는 날짜는?', '정기선 전무가 미국 유학길에 오른 해는?', '김혜연의 배우자는 누구인가?', '아멜리아는 빅토르의 직업을 무엇으로 착각하나요?', '김정길이 지역주의 제거에 선구하기 전 분위기를 조성한 사람은?', '방실이가 미군 부대에서 처음으로 활동하기 시작한 해는?', '더퍼포먼스 대표 이전에 먼저 강의를 한 인물의 이름은?', '2019 해양관광 오디션에 우승시 받을 수 있는 상의 가치는?', '안산벚꽃음악회가 열리는 인근에서 홍보 중인 아파트는?', '장정기가 들어있는 우산이끼의 가지는?', '쌍용어패럴이 입주해있는 건물은?', \"글로벌 인재포럼 2015'에서 <인구쇼크>의 저자가 있는 세션은?\", 'LG전자가 90여개국에 G2를 선보인 기간은?', '루신화가 에세이를 써낼 때 까지 미국에서 산 기간은?', '청년몰에 있는 여러 가게 중 SNS를 이용한 마케팅전략으로 많이 알려진 곳은?', '여신협회가 부담할 증여세율은?', '1톤당 150달러로 발전용 연료탄이 판매되었던 년도는?', '존스가 최정예 대대를 파견해서 돕고자 한 부대는?', '제주도 소재 아파트 가격이 급격하게 오르기 시작한 날짜는?', '영상을 통해 마지막으로 소개되는 ‘이지스-테크업플러스’ 선발 기업은?', '대중이 불교에 친숙해질 수 있도록 일감 스님이 주최한 행사의 이름은?', '작년 17일 삼겹살 1kg당 소매가격은?', '블루 아도니스가 있는 곳은?', 'When We Were Close 노래의 장르는 무엇인가?', '허계임과 그녀의 두 딸 중 가장 먼저 순교한 것은 누구인가?', '메구밍에게 자신이 사용하던 안대를 준 사람은?', '리모델링 박람회에서 수도권 아파트 리모델링 관련 내용을 밝힌 사람은?', '국산 라면이 두 번째로 많이 수출되는 국가는?', '로그 오브 히어로즈 게임이 시중에 나오기까지 얼마나 걸렸는가?', '한국에서 고등 교육이 두 계열로 분화되었던 관행이 생긴 지는 대략 얼마나 되었는가?', \"쏘카만 있어도' 프로모션을 통해 1박 2일동안 쏘카를 이용할 수 있는 최소 금액은?\", '무바라크 측근의 지난 대선 득표율은?', '일본이 반자본주의 사회가 되었다고 라고 주장한 조직은?', '재판을 받고 있는 인물의 이름은?', '박용만 회장의 의견에 따르면, 경제민주화 입법으로 피해를 입고 있는 기업의 유형은?', '미국의 일광절약시간제 기간이 늘어나기 시작한 해는 언제인가요?', '비트겐슈타인이 병원에서 봉사를 할 수 있도록 한 인물의 직업은?', \"잃어버린 얼굴 1895'에서 '명성왕후 민자영'을 연기한 배우의 데뷔작은 무엇인가?\", '수수료를 올해 마지막 달까지 면제해주는 행사는?', '미네소타주 경찰이 오마르 히메네스를 체포한 날짜는 언제인가요?', '철도공으로써 받은 첫 급여로 파브르는 무엇을 구매하였나?', '106번째 북미 영상의학회에서 인정된 연구는 몇 건인가요?', '19일까지 올 뉴 쏘렌토의 주문량은?', '성과보수체계 개선안을 만들겠다고 밝힌 인물의 이름은?', '줌에서 전체 참여자의 일부분이 따로 회의를 열 수 있는 기능은?', '저출산 문제를 해결하기 위한 대책을 수립하는 역할을 맡은 기관은?', '주가 변동폭이 1260포인트를 기록한 날은 며칠인가?', '중국에 진출한 국내 보험사 중 두 번째로 점유율이 높은 회사는?', '독립채산제의 확대 실시 등으로 이루어진 경제 관리 개선 조치를 무엇이라고 하는가?', '소득공제장기펀드에 가입할 수 있는 최대 연간 총급여는?', '이사회에 가입되어있는 회원국 수는?', '기원전 324년에 드리페티스의 결혼 상대는 누구의 동료였나요?', '올해 1분기 세수가 지난해 같은 시기와 비교하여 감소한 액수는?', '현대로템이 준비하는 실증사업을 진행 중인 회사는?', '고권삼이 친일인명사전 수록예정자 명단 중 해외 부문에 포함된 이유는 무엇 때문인가?', '버클러를 이용하거나 애초에 방패의 장점을 버리고 양손 무기를 썼던 사람들은?', '모세가 십계명을 받고 시나이 산에서 내려와 누구를 보고 슬퍼하고 분노했다고 <탈출기>는 전하는가?', '동부화재가 미국에서 세 번째로 지점을 연 때는?', '해외사업이 넷마블 전체 매출에서 차지하는 비중은?', '2019년 한일청구권 협정 제 3조에 의거하여 일본이 대한민국 정부에 설립을 요구한 부서는?', '드림허브의 2대 주주가 용산역세권개발에 투자한 금액은?', '돌비 협력 작품 중 4K 화질을 지원하지 않는 것은 무엇인가?', '서든애비뉴매니지먼트가 정크본드 환매를 중지하면서 그 사유로 내세운것은?', '작년 외국인 관광객을 가장 많이 유치한 지역의 이름은?', '아카풀코에 새로운 열대 요란이 일어난 날짜는 언제인가요?', '과잉 인증의 정비를 통해 비용을 절감하게 된 회사의 수는?', '씽씽 서비스 배치 구역의 선정 이유를 설명한 사람의 직책은 무엇인가?', '삼성이 이번 년도에 출시한 김치냉장고의 이름은?', '항우가 진나라를 멸하면서 조왕 헐은 어디로 이동했는가?', '이번 6일 이전에, 원·달러 환율이 가장 낮았던 것은 언제인가?', '현대차의 대당 수출단가는 전년 동기 대비 몇 퍼센트 증가했나?', '테바이는 권력을 잃고난 뒤 누구에게 복종하게 되는가?', '프리마 카테고리아 1912-1913 결승전에서 6-0으로 패배한 팀은?', '삼성전자에서 이번 년도에 출시한 핸드폰은?', '스빈후부드가 신분제 중심의 핀란드 국회를 개혁하는데 큰 영향을 미쳤던 시기는?', '한국 대 멕시코 경기에서 선제골을 넣은 쪽은?', '추락한 헬기를 제작한 곳은?', '관람객들이 마니프의 전시회에서 감상할 수 있는 작품은 대략 몇 점인가?', '한미엔텍이 악취처리 신기술을 제공하고 있는 다른 나라는 어디인가?', '구즈바의 학교 기숙사에 무단으로 들어와 학생들을 공격한 사람은 누구인가?', \"위대한 탈출' 번역판에서는 책 커버에 보충 제목이 뭐라고 쓰여있는가?\", '의사-석유 교환 협정으로 이득을 본 베네수엘라의 정책은?', '서울상상나라에 참가비를 내지않고 방문할 수 있는 때는?', '롯데마트에서 2일에 한 근의 훈제오리슬라이스를 신한카드로 계산하면 얼마에 살 수 있나?', '김태원석함 오디션 예선에서 오샘의 선곡은?', '뉴욕주에서 총기 규제 문제가 대두된 것은 어떤 사건때문인가?', '셧다운제 시행 이듬해의 국내 게임 시장규모는?', '우효준 대표가 잠에 관심을 갖게 한 사람은?', '죽림사 세존괘불탱은 어떤 재료 위에 그려졌는가?', '상원이 합의안을 표결에 붙일 것으로 알려진 날짜는?', '로스 수장이 살해한 사람은 어느 당 회원인가?', '민주노총을 압수수색한 기관의 대표의 이름은?', '티라윗 리타본 부회장이 방문한 도시는?', '크레센티우스 2세가 받은 형벌은?', '기재부가 세법개정 계획을 밝힌 장소는?', '총학에서 노동자의 인권에 관한 내용을 기반으로 협의하여 정한 규칙은?', '30대 그룹이 작년 상반기에 투자한 금액은?', '3개년 로펌 누적 합격자수가 19명인 대학교는?', '전기안전공사 채용 결과는 언제 알 수 있는가?', '우핑가스 왕조의 이름은 어디서 유래하였나?', '무용인 한마음 축제에 두 번째 순서로 오를 공연은?', '1989년에 가내작업반은 무엇으로 인정받게 되었나요?', '콜 오브 듀티 블랙옵스의 후속편이 출시되는 달은 몇 월인가?', '토론회에서 선의의 차명거래 제도화를 주장한 인물의 이름은?', '세계 자동차 판매량 1위 기업의 부정행위가 발표된 날짜는?', '미국 1위 투자은행의 부회장이 회사에 입사한 연도는?', '중학생이었던 하상욱 씨의 장래희망은 무엇이었는가?', '구글 드라이브와 연동되는 메모 앱 이름은?', '수입 대금을 돌려받지 못한 기업들은 어느 기관에 도움을 요청할 수 있나?', '플래그쉽 스토어 방문객들이 쉴 수 있는 공간은 몇 층에 마련돼있는가?', '유럽 부동산에 투자될 자금의 규모는 얼마인가?', '피아노 협주곡 5번의 첫 공개 초연이 이루어진 해는?', '전주 소재 공장에서 작년에 만들어진 차량은 총 몇 대인가?', '다 다른 계정으로 게시물을 올려도 무엇이 동일하다면 모든 게시물의 IP 주소는 동일한가?', '한국 주식시장에 대해 비관적인 견해를 밝힌 인물이 단독 인터뷰를 한 일자는?', '에스북서비스로 받은 책은 며칠간 볼 수 있는가?', '보퍼트해에서 기름 유출을 감시하는 드론의 제조사는?', '새로운 대형 중폭격기 개발을 위해 필요한 것은?', '확실한 고정력으로 휴대폰의 낙하를 방지하는 부품은?', '페리클레스가 발의한 법이 입제된 시기는?', '페스티벌에 참가하는 우리나라 단체의 이름은?', '고천문학자는 연구할 때 사회 분야와 어떤 분야의 조화를 이루는 것이 중요한가?', '불가살이가 먹은 무기들을 사용하는 장수는 실제로 어느 나라 사람인가?', '호프만스탈의 사망 원인은?', 'G4의 예약 판매가 끝나는 날은?', '유니버셜뮤직과 협력하여 만든 메가기프트를 살 수 있는 업체의 매장 수는?', '은행정리체제가 합의된 이후 EU의 신용등급 전망은?', '서울고속버스터미널 지분 매입을 망설였던 기업은?', '대한민국에 농구가 처음 상륙한 해는?', '빛과 물질의 상호작용 시에 입력 증가 정도와 다른 진동수 출력을 내는 현상은?', '호쿠토는 업무전화를 받고 어디로 가버렸나요?', '다음해에 정부가 첫 번째로 증원하는 해양대 해사대학 인원은 대략 몇 명인가?', \"왕의 하루' 공연의 스토리 구성을 맡은 사람의 이름은?\", '톡 쏘는 것처럼 혀가 아린 매운맛을 내는 향신료는 무엇인가?', '피렌체파의 대미를 수놓은 사람은?', '경상남도 기념물 제289호를 창건한 인물은?', '루이지애나흙파는쥐 다음으로 큰 동부흙파는쥐는?', '교보문고에서 이순신과 연관하여 가장 많이 팔리고 있는 도서는?', '핵무기 공유 협정을 맺은 경우 발사에 필요한 물건은?', '데이콘과 매스챌린지 보스턴 본선에서 경쟁 중인 아시아국가는?', '노랫말의 번역이 대구 시구 번역보다 훨씬 제약이 많은 이유는?', '피터와 함께 하이든의 무덤을 도굴한 인물은?', '블루투스 분야에서 세계 2위인 기업이 있는 나라는?', '던스터블 수도원에서 발견된 물건은 누구의 것으로 예상되는가?', \"송세호가 '삼신리 2호'를 운영했다고 보도한 곳은?\", '화학 반응 발생 시 스스로는 무변하지만 반응 속도에는 변화를 일으키는 것은?', '레보노게스트렐 성분을 포함한 응급피임약은 높은 효과를 위해 최대 몇 시간 안에 섭취해야 하는가?', '1회용 샴푸라는 아이디어를 낸 회사는?', '인간에게 가장 익숙한 크기의 개념은 무엇인가요?', \"야로스와프와 같이 '법과 정의당'을 만든 사람의 이름은?\", '삼성이 중소기업에 개방하는 특허 중 무료인 특허는 몇 건인가?', '건강식 코스요리를 제공하는 디너쇼가 열리는 호텔 이름은?', '현직 추밀원사무처장 웨인울터즈의 선임은?', '레오 6세에 의해 감금당하여 살해된 인물은 누구인가요?', '꼬깔콘의 작년도 연매출 규모는 얼마인가?', '임산부가 태몽을 꾸는 시기는 주로 임신전후와 또 언제인가?', '작년에 현대산업개발이 분양한 가구수는?', '상하이의 북역과 남역 모두를 자유롭게 타기 시작했던 해는?', '콘스탄티네 2세에 이어 왕위를 계승한 인물은 언제까지 군림하였나요?', '플린트를 기본 공간으로 하여 다양한 영화를 제작한 인물은?', '가석방 대상이 될 수 있는 자격은?', 'OGN 다트 챔피언십 일반부 마지막세트 최종 스코어는?', '사실과 다른 문서를 서울시에 제출한 업체의 이름은?', '국내무사가 체포 활동에 참가한 것은 무엇 때문인가?', '방송채널사업자가 송출하는 방송의 화질은?', '12월 12일에 호트군의 선봉이었던 사단의 하루 이동 거리는?', '롯데백화점에서 올해 추석 매출 5등인 품목은?', '공정위가 소비자보호 실태 조사를 맡긴 기관은?', '결의 전에 장관의 발언을 제지한 사람은?', '상대적으로 애니메이션의 캐릭터에 맞추는 것이 수월한 사람은?', '연세 금호 아트홀의 첫 공연은 언제 열리는가?', '안중근의 동생이 실종된 지역은?', '중국에서 3번째로 인기있는 K팝스타는 누구인가?', '정재근이 묵은 숙소가 있는 시는?', '환경재단과 함께 공모전을 주최하는 회사의 대표 이름은?', '블레이드 러너에서 실제 사람같은 존재를 부르는 단어는?', '정보 유출보다 카드 사용액에 크게 작용한 사건은?', '지난 해 말, 연예인 주식부자 3등인 사람의 직업은?', '등산용 신발에 보아 클로저 시스템을 적용해 큰 매출을 달성한 회사는?', '데스볼트는 무엇이 결여되어있나?', '상사병으로 사망한 소녀의 장례식이 열린 곳은 어디인가?', '연 5% 정도 수익을 낼 수 있는 금융상품을 추천한 사람 수는?', \"2차 업데이트 후 '북방대초원'에 새로 생긴 미션은?\", '박근혜 대통령의 중국어 연설 영상을 유쿠에서 시청한 사람은 얼마인가?', '소유자에게 기준시가가 공개되는 날짜는?', '제국과 메시나를 두고 전쟁을 벌인 민족은?', '지오영과 유통마진을 나누어 갖는 기업이 공급하는 마스크 비율은?', '천지 괴물에 대한 목격담은 어느 시기에서부터 시작되었나요?', '국가채무 산정에 포함되지 않아 실제보다 측정액이 낮게 나오게 하는 것은?', '한국크라시에가 과립형 제제를 생산하고 있는 지역은?', \"이승조의 '평면과의 대결'을 높게 평가한 사람은?\", '19세기 말 러시아의 농민과 진보 귀족이 거부했던 농업 구조는 무엇인가?', '등록금 인상률이 3번째로 높은 대학교는?', '스위니가 테네시에서 무엇을 도둑질 한 것으로 전해지나?', '유병언의 금융비리에 가담한 종교단체는?', '할리우드 대작 최초로 한국에서 촬영을 한 영화는 며칠만에 천만 고지를 넘었는가?', '미국 민주주의의 기원으로 여겨지는 것은?', '토치가 무엇을 가지고 있어서 돌로 바뀌지 않았는가?', '유영 대신 황태자가 될 뻔한 인물은?', '사망 사건으로 논란이 된 에너지 드링크는?', '카르타고 시민 보병대가 역사 기록에서 없어진 시기는?', '정부의 예비비를 받게 될 교육청의 수는?', 'KEB 하나은행에서 몇 군데를 대상으로 약 500명을 고용하는가?', '현대차그룹의 5개 계열사 중 가장 지원자가 많은 계열사는?', '신 회장이 최근 CEO 자리에 오른 회사는 어디인가?', '재형저축을 들 수 있는 사람 중 가장 소득이 높은 사람의 연봉은 얼마인가?', '대구범어점이 생기기 전, 한샘에서 매장이 가장 컸던 지점은?', '21일 상장 예정 회사의 공모 희망 최저가는?', '스튜어트를 구하러 온 부대는 어디에서 출발했나?', \"2020 차별에 대한 국민인식 조사'를 실시한 단체의 우두머리 이름은?\", '성당의 서쪽과 남쪽 부분에 난방이 가능해진 시기는?', '아레나에서 전투에 임하기 위해 사용해야 하는 것은?', '청약자가 정원보다 9명 적게 모인 아파트는?', '노동운동 단체가 소멸하기 시작한 연도는?', '독일이 우승했던 월드컵에서 전술과 선수 기용의 실패를 맛본 감독은 누구인가?', '일반적으로 사람들은 구입한 차량을 얼마동안 이용하는가?', '보주에서 반란이 빈발한 시기는 언제부터인가?', '상반기에 카드분실 책임을 고객에게 4번째로 많이 물게 한 카드사는?', '장하준 교수의 한국경제에 대한 생각에 대해 반론한 김상조 교수의 저서는?', '핀란드의 최대 교역국은?', \"호적을 '남'에서 '여'로 바꾼 인물은?\", '보조 수트 액터를 맡은 사람은?', '사무총장이 정권에 따라서 방향을 설정하는 감사는?', '이명박 정부를 비판한 여당 광역자치단체장은?', '페스트파이브가 우리나라에 개방형 오피스를 처음 소개한 시기는?', '양회와 강절에서 산서시들과 경쟁을 한 집단은?', '청주공예비엔날레 기획전2에 참여하는 국가 수는?', '한국과 중국의 FTA 체결 후 한국에서 치뤄야하는 과정은?', '현대자동차 임금협상에서 노조측 대표를 맡은 사람의 이름은?', '꾹꾹을 운영중인 기업의 수장 이름은?', '텔 아파르나 키프리를 탈환하기 위해 계획 중인 집단이 소속된 나라는 어디인가?', '부산대학병원 인근에 EG건설이 공급하는 총 아파트 가구수는?', '피르 볼그라는 이름은 어떤 의미를 지니는가?', '어셈블리의 구성 요소 중 어셈블리에 대한 고유값을 가진 것은?', '다음달 5일에 영업 정지되는 회사는?', '불평등의 본질을 탐구한 인물이 재직한 학교의 이름은?', '박 대통령이 일본 특사단 4명과 만난 장소는 어느 동에 위치해 있는가?', '저번달 세 번째 주에 일본에서 가장 많이 팔린 삼성의 스마트폰은 무엇인가?', '경찰관 5명이 부상을 입는 사건이 발생한 도시는?', '샤이반계 유목민들이 주치 울루스의 소유권을 두고 분쟁한 상대는?', '공정거래법 개정안에 대해 위원들과 다른 의견을 보인 인물의 이름은?', '중국이 관리, 경영하는 곡물재배 기업으로 CJ제일제당의 제휴사는?', '마틸데의 첫째 언니가 사망한 년도는?', '2017년 총선거에서 50석을 차지한 당이 만들어진 달은?', '미국에서의 현대차 매출은 1년간 몇 퍼센트 증가하였나?', '슈타우펜베르크가 패전을 확신한 것은 몇 년인가?', '조소문화협회가 만들어진 시기는?', '특허를 보유하지 못한 중소기업의 어려움을 해소해주라고 지시 받은 사람의 이름은?', '오리너구리가 전기를 가장 잘 느끼는 부위는?', '평상시 기독교선교사들로부터 차별적 대우를 받은 윤치호가 생각한 미국의 중대한 속성은?', '천주교로 종교를 바꿨다는 의심을 받았던 학자는?', '국내관광 트렌드 전망에 대해 들을 수 있는 세션은?', '작년 말 기준 보험계약자가 찾아가지 않은 보험금과 환급금의 총액은 얼마인가?', '차명계좌 규제 법안을 발의할 것으로 예상되는 사람의 이름은?', 'F5의 별칭은?', '6월 평가 이후 EBSi에서 제공될 수능 연계 교재의 이름은?', '통근특급이 걸림돌인 노선과 서로 평면교차하는 노선은 어디인가?', '사민당이 화력 발전보다 친환경적이라 주장하는 것은?', \"13대 창조경제 산업엔진'을 제시한 부처에서 착용형 컴퓨터 산업을 일컫는 말은?\", '현대의 조선 3사 중, 이번 년도 상반기 때 임원 수가 가장 적었던 곳은?', '분에이 전쟁 이후 로쿠하라 단다이에게 주어진 권한으로 처벌할 수 있는 신분은?', '음식 관리나 조리 과정에서 발생하는 문제로 인해 나타날 수 있는 질병은?', '도요타가 업계 1위를 기록한 해, 폭스바겐의 업계 순위는 몇 위였는가?', '전문대학원 방식을 처음 도입한 곳은 보통 몇 년을 다니나요?', '몽키3의 모회사가 된 회사의 이름은?', '직거래로 300마리를 판매한 농가의 지역은?', '미국 코튼마크를 받기 위해 상품에 사용해야 하는 미국 면의 최소 비율은?', '그리스의 고대 올림픽 경기에 참여할 수 있는 자격은 무엇인가?', '사고 건수를 기준으로 하는 자동차보험료 제도에서, 두 번째로 사고를 내면 보험료가 몇 개 등급 올라가는가?', '신용 경색 현상을 감내하면서도 중국 정부가 이율을 높인것은 무엇을 감시하기 위함인가?', '구슬 모양이 특징인 불상의 머리부분은 무엇을 본떠 만든것인가?', '2차 컨스타운 전투 당시 브레킨리지는 누구의 휘하에 있었나?', '영화 미스터 고의 국내 총 관람객 수는 몇 명인가?', '개인이 기업의 자산을 보유하며 8명 이상의 노동자를 고용하여 수익을 얻는 기업의 유형은?', '생활숙박시설이 과거에 불렸던 명칭은?', '4월 기준 시화산업단지에서 임차공장이 차지하는 비율은 몇 %인가?', '안경 없이 3D 입체 영상을 볼 수 있는 스마트폰이 발표된 일자는?', '어획량 감소로 가격이 비싸진 킹크랩의 원산지는?', '오리온의 직원은 초코파이 개발에 영감을 준 간식을 어느 나라에서 접했나?', '하반기 신약 허가를 신청할 예정인 회사는?', '알렉상드린의 아빠는?', 'WEF에서 조사한 대상 중 국가경쟁력이 가장 강한 나라는?', '증권사 ROE가 5.6%였던 해에 하루 평균 주식거래대금은 얼마였는가?', '바다뱀자리 방향에 위치한 중력체가 움직인 원인은 무엇으로 추정되나요?', '예루살렘 공의회는 누가 유대 그리스토교인의 주장에 반론하면서 개최되었나요?', '아카리가 미조로기 료타를 만난 해는?', '미슈텍어파 언어들의 확산의 시발점이 된 곳은?', '소송에서 이긴 곳은?', '개정이 예정된 법 중 교육청과 관계된 것은?', '슈퍼셀은 어디에서 창립되었는가?', '세종시의 전체적인 일처리 방식을 개선하기 위하여 참고하는 국가의 정부부처는?', '융합스테이션 플랫폼 구축에 나선 기업의 할인된 수소차의 금액은?', '공무원노조 인정 등의 요구사항을 전달한 사람의 이름은?', '세계에서 ICT 산업의 규모가 가장 큰 나라는?', '조스마의 나이는 약 몇 년으로 예측되는가?', '이종휘 위원장이 우리은행장으로 취임한 연도는?', '2분기 GDP 성장률은?', \"재개발 추진위원회 및 조합 해산 기간'을 연장하는 법안을 발의한 인물의 이름은?\", '염규호가 AEJMC의 학회장을 역임한 마지막 해는 언제인가?', '저번 달에 세계에서 발주된 선박의 표준환산톤수는?', '그랑에이지를 제작한 회사는?', '박대통령은 취임사에서 조상들의 배려를 무슨 과일에 비유했나?', 'SDK 중 다양한 기능을 추가로 장착한 것은 무엇인가?', \"은퇴부자들'의 저자는?\", '넥서스를 설립한 사람의 이름은?', '기금운용위원 중 정부 소속 인원 수는?', '한국사이버결제와 겨루는 새로운 결제 시스템은?', '망각의 지팡이를 만든 사람은 지금 어디 살고 있나?', '작년 동기 대비 포스코의 1분기 영업이익은 몇 퍼센트 감소했는가?', '최초의 여성적위대가 참고한 부대 모델은 어느 국가의 것이었나?', '현대상선이 현대그룹에서 분리될 경우, 현대상선을 인수할 후보로 유력한 기업은?', '다니엘 헤니가 새로 키우게 된 개의 품종은?', \"뱅크월렛'을 통해 송금할 경우, 확인 메세지는 어디로 받을 수 있는가?\", '투자 기간에 정비례하는 것은?', '송대섭 교수가 메르스 연구를 위해 협력할 예정인 기관은?', '애플이 전례 없는 수법을 사용했다고 말한 사람의 이름은?', '기어S2를 만들어 낸 회사는?', '고스자쿠 천황이 사망한 연도는?', '지구상에서 열한번째로 경제력이 강한 나라는?', \"바이오배양공정과 '녹십자생명반' 학생들의 작년 취업 성공률은?\", '2015년에 대리점 대회를 연 회사는 어디인가?', '집행임원제에서 사외이사를 추천할 권리는 어디에 있는가?', '워드는 무엇에 열정적이었나?', '진공흡인 유방생검술에서 1회에 많은 양의 조직을 얻을 때 사용하는 도구는?', '나라에서 군인들을 뽑아 만든 군대를 통솔하는 우두머리는 누구인가?', '경제전문가들은 최경환 경제팀이 무엇을 높이는 데 주력해야한다고 요구하는가?', '부모를 내다버리기 위해 아들을 설득한 인물은?', '퓨쳐캠의 전립선암 진단후보물질과 경쟁하는 약품은?', '1575년 아시가루가 다네가시마로 무장하고 참가한 전투는?', '박진호 씨에게 올 4월 최고 학생논문상을 수상한 학회는?', 'LTE 음성통화 품질 조사에서 S등급이 가장 적은 통신사는?', '형재 프랭크퍼트 지역에 처음 발을 딛은 백인은?', '주택 매입에 대한 취득세 인하를 알린 날짜는?', '메리 바라는 GM 입사 초기에 어떤 직책을 맡았었는가?', '엔일렉트릭이 민물 양식장을 조성한 태양광 발전소는 어디에 위치하는가?', '경제 회복 시기에서 가장 많은 득표율을 얻은 항목은?', '허츠 해외 렌터카의 프로모션 종료날짜는?', '전체 매출에서 우리 나라를 제외한 지역의 매출은 얼마를 차지하는가?', '쑨리리 일행은 총 몇 인인가?', '해외 다운로드 비중이 50%에 육박하는 동영상 스트리밍 서비스의 사업자는?', '5년 내 1000개 점포 개점이 폭표인 회사의 현재 중국 내 점포 수는?', '14번째 메르스 환자가 삼성병원에 오기 전 방문한 병원은?', \"최근 예술의 전당에서 공연된 '맥베드'의 감독을 맡은 사람은?\", '코드스테이츠에 채용되기 위해서 거쳐야 하는 마지막 채용 과정은 무엇인가?', '정부는 중소기업을 지원함으로써, 금융기관이 어떤 이즘으로부터 탈피하게 하려 하는가?', '지하철역 인근 아파트의 평균 거래 가격이 3위인 수도권 지하철 노선은?', '불소와 반응 후 그래핀의 탄소 1개는 몇 개의 탄소와 결합되어 있나요?', '돈카를로의 작곡가는?', '윤창중이 수석비서관 인선 내용을 발표한 날은 며칠이었나요?', '아타속이 먹는 균이 길러지는 곳은?', '요한 바오로 2세의 아들을 죽인 악마 이름은?', 'LS 전선이 해저 케이블 사업을 시작한 것은 몇 년 전인가?', '원래 두 번째 순위였던 사람은 기준이 바뀐 후에는 몇 순위가 되었겠는가?', '길이 274m, 11개의 안뜰, 1000여개의 방으로 구성된 건물의 이름은?', '글로벌 테마파크를 유치하자고 주장한 사람의 이름은?', '에티오피아 인구의 절반이 유지하고 있는 언어는?', '엔드-투-엔드 5G 네트워킹 인증 프로그램이 국한되지 않는 대상은?', '김준연은 김구가 누구와 몰래 교류하고 있다고 주장했나요?', '현재 전시사업자가 자료제출의무 위반시 내야하는 것은?', '소비자가 전통시장을 이용하도록 휴무일을 조정한 백화점은?', '치과용 CT 장비 부문에서 매출 1위 기록했던 회사의 나라는?', '강중인이 경제사범을 비판하며 국민의 일대수치라 표현한 글은?', '복제약이 시중에 나올때 최초로 만든 의약품 값의 하락률은?', '미국기업이 원하는 작업자는 어떤 언어를 사용하나요?', '당이 통일되던 해에 낭비성은 어느 국가의 영토였나?', '이미 PCS3 대회가 끝난 대륙은?', '브레슬라우 전투 이후에 벌어진 전투는 무엇인가?', '이번 년도 행정고시를 통해 뽑힐 인원의 수는?', '임영웅이 이름을 알리게 된 계기는?', '최모씨가 당시 자산 규모 220억원의 업체를 사들여 유용한 금액은?', '아파트 분양 물량이 4번째로 많은 지역은 어디인가?', '복지 서비스에 대한 중장기 로드맵의 필요성을 얘기한 사람의 이름은?', '확증 편향을 소재로 한 작품의 제목은?', \"Tiny 프로젝트'의 소개가 이뤄지는 행사는?\", '중국의 부동산 경기 활성화 대책 이후, 1주택 보유자는 집값의 몇 %까지 담보대출을 받을 수 있는가?', 'G20이 IMF에 테이퍼링 시나리오 검수를 맡기도록 한 것은 어느 나라의 의견인가?', '고토 신페이가 제도부흥계획을 만든 이유는?', '매화마을 1단지의 리모델링 전 가구수는?', '그림에서 귀걸이와 팔찌가 장식된 인물은?', '현대모비스 협력사 임직원들이 간담회에서 공유하기로 한 것은?', '메드닌 전투는 누구의 마지막 전투인가?', '이삿짐 업체이지만 인테리어 사업도 하는 업체의 이름은?', '로마의 성벽을 확장한 인물을 기록한 사람은?', '지난 8일 신제품 발표회에 스티브 잡스가 생전 즐기던 옷차림으로 나타난 사람은?', '법무법인 바른에서 송무와 함께 장기적 관점으로 키워나가고자 하는 부분은?', '위대한 탄생은 초기에 어떤 프로그램을 모방했다고 비난을 받았나요?', '인베스코와 BG그룹플레이스를 공동구매한 회사이름은?', '올해 이전에 중국의 산업생산 증가율이 가장 낮았던 때는 몇 %인가요?', '연금저축 계약을 해지하지 않고도 중간에 돈을 찾아 쓸 수 있게 한 국가에서는 몇 %의 한도를 두었는가?', '신라시대에 만들어진 작품이라고 추측하는 근거는?', '도요타가 원예업종으로 사업을 확장하면서 유리온실을 만든 지역은?', '현재, 가전제품의 관세는 몇 퍼센트인가?', '전기와 전자가 서로 유도하는 원리를 활용해 만든 물건은?', '변경 전 제도에 의하면, 특별통관 업체는 최소 얼마를 보유하고 있어야 했나?', '일본 IP시스템에 관해 강연하는 사람의 직책은?', '김균섭 사장의 후임이 결정될 때까지 대리로 사장 업무를 보는 사람은?', '석동현이 의식한 최근의 수해는 어떤 도시에서 발생했는가?', '헤레라가 처음으로 패션쇼를 개최한 나라는 어디인가?', '외계인이 주인공을 괴롭히는데 사용한 것은?', '속도제한 구간에서 자동으로 감속해주는 기술은?', '독립 운동가들의 고단한 삶에 대한 기록물은 언제 공개되었나요?', '새우를 죽음에 이르게 할 정도의 영향을 주는 바이러스는?', '규제로 인해 어떤 종류의 매장이 증가했는가?', '한은이 장기적 차원에서 투자규모를 확대해 나갈 방침임을 밝힌 외화의 종류는?', '두위밍이 창춘 시를 점령한 해는?', '완전 자본잠식이 우려되는 기업은?', '북지황군위문단 파견에 지원을 해준 기구는?', '바이두가 산 회사에 자본을 제공한 회사는?', '볼세비키에 참가해 볼세비키의 군적 역량을 강화시킨 사람은 누구인가?', '숲과 나눔이 주최하는 행사가 열리는 장소는?', '리싼치가 현재 근무 중인 회사에 입사한 시기는?', '카리용 전투에서 영국 육군이 조지 호수 해안에 상륙했을 때, 그곳에 방치되어 있던 물자와 무기는 어느 나라 군대의 것이었나?', '무엇을 감소시키기 위해 조현병 치료제를 꾸준히 먹어야하나요?', '2008년에 가족친화인증제도의 인정을 받은 기업은 몇 개인가?', 'CES에서 기조연설을 한 사람 중, 자동차 기업의 대표를 맡고 있는 이의 수는?', '연역법과 같이 수학에서 증명하는데 사용할 수 있는 방법은?', '스트라빈스키가 \"스위스 시계 장인\"이라고 칭한 인물이 사망한 해는?', '전국 아파트값 상승률이 가장 적었던 정부시기의 대통령의 이름은?', '헨나 호텔에서 고객 인증을 위해 설치한 장비는?', '최고의 실내악 공연장은 언제부터 이용할 수 있나요?', '박해룡이 빈번하게 사용하는 그림 소재는?', '관료 출신이 회장이 되었다는 이유로 출근하지 못하고 있는 인물은?', '신흥 경제국의 자본이 빠지게 된 이유는?', '후타마타구치 전투가 일어났던 달은?', '서울 아파트의 평균 임대수익률 4위를 차지한 자치구는?', '1993년 두산그룹이 맥킨지에 의뢰했던 업무는?', '8명 이상의 노동자를 고용하여 영리활동을 하는 경제조직은 언제 이후부터 출현하였나?', '심노숭의 배우자가 사망한 해는?', '음향기기에서 외부소음을 줄여주는 기능은?', '김영철 변호사가 KCL에서 일하기 시작한 때는 언제인가?', '대선 보도 진단 연속 세미나가 주최되는 건물은?', '컴투스 모바일 게임 중 굿바이2020 꾸러미를 제공하는 게임은?', '김남윤이 교수 생활을 시작한 때는?', 'PP에 대한 33% 매출점유율 규제 적용을 사실상 받지 않는 방송시장은?', '포랭과 로트렉, 도미에의 공통된 성향은?', '오바마 대통령은 백악관에서 누구와 협의하였는가?', '펜트하우스가 있는 건물의 층 수는?', '실버 암보험 연간 보험료가 가장 저렴한 보험사는?', \"2020 마스크팩 어워즈'가 끝나는 날은?\", '오자와가 핼시를 꾀어내기 위해 손실을 감수한 것은?', \"자이드 미래 에너지상'의 접수 마감일은?\", '국내에서 박사학위를 취득한 외국인 중 네 번째로 많은 국적을 차지하는 나라는?', 'ABP 출장소가 있는 장소는?', '애널리스트들이 등재되어 관리되는 곳은?', '한국전력은 본사를 어디로 옮기는가?', '차명거래가 위법에 해당하지 않는 품목은?', '난방비 지원에 투입되는 총 예산은 얼마인가?', '코르비니아노가 비판한 인물은 누구와 혼인하였나요?', '레닌그라드 제품보다 결점이 적은 전차포를 생산하는 공장은 어디인가?', '업데이트가 된 세인트헤이븐의 정보를 알려주기 위해 만들어진 것은?', '한나 아렌트가 악의 평범성에 대해 이야기한 저서는?', '유브이알의 기술이 발표되는 날은 언제인가?', '작년 전국 공동주택 공시가격의 상승률은?', '영덕군 주민 투표는 며칠 동안 진행되는가?', '반기문 사무총장이 방문 예정인 달에 22일간 설치될 등의 개수는?', '이보 안드리치가 시집 <알리야 제르젤레즈의 여행>을 발표한 해는 언제인가?', 'SIECA 소속 국가들의 전년도 GDP를 합산한 금액은?', '현 사태에 대한 미 정부의 대응에 긍정적 신뢰를 표시한 인사는?', '작년 1억달러 이상 초호화 주택의 거래 건수는?', '안희정 지사가 참여하는 팸투어가 이루어지는 날짜는?', '옐로모바일이 최근 인수한 인도네시아 회사는?', '월세 60% 공제 혜택을 받을 수 있는 최대 연 소득액은?', '폴이 어릴 적 성적으로 흥분을 느꼈던 대상은?', '캄보디아 여당의 이름은?', \"휴가에 '뱅크 2.0'을 읽고자 하는 사람 이름은?\", '<수도원에서 배우는 경영의 지혜> 속에서 등장하는 신부가 수도원의 재정을 관리한 햇수는?', '일월회가 창설된 곳은?', '신흥국 위기론의 부풀려진 단면을 지적하며 그 근거로 기디언 라크먼이 예를 든 나라는?', '6개월 무이자 할부를 할 수 있는 사람이 받는 상품권 액수는?', '고교생용 국가영어능력평가시험을 개발한 곳은?', '전체의 95%가 5만원이 넘는 상품으로 구성된 선물세트는?', '19세기 가곡이 성행하는 데 큰 역할을 한 인물은?', '블룸버그상품지수를 계산할 때 사용된 원자재의 개수는?', '대제학을 지낼 수 있는 유일한 사람은?', '아반떼 모던에 적용되는 세금의 기준은?', '김승유가 국제경영특강을 진행한 시기는?', '기관이 특별공급 대상자를 전체의 15% 비율로 선정하고자 할 때 필요한 것은?', '2016, 2017년 동안 초록우산어린이재단이 도움을 준 기관의 수는?', '세종대 국제학부의 사업을 대학 특성화 사업으로 채택한 부처는 어디인가?', '대한상공회의소의 설문 결과, 절반 이상이 선택한 답은?', '최초의 점성술 체계는 언제 등장했나요?', '우리은행에서 스마트폰으로 대출받을 수 있는 최대 한도는 얼마인가?', \"렉스'의 뼈를 만든 물질은?\", '이명희가 입사 이래로 세 번째로 맡은 직책은?', '이랜드그룹에서 2008년 이후 처음으로 분양하는 아파트의 위치는 어디인가?', \"글로벌 강소기업' 중 상장회사는 몇 개인가?\", '나스닥에 두 번째로 많은 기업들을 상장한 나라는?', '아들이 무엇을 옮겼기 때문에 아들의 어머니가 돌아가셨나?', '이를 빈약한 용이라 여긴 국가는 어디인가?', '1995년 사단법인 인가를 받은 곳의 현 회장 이름은?', '카를이 교황으로부터 신성 로마 제국 황제관을 부여받은 장소는?', '민간 CEO가 손보협회장에 선임된 건 몇 년만의 일인가?', '옛날 어부들이 육수를 만들기 위해 사용했던 것은?', '대학생들의 스타트업 인턴경험이 창업가능성을 높인다고 한 사람은?', 'G6에 소속된 회사는 총 몇 개인가?', '국민연금 가입자의 평균소득 상승의 결과로 수령액이 오른 연금은?', 'ST가 새롭게 내놓은 쇼트키 다이오드의 정격전류의 범위는?', '시에라 네바다 산맥에서 할 수 있는 스포츠는?', '인천공항의 창고 활용도를 높이기 위해 조정한 건폐율 수치는?', '조양호 회장에게 한진해운의 경영권을 넘겨받은 사람은 어떤 관계인가?', '연령에 따라서 디자인을 조절할 수 있는 물건을 낸 회사는?', '남자친구를 잃은 슬픔에 대해 《Moonlight Shadow》에서 말한 인물은?', '최경환이 환영의 말을 전한 행사가 있었던 장소는?', \"국내 조선 '빅3'가 주최한 회의가 진행된 도시는?\", '전산학 발전 초기단계에서 아끼고자 했던 자원은?', '어떤 사건을 배경으로 새로운 여객선 정책이 등장했는가?', '페라리 로마가 입상한 시상식이 처음 열린 해는 언제인가?', '에너지 기본권의 의미를 포함하는 법 조항은?', '진나라에 복종하려 했지만 대부들의 저항이 심했던 나라는?', '5년간 1조 2000억원을 투자하겠다고 밝힌 기업의 대표 이름은?', '군사 전초 기지의 용도로 쓰인 도시는 언제 만들어졌나요?', '정조가 태어난 해는?', \"짜오차이바오'를 판매하는 회사의 지급결제사는?\", '환율 변동폭에 대한 회의가 열리는 날짜는?', '우미린 센트럴파크의 최고 층수는?', '학군이 좋은 곳에 있는 집을 의미하는 말은?', '수도권 KTX의 수혜지로 언급된 아파트 이름은?', '스웨덴의 비르지타가 일찍이 스웨덴 왕실과 깊은 관계를 맺도록 기여한 인물은?', '이다혜의 아버지는 무슨 종목을 하던 사람이었나?', '전조선축구대회에서 이영민과 라이벌 관계로 경기를 뛴 선수는?', '1874년 귀국 이전 쓰보이가 머물던 국가는?', '음악 저작권 처리 과정의 다양한 예에 대해 설명할 사람의 이름은?', '우에르타가 통치권을 가지고 있었을 때, 그를 옹호한 국가는?', '배임죄가 위태범 또는 위험범이 되는 나라는?', 'GS샵이 제조사와 연결을 지원해준 디자이너 이름은?', '삼성전자 주요 인사들이 다같이 어벤져스를 볼 영화관이 있는 지역은?', '아폴로13의 우주비행사를 지구로 귀환시키는 데 활용된 이론을 만든 사람은?', '12일 방하남 장관의 특강이 열린 교육기관은?', '삼성 SDI와 하나가 된 삼성계열사는?', '신동빈의 명령으로 인사를 앞두고 처음 개최하는 회의는?', 'GSK에서 누구의 의견으로 사장실이 사라졌는가?', '아부나얀 회장이 저가수주 문제 해결 방안으로 거론한 대상국들이 속한 대륙은?', '건당 배송 수입 500원을 지급하는 회사 이름은?', 'KT가 에너지 관제센터를 세운 지역은?', 'TAIT가 설계한 공연기술이 활용된 뮤지컬은?', '이랜드는 며칠에 표창을 받았는가?', '기업공감 원스톱서비스를 이용한 후 에이알텍의 연매출은 얼마나 증가했는가?', '산업활동동향이 두 달째 하락세인 산업은?', '메디치 가문의 몰락 후 토스카나를 넘겨받은 사람은?', '일본식품시장의 해외인수합병에 영향을 준 내수시장의 직접적인 원인은?', '자산 2조원 이상의 기업에 적용되는 법안이 이사회의 감독 기능과 분리하고자 하는 것은?', '인도에 처음으로 설립된 초코파이 공장은 어느 도시에 있는가?', '동화사 석조비로자나불이 제작될 때, 당시 임금은 누구였는가?', '조 수석의 배우자가 예금을 넣은 저축은행은 모두 몇 곳인가?', '정약용이 가장 중요하게 생각한 독서법은?', '작년에 비해 메리바 판매량의 감소율은 얼마인가?', '8월 이후 2개월 연속으로 수치가 줄어든 것은?', '한국의 주먹밥과 비슷한 일본의 음식은?', '불공정거래 혐의로 입건된 삼성전자 직원이 산 주식은?', '동서발전의 모회사는 어디인가?', '하스타티들이 사용하지 않은 무기는?', '세미놀과 협상을 시도했던 인물은?', \"아프리카의 여왕'이 단 하나의 스크린에서만 상영한 동기는?\", '바르나 십자군의 구성국가는?', '딜로직의 조사에 따른 인수합병 자문 8위를 차지한 글로벌 투자은행의 자본 규모는?', '국기 중앙에 자리잡고 있는 국장은 어디에서 따왔는가?', '단양 우씨 마을의 유래에 관한 사연이 있는 나무는?', '윤치호의 사망원인은?', '올해 IFA에서 삼성의 생활가전 전시가 차지하는 면적은 몇 ㎡인가?', '글로벌 500대 기업 CEO 중 게이오대 출신은 몇 명인가?', \"시그널'을 제작한 회사 대표의 이름은?\", 'B형 항성보다 비이형 별의 스펙트럼에서 더욱 뚜렷하게 나타나는 현상은?', '어머니가 모든 재산을 가지고 사라졌다는 소식을 전해준 사람은?', '전국경제인연합회에 전용 빌딩이 처음 생긴 해는?', 'CMV에서 2위한 차의 이름은?', '유숙열의 두 번째 근무지는?', '꿀풀목 가운데 가장 큰 과와 생김새가 비슷한 과는?', '유방암 건강강좌의 첫 번째 강좌명은?', '페라타 제6군단은 기원전 41년에 누구와 동방에 있었나요?', '아카데미 시상 이전에 러닝 투 스케이트보드 인 어 워존이 상을 받은 시기는 언제인가?', '러시아가 ISIL과 타 반정부 단체와 전투를 벌인 년도는?', '릴레이 기부 콘서트가 시작한 시간은?', \"섀도우버스 코리아 오픈 2020 시즌 1' 8강 경기가 열린 첫날은 며칠인가?\", '콘티넨탈과 함께 음향 기술로 수상을 이끌어낸 곳은 어디인가?', '이승철, 이동근 등의 일행이 의장실에 가기 전 새누리당 사람들과 의논한 법은?', '코흐보다 4년 앞서 노벨상을 받게 된 인물은?', '돔 아트홀에서 열리는 공연의 이름은?', '심우섭을 모티브로하여 만든 인물이 등장하는 책 제목은?', '상반기 대비 상승폭이 둔화될 것으로 예상되는 지표의 전년 대비 올해 상승률은?', '한국판 뉴타입의 간행이 폐지된 해는?', '뚜껑이 조롱박 꼭지를 닮은 작품의 이름은?', '버넘이 허빅-아로천체를 찾아냈을 때, 사용한 물건은?', '펜타곤을 방문한 박근혜 대통령을 위한 의장행사 식순의 네 번째는?', '행복공감봉사단 1차 활동이 진행된 달은?', '완다그룹의 빠른 성장을 도운 핵심 요인은?', '윤종국이 64억원의 발전기금을 낸 해는?', '환경을 고려해 불스원이 향기캡슐 제조에 사용한 것은?', '위상수학을 상권분석에 이용하는 회사는?', '주기적으로 고혈압, 두통, 다한등의 증상을 일으키는 병의이름은?', '자산가들에레 과세가 되는 금융소득 기준액은?', '이번 황금연휴 첫째날, 순천만국제정원박람회에서 이전의 하루 최고 관람객수를 넘어선 시각은 언제인가?', '12일에 일시적으로 작동하지 않은 것은?', '10월에도 마늘값은 큰 변동이 없을 것이라고 예측한 사람의 이름은?', '임시판관에 임명된 사람의 2010년 당시 직책은?', '시기적으로 가장 나중에 출시되는 유니티의 버전은 무엇인가?', '이성당 본점이 있는 도시는?', '게를리히는 누구의 제보를 기사화했다가 히틀러에게 쫓기게 되는가?', \"마플샵'을 운영하는 회사의 대표의이름은?\", '천연두에 감염된 모든 사례 중 출혈성 천연두는 얼마의 비중을 차지하는가?', '다우케미칼 다음으로 정치자금을 많이 제공한 기업은?', '흰다리새우와 블랙타이거새우는 양식 새우의 몇 퍼센트를 차지하나요?', '주요은행 중 고객의 계좌 이동이 제일 빈번히 발생한 은행은?', '혈액암 4기를 극복한 신문 기자는 얼마 동안 투병을 하였는가?', '키카이다와 권투사 군단이 결투를 벌였던 장소는?', '교황 우르바노 2세가 그레고리오 7세를 원조했을 당시 그의 직책은?', '기술에 자신있다면 협력사라 해도 을이 아니라고 말한 사람의 이름은?', \"프레디 머큐리 대타로 '슈퍼소닉'에 서게 되는 사람은?\", '지난해 4년제 대졸 신입 사원의 평균 초임은 올해보다 몇 % 더 적었나?', '어떤 회사가 에틸렌을 80만t까지 만들어내는 능력을 가지고 있나?', '2·3·9광구를 낙찰받은 이탈리아 기업이 가진 지분은?', '올해 최고가로 거래된 아파트가 건축된 연도는?', '현대건설의 첫 번째 중동 진출국은?', '남조식물의 세포벽을 구성하는 주요 물질은?', '1895년에 서재필이 숨어있던 곳은?', '동로마 제국의 총대주교가 불가리아 총대교구를 정식으로 인정한 것은 어느 왕이 죽고 난 뒤인가?', '두 개의 지역으로 줄어든 후에 킬리키아의 명칭은 무엇으로 변경되었나?', '엑소세스템즈의 사무실이 있는 곳을 관리하는 주체는?', '세무공무원의 성과평가 방식을 상대평가에서 절대평가로 바꾼 회의가 열린 장소는?', '이웅 차장이 이용한 커리어마켓의 공간은?', '중국인 관광객에게 여행 정보를 알려주는 앱은 무엇인가?', '강다니엘이 처음으로 혼자 낸 노래가 천만 뷰를 달성하기까지 얼마나 소요되었는가?', '2011년 크리스마스에 열린 대부분의 축구 시합에서 내국 병사는 누구를 상대했는가?', 'SK 신입사원과의 대화를 시작한 사람의 이름은?', '기동전사 건담 SEED 중 만화판과 다르게 묘사된 화는?', '음악을 재생할 수 있는 삼성의 응용프로그램 이름은?', '스탠퍼드 동문기업의 연간 매출액은?', '메릴린치가 BoA에 넘어가고 흡수합병되기까지의 기간은?', '한독의 2011년 매출은?', '루돌프는 누구 다음으로 죽었는가?', '대한변협이 헌법재판소법에 대한 헌법소원을 낸 날은?', '성하 마을과 주요 도로를 정비한 연도는?', '배치 기반의 엑셀러레이팅 프로그램을 최초로 실행한 나라는?', '중상주의 시기에 콜베르는 어떤 국가의 산업을 보호하려 했나요?', '두 콘덴서 종류를 나누는 기준은?', '미에빌이 2001년 선거에 출마해 얻은 득표 비율은?', '대학원에서 수업을 듣던 시절 소설을 출품하던 곳은 어디었는가?', '고문철 사장이 출강했던 교육 기관은?', '국내 수입차 개인 구매 비중이 80%를 초과한 차량을 생산하는 나라는?', '강남규의 직장은 어디인가?', '어느 나라의 업체가 시디즈 의자 디자인을 도와주는가?', '텐스카타와의 개명전 이름은?', '토탈과 삼성종합화학이 공동으로 자본을 마련하여 경영하고 있는 회사는?', '그랜드 인터컨티넨탈에서 숙박 가능한 최고층은?', '눈 밑 지방에서 추출된 줄기세포로 쥐에게 실험한 결과가 수록된 전문 잡지는?', '전통적인 노동당 공약을 다시 내건 인물의 이름은?', '금년 베네수엘라의 물가는 몇 % 까지 증가할 예정인가?', '해외에서 돌아온 기업이 보증료 7000만원을 내면 얼마를 지원받을수 있나?', '마가다와 다이아몬드 채굴권을 협상한 나라는 어디인가요?', '특경비 사용지침을 마련한 정부 부처의 이름은?', '오스트리아 황제가 항복했던 해에 나폴레옹이 패배했던 나라는?', '올해 초에 새로 만들어진 정부부처의 이름은?', '갓반을 출시하며 각종 업체들과 협업에 개입한 11번가 직원의 직무는?', '제네시스를 가장 비싸게 사면 얼마에 살 수 있는가?', '더클래스 효성이 주최하는 캠페인의 종료날짜는?', '온라인 통합몰을 통해 가입하면 사용할 수 있는 유심을 만든 회사는?', '바빌론의 공중정원이 실존했는지 정확히 알 수 없는 이유는?', '국내 과학관 등의 시설이 소장하고 있는 자연사 자료가 총망라된 콘텐츠는?', '경제 패러다임을 창조경제로 정의한 사람의 이름은?', '메탈의 내구성이 뛰어난 이유는?', '세액 공제율이 가장 많이 올라간 경우는?', '오바마가 거부권을 행사한 이유와 관련되지 않은 특허는?', \"시계의 도시'로 불리는 지역의 명칭은?\", '1500호점는 위치는 어디인가?', '‘급격한 압력 해소(the great decompression)’라는 제목의 글을 출간한 곳은 어느 나라의 회사인가?', '기재부가 재정 다이어트를 주문한 해의 세수진도율은?', '신경림 씨가 작년에 방문한 국가는?', '새정부를 만드는데 가담하지 않은 사람은?', '이셴 층을 두가지 방법으로 측정했을 때 다른 결과가 나온 부분은?', '이번 회계연도에 900억엔을 투자한다고 발표한 사람의 이름은?', '베르니츠 강과 라슈트 강이 만나는 곳 부근에서 코네티컷 연대와 만나 전투를 벌였던 프랑스 부대는 어디인가?', '지난 6개월간 오피스빌딩의 세계 최고 가격 상승률은 얼마인가?', '밤에 임 회장을 찾아간 사람의 직위는?', '우한에 공장을 신축중인 자동차업체의 소속 국가는?', '체력아이템이 없는 경우 둘리의 체력을 회복하려면 누구를 처치해야 하는가?', '싱글생활연구소가 출간된 해에 선보인 이음소시어스의 데이팅 서비스는?', '여러 명의 생각을 합쳐 보다 많은 이익을 얻는다는 의미의 네 글자 단어는?', '독일 기사단은 누구의 지휘 아래 트란실바니아로 이동했나요?', 'LG 측 회사와 국토부, 제주도 사이에 그린 모델링 관련 계약이 성사된 시기는?', '부작용 우려가 없는 대상포진 치료 시술 이름은?', '조선인민공화국에서 최고로 높은 직위에 오른 자는?', '리골레토 개막일 공연시각은?', '한중을 공격 시, 군량과 운송이 속한 조조의 부대는?', '파라다이스시티에서 페스티브 위크를 개최하며 참여할 사람을 결정하는 방식은?', '6월에 사이버 공격으로 인해 가동이 중지된 공장은 총 몇 군데 인가?', '금융위원회에 텔레마케팅 영업제한 조치의 무효화를 요청한 기업은?', '전자태그 갱신제와 함께 도입되는 제도는?', '동화산업의 사장이 한 명이 된 시기는?', '간선도로 교통량이 최근 10년동안 두 번째로 높았던 차종은?', '모세상은 누구를 위해 만들어졌었는가?', '갤럭시노트4 S-LTE의 공시지원금을 3배 받을 수 있는 첫 날은 언제인가?', '고속 노칭 커팅 매거진 장비의 생산속도는?', '스파르타군과의 전투에서 트라쉬불로가 노예들에게 제안한 것은?', '면역력이 약해져서 아시클로버의 약효가 발휘되지 않을 때 쓰는 것은 무엇인가?', '현대산업개발이 구리갈매지구에 건설할 아파트에서 가장 가까운 지하철역은 어디인가?', '퍼거슨 시에서 흑인이 백인보다 더 많아진 년도는?', '7년이상 가입 유지시 금융소득세를 면제해주는 금융 상품은 무엇인가?', '공제율과 공제 한도를 늘림으로 주거비 부담을 더는 대상은?', '섬이 침수되더라도 섬을 지키겠다고한 사람은?', '작품에서 로즈의 남자친구 역할을 맡은 배우는?', '중국에서 제조된 H형강이 금년 1월에서 6월까지 국내에 반입된 양은?', '정 명예회장이 그린혁명을 언급한 해는?', '백제 시대에 사면불 조성을 추진한 왕은?', '직원들에게 커피를 공짜로 제공하는 회사는?', '함영주가 두 번째로 근무했던 은행 지점은?', '박근혜 대통령의 중동 4개국 순방 일정에 모두 동행하는 사람은 누구인가?', '가장 많은 지지를 얻은 기획자의 이름은?', '현재 삼성전자에서 1위 실적을 내는 사업은?', '건강기능식품에 금지된 재료를 넣은 경우 늘어난 징역형의 기간은?', '지식기반사회 변화에 부응하는 창조적 인재육성의 중요성을 말한 사람의 이름은?', '메가박스의 패키지 중 관람권이 더 많이 포함된 것은 얼마인가요?', '헥토르의 부인을 노예로 부렸던 인물은?', '인도네시아의 롯데마트가 일부 고객에게 제공하는 할인의 이름은?', '2008년 9월 29일 이후 최고치를 찍은 주식의 주가는?', '다이어트 음식으로 소비되었던 음식은?', '과거 우리나라의 전국지는 어디서 출간되었나?', 'LG 계열사 중, 영업이익률이 가장 많이 감소한 곳은?', '작년 한 해 동안 정부가 거두어 들인 세금은 얼마인가?', '일렉트로마트에서 참여할 수 있는 이벤트는 며칠에 끝나는가?', '우버의 고급 서비스만 이용할 수 있는 나라는?', '동부간선도로를 지을 때 나라에서 보조해주는 금액은?', '마사키가 라기아스에 남을 수 있었던 이유는?', '주간2교대 시행 이후 북구지역 당구장은 몇 개인가?', 'SaaS를 이용하는 회사는 어느 나라 회사인가?', 'Yoo Doo Right이 수록된 앨범명은?', '농심이 처음 신라면을 내놓은 때는?', '스트리밍도 공연보상금 대상에 포함된다는 판결이 난 재판의 피고는 누구인가?', '포럼의 1~2일차에 열리는 설명회는 몇 개의 분야를 다루는가?', '중국이 6.2%의 경제성장률을 보인 것은 얼마 전인가?', '메리어트 인터내셔널과 제휴한 호텔의 개장은 언제인가?', '롯데백화점 문화센터점에서 젊은 층의 소비에 대응해 새롭게 들인 브랜드는 무엇인가?', '노준석 교수팀에서 메타표면을 만들 때 사용한 재료는 무엇인가?', '만지로가 나카하마 성을 부여받은 해는?', '기존보다 더욱 강력한 몬스터들이 출현하는 던전은?', '이우종을 TV에서 보기를 고대하고 있는 사람들은?', '민주당 내부의 갈등을 해결하기 위해 양보한 측은?', '은빛 성기사단의 첫번째 성기사 이야기를 완료하면 받는 보상은?', '물쉼표 프로젝트는 누구를 타깃으로 하는가?', '조현아 부사장이 대한항공에서 처음 근무를 시작한 부서는?', '고속 NCM 장비의 최대 생산 속도는?', '무료 전자 잡지를 이용할 수 있는 라운지탐탐 지점은 어디인가?', \"김주원의 마그리트와 아르망'에서 아르망 역을 맡은 무용수의 이름은?\", '태광산업의 조직개편 이후, 신소재 관련팀은 무엇으로 바뀌는가?', '4월에 월매출 94억원을 기록한 약의 이름은?', '자유무역지역 입주 자격과 관련있는 법령은?', '현대자동차 면접에서 옷에 대한 규정이 없는 면접은 몇 차인가?', '창조신화는 누구에 의해 계획하고 실행된 것으로 그려지나?', '정홍원은 검사로 활동한 뒤에 어느 기관에서 일했나요?', '코시모는 누구로부터 교육을 받았나?', '진주만 작전에서 제3차 공격강행을 반대한 인물은?', '일본 100엔숍 계열사 중 4위 회사는?', '2015년 곡물 조달사업을 주도하는 측은?', '용산관광버스터미널 부지에 들어서는 호텔의 공사가 착수되는 해는?', '1919년 비트겐슈타인의 원고를 대신 출판한 사람은?', '28일 오후에 치유 농장 관련 다큐멘터리를 방영하는 채널은?', '윈터 에디션이 주제인 행사가 시작되는 달은?', '현판에 임영관이란 글씨를 자필로 쓴 사람은 누구인가?', '류한욱이 두 번째 뇌출혈로 쓰러진 공간은?', '조작설의 근거가 되는 물건은?', '11월 11일 첫 방송하는 작품의 미래 이야기를 다룬 작품은?', '프랑스군의 옆을 공격하여 그들을 퇴각시켰던 집단은?', '앨범준비를 하고 있는 가수와 게스트로 방송에 나간 사람의 이름은?', '뮌헨 협약을 통해 전쟁을 모면하려고 했던 영국 총리는?', '왕망에 대한 계략을 꾸민 이들 중 주살되지 않은 이는 누구인가?', '칠갑산 암각화의 그림은 어떠한 방식으로 표현되었나?', '세종시와 과천 땅값 변동의 공통 요인으로 작용한 것은 무엇인가?', '발코니 확장비를 지원하는 아파트는?', '서울대학교 다음 총장으로 출마한 후보 수는?', '높은 기온과 과식으로 인해 유발되는 증상은 무엇인가?', \"번지 점프를 하다'의 첫 공연이 열린 때는 언제인가?\", '밀월 관계로써 미국이 지속적으로 보급하고 있던 것은?', '생활편의시설을 공유할수 있도록 아파트 단지내에 조성되는 오피스텔을 지칭하는 말은?', '경기를 홍보하기 위해 언급된 사람은?', \"보스포러스 제3대교'의 주탑 건설 공사장의 책임자는 누구인가?\", '행복주택 사업승인을 받은 지방 가구 수는?', '24일에 희망스튜디오로부터 태블릿 PC를 기부받은 곳은?', 'SKC솔믹스가 불량률을 줄이기 위해 개선하려는 것은?', '관중석이 가득 찼다고 전한 인물과 대화한 사람의 이름은?', \"LH 비발디'와 'LH 꿈에그린'를 보금자리주택으로 분양하도록 한 대통령은?\", \"휘리리후 휘리리후'를 볼 수 있는 것은 며칠까지인가?\", '쿠팡에 10억 투자한 회사를 이끄는 인물의 이름은?', '권성 전 재판관이 진보적 민주주의를 빗대어 변론으로 인용한 문구는?', '제재금 관련 규정을 불공정하게 만든 손해보험사는 몇 군데인가?', '망포역까지 걸어서 10분 거리에 위치한 아파트는 무엇인가?', '미군이 충원되지 않으면 서울이 전쟁 시작 후 2주만에 함락될 것이라 밝힌 문서는?', '13~23일 기준, 대한항공의 동남아노선 예약률은?', '4개 기업이 강의하는 행사는 언제부터인가?', '김집이 몸이 아파서 내려놓은 관직은?', '쇼보트 카지노의 영업 기간은?', '한위수가 판사를 그만 둔 연도는?', '자동차 튜닝 규제에 관한 건의가 나온 날은 며칠인가?', '주인공에게 매번 살려달라는 간청을 받았던 인물은?', '아다케부네가 제작 된 시대는?', '최고경영자들의 모임인 삼성 수요사장단회의 이전 명칭은?', '자녀가 어른이 아닌 경우 증여세 감면 범위는 얼마인가?', '이번 면세점 특허는 몇 사람이 심사하는가?', '포커스온유의 행사가 시작되는 날짜는?', 'LG 트윈타워에서 임원세미나가 열렸던 날짜는?', '2020년 하계올림픽 개최지를 결정하는 투표에서 도쿄에게 밀린 곳은?', '이인종 부사장이 대통령상을 수상한 날은 언제인가?', '현대자동차와 함께 스마트카를 개발하려는 정보기술(IT) 업체는?', '할머니가 노이에 대한 걱정을 이야기했던 인물은?', '기간 한정 특수 서버의 회원들이 캐릭터를 이전할 수 있는 날은 언제부터인가?', '박 대통령이 스탠퍼드대 연설에서 처음 사용한 말은?', '닭고기 소비량에 큰 영향을 미칠 것으로 예상되는 질병은?', '스웨덴 총리와 독일 총리가 만난 지역은?', '작년 국산 자동차는 해외에서 얼마나 팔렸나?', '세계에서 글을 읽지 못하는 성인은 몇 명인가?', \"페코타'를 만든 인물의 이름은?\", '사슴 동상이 위치한 동은?', '평택 소사벌 중흥S-클래스에서, 부엌에 큰 창고가 있는 가구 수는?', '업로드와 다운로드 시 같은 주파수 대역을 쓰는 LTE 방식은?', '피에르 루이지 반대 세력이 지지했던 사람은?', '컵라면 매출에서 불닭볶음면을 이긴 상품은?', '161개의 집터 근처에서 발견된 석실묘의 개수는?', '홍콩을 온라인으로 여행할 수 있는 무료 행사는 몇 월 며칠에 시행되는가?', '낮은 월급 대신 복지를 지원받는 고용 형태가 법률로 제정된 년도는?', '기업에서 오픈프라이즈를 활용할 수 있는 분야는?', '잘못된 진실 덕분에 새로운 땅을 개척한 사람은?', '이호제가 통솔했던 부대가 거의 궤멸된 시기는?', '전래식 화백의 작업실이 위치한 지역은 어디인가?', '특검팀에 파견되었던 인물의 이름은?', '‘BMW M 클래스’가 넥센타이어에게 후원을 받고 있는 타이어의 장점은?', 'KB 중개업소 회원들이 평가하기에 집값 상승에 두 번째로 영향을 미친 것은?', '김광진이 과거에 연습을 구경하곤 했던 농구 선수의 이름은?', '웹어워드 코리아 2020에서 대상을 받은 웹의 주제는?', '신문 <파시스트 정권,Il Regime Fascista>의 주된 논조는?', '현대어린이책미술관 개관 그림책 전시회의 테마는 무엇인가?', '트리마제 아파트는 언제부터 거래되기 시작했는가?', \"한양대학교 대학원생이 '스마트 계약 및 탈중앙 애플리케이션'을 들을 수 있는 첫 번째 날은?\", '올해 8월 말 기준 60세 이상인 카드회원 수는 몇 명인가?', '남학생 선호 2순위 향수 브랜드는 무엇인가?', \"아! 나는 사랑했었네' 를 부른 사람의 이름은?\", '돈 봉투를 건네주라고 명령한 사람으로 의심 받은 사람은 누구인가?', '멜론 이용자와 아티스트 간의 소통을 목적으로 진행된 이벤트는?', '호프만 폭동이 수습된 해는?', '러시앤캐시는 광고를 통해 어떤 회사라는 이미지에서 탈피하고 싶어하는가?', '동승콜로 택시를 잡을 수 있는 시간대는?', '브릴리언트 아이디어 1화에서 다루는 인물은?', 'CJ오쇼핑에서 가장 많이 판매된 브랜드의 이름은?', \"삼성물산을 '머시 게이트웨이' 프로젝트에 초청한 회사는?\", '비행기가 추락할 때 첫 번째로 떨어진 것은?', '주말 방송가를 장악한 프로그램 중 김건모가 출연한 프로그램의 시청률은?', '클라우제비츠가 군인이 된 것은 누구의 영향인가?', '퍼스트 스트라이크 선발전에 출전하는 상위 8개 팀이 경기를 시작하는 날짜는?', '금수원 신도와의 충돌을 막기 위한 대책이 이루어진 곳은?', '비행기를 통해 입국하는 사람들이 반드시 써서 내야하는 것은 무엇인가요?', '베트남에서 일어난 시위의 원인으로 중국이 억지로 실행한 것은?', '신창재가 재무설계사들을 격려하기 위해 낭송한 시는 누구의 작품인가?', \"해군기지 결사반대'를 외치며 공사차량을 막은 인물의 직업은?\", '롯데월드타워가 들어서는 동네의 현재 3.3㎡당 전셋값은?', '남양주~서울 강남 구간을 30여분 만에 이동하기 위해 이용할 수 있는 길은?', '농지법을 개혁할 당시 카이사르의 직위는?', '민생과 경제살리기 법안에 집중해야 한다고 주장한 사람의 이름은?', '프란치스코 교황이 청와대에 오기 전 방문한 동네는?', '연희의 직업은?', 'LNG선과 해양플랜트 부문에서 안정적으로 흑자를 내고 있는 회사는?', '자기 삶의 전환점이 되었던 질문을 책에 실은 저자는?', '특별인출권 바스켓통화 변경 심사가 원래 예정되었던 달은?', '신장기능 평가수치를 비교 연구한 교수팀이 속한 대학은?', '프리미엄 혜택을 받기 위해서는 얼마의 금액이 드는가?', '지급되는 교육·연구 지원금은 총 얼마인가?', '다이어트시 근육을 유지 및 증가시키기 위해 섭취해야 하는 영양소는?', \"투란도트' 광저우 공연을 지휘한 사람은?\", '오늘날 역사적인 장소로 알려진 곳은?', '프란치스코 교황의 즉위를 축하하기 위해 국내에서 미사가 열리는 날짜는?', '지난 1~9월에 전체 공항 이용객 중 환승객 비중인 환승률은 몇 퍼센트 떨어졌는가?', '다음 세계교육포럼이 열리는 해는?', '작년 정부가 세월호 사고에 사용한 사고수습 비용은?', '대학 총장들이 대학교육에 두 번째로 가장 영향을 많이 주는 것으로 꼽은 정책은 무엇인가?', '2020 NeurIPS에서 뽑힌 논문을 작성한 곳은?', '20일 기준 아모레퍼시픽 회장이 보유한 상장 주식의 총 가치는 얼마인가?', '모두의마블이 연상케 하는 게임은?', '이번 모의평가에서 다른 과목과 달리 영어는 어떤 형태로 시행되었는가?', '한국벤처투자가 고른 운용사 개수는?', \"침묵의 봄'은 어느 해에 나왔는가?\", '박장적 부회장의 경영진 자리에서 내려온 이후의 직책은?', '23일 SK하이닉스 주식의 종가는?', '영어로 의사소통하는 식당 중 피자를 판매하는 곳의 이름은?', '중국 1위 부자는 완다그룹 회장이라고 밝힌 곳은?', '전라북도가 현재까지 살처분한 오리의 수는?', '주택담보대출시 5년 이내에 대출을 갚을 계획이라면 어떤 금리를 선택하는 것이 유리한가?', '대청아파트의 기존 리모델링 시공사는?', '테마기획전에서 국산 RV 차량을 선보인 기업은?', \"Moon' 선수가 'Eer0'선수를 3:0으로 이긴 날은?\", '12년간 일했던 사외이사의 임기를 늘린 회사는 어디인가?', '윤치호의 아내는 누구의 부인을 방문했나?', '나카무라 슈지가 졸업한 대학은?', '정부 실태 조사에서 배제된 기관은 몇 군데 인가?', '성현의 위패를 모시는 곳이 위치하는 방향은?', '광둥 음운 강의를 했던 사람의 이름은?', '스퀠쾨더가 남군 해군에 인도된 시기는?', '해피랜드의 매출에서 골프의류가 가지는 비중은 얼마인가?']\n",
            "1203\n",
            "{'guid': ['844e22ab28924c1697d5ac28801b34c1', '31650c1dfb3a46c09c6600cfc31b1ec4', '925dbda8c7a0474a832b87e99c6afaec', 'f15f6ce1a422400c951878df7649b12d', '2824772bc3ce4aaba089c192b30a7dc3', '73c4446c192846208336410e3bfe9d05', 'f0f59825d2634635a4615476a506a4e9', '6253d0278e264a28a048f8bf986b8b57', 'dfe026ffcaf24af9862df6d77b5a183b', '517499a00e6648df8dbf2983dfa7d8f0'], 'context': ['지난해 주요 연극상을 나눠 가졌던 세 편의 작품이 올봄에 나란히 앙코르 무대를 갖는다. 대한민국연극대상 연기·무대예술상, 동아연극상 작품·희곡·연기상 등을 수상한 ‘알리바이 연대기’(17~20일 대학로 아르코예술극장 대극장, 25일~5월11일 서계동 국립극단 백성희장민호극장), 연극대상에서 대상과 희곡상을 받은 ‘여기가 집이다’(18일~5월22일 대학로 연우소극장), 연극대상 작품·연출상과 김상열연극상 수상작인 ‘황금용’(5월9~18일 서강대 메리홀 대극장)이다. 초연 당시 짧은 상연 기간과 낮은 인지도 등으로 공연을 놓친 연극팬에겐 평단으로부터 작품성을 인정받은 수작을 관람할 수 있는 기회다. ‘알리바이 연대기’는 희곡을 쓰고 연출한 김재엽의 가족사에 근거한 다큐멘터리 드라마다. 1930년에 태어난 한 개인의 사적인 연대기를 바탕으로 그 사이를 파고드는 역사적 순간들을 정밀하게 조명한다. 연출가는 “공적인 권력이 사적인 권리를 지켜주기보다 억압하기 일쑤였던 한국 현대사 속에서 개인은 언제나 무죄를 입증하며 하루하루 자신을 지켜내야 하는 ‘알리바이의 연대기’ 속에서 살아왔다”고 말한다.한국연극평론가협회는 이 작품을 ‘2013년 올해의 연극 베스트3’로 선정하며 “촘촘하고 세세하게 삶에 천착해 개인과 역사에 대한 이분법적 관점을 극복한다. 정치극에 대한 새로운 가능성을 보여줬다”고 평했다. 이 작품으로 연기상을 휩쓴 남명렬을 비롯해 지춘성 정원조 등 초연 배우들이 그대로 출연한다.‘여기가 집이다’는 허름하고 볼품 없는 ‘20년 전통’의 고시원에 모여 사는 사람들의 절망과 희망을 그린 작품. ‘차력사와 아코디언’ ‘택배 왔어요’를 만든 극단 이와삼의 장우재 대표가 직접 대본을 쓰고 연출했다. 나름의 규칙을 가지고 평화로웠던 고시원에 새로운 주인으로 등장한 ‘20세 고등학생’ 동교가 “이제부터 고시원 식구들에게 월세를 받지 않겠다”고 선언하면서 갑작스런 변화의 바람이 분다.날것 그대로의 직설 화법으로 풀어 놓는 풍성한 인생 이야기와 생동감 넘치는 극적 구조로 ‘집’의 본원적 의미와 삶에 대한 성찰의 기회를 제공한다는 평가를 받았다. 재연에서는 중견 배우 김세동이 장씨 역으로 출연해 박무영 김충근 한동규 류제승 김정민 등 초연 배우들과 호흡을 맞춘다.독일 극작가 롤란트 시멜페니히가 쓴 현대극 ‘황금용’은 독일 소도시에 있는 아시아계 간이식당을 배경으로 현대 물질사회와 세계화 속에 가려진 욕망과 폭력, 소외를 그린다. 치통을 앓지만 불법 체류자 신분으로 치과에 가지 못하는 한 젊은 중국인 요리사는 결국 비참한 최후를 맞는다.작품을 연출한 윤광진 용인대 교수는 “극의 배경은 유럽의 한 소도시이지만 서울이나 경기 안산의 어느 거리에서 일어나는 듯 우리에게 가깝게 다가오는 작품”이라며 “지하철에서 마주치는 외국인 근로자들, 그 옆에서 졸고 있는 우리의 이야기”라고 말했다. 이호성 남미정 이동근 한덕호 방현숙 등 초연 배우들이 다시 뭉친다.', '정부가 저축은행의 수익성 확보를 위해 내년 2월부터 펀드와 보험, 신용카드 판매를 활성화하기로 했다. 또 지역 밀착형 서민금융회사라는 저축은행 본연의 기능을 강화하기 위해 비 수도권 저축은행의 지역 내 점포 확장 기준을 완화해주기로 했다.금융위원회는 17일 이 같은 내용을 골자로 한 ‘저축은행의 건전한 발전을 위한 정책방향’을 발표했다. 금융위는 우선 펀드판매와 할부금융 등 법적 근거가 필요한 업무는 세부 시행기준을 마련해 활성화하기로 했다. 저축은행의 펀드판매는 불완전판매가 최소화되도록 기준을 마련해 제한적으로 허용된다. 할부금융은 하위 법령이 정비되면 내년 2월부터 취급할 수 있게 된다. 보험과 신용카드는 저축은행중앙회가 카드·보험사와 계약 후 모든 저축은행에서 판매하는 방식으로 추진된다.금융위는 아울러 여신심사 능력을 갖춘 저축은행을 선별해 △정책금융공사의 온렌딩(중소기업 간접 지원)대출 △주택금융공사 보금자리론 △미소금융 등과 같은 서민과 중소기업 대상 정책자금도 취급할 수 있도록 할 방침이다.영업실적이나 대출모집인 활용도를 평가해 지역밀착형·관계형 영업을 충실히 수행하는 저축은행에 대해서는 영업구역 내 점포를 신설할 때 증자요건 등을 완화(수도권 제외)해 주기로 했다. 금융위는 또 저축은행이 체계적인 신용평가를 통해 금리를 적용하는 대신 높은 수준의 최고 금리를 적용하는 경우가 많다는 지적에 따라 신용평가시스템(CSS)을 개선하기로 했다. 자체 CSS가 있는 대형 저축은행의 경우 은행권 수준으로 시스템을 발전시키고, 자체 CSS 구축이 어려운 저축은행은 중앙회의 표준 CSS를 활용하도록 하는 방식이다.금융위는 다만 서민 대출이 늘어날 것으로 예상됨에 따라 소액신용대출 비중이 높은 저축은행의 관리·감독을 강화하고 개별 차주에 대한 신용공여 한도(법인 100억원)의 적정성을 재검토하는 등 건전성 관리에도 힘을 쏟을 방침이다.', '전산 언어학은 인공 지능에 전제되는 분야로써 종종 다루어지기도 한다. 전산 언어학은 1950년대 미국에서, 외국어, 특히 러시아의 과학 잡지를 영어로 자동 번역하려는 노력으로부터 기원한다. 컴퓨터는 인간보다 수리적 능력이 더욱 빠르고 정확하다고 입증되었기 때문에, 기술적 세부사항에서 컴퓨터가 인간처럼 언어를 처리할 능력을 갖게 될 수 있는 것은 단지 시간문제라고 생각되었다.\\n\\n기계 번역(또한 기계적 번역)이 정확한 번역을 즉시 해내는 것에 실패했을 때, 인간 언어 자동화 프로세싱은 원래 여겨지던 것보다 더욱 복잡한 것으로 인식되었다. 전산 언어학은 언어 데이터를 지적으로 처리할 수 있는 산술과 소프트웨어의 발달에 힘입어 새로운 학문 분야의 이름을 가지고 탄생했다. 인공지능(AI)이 1960년대에 접어들면서, 인간 수준의 이해를 다루고 자연 언어의 생산을 다루는 전산 언어학의 분야는 인공지능의 하위 분야가 되었다.\\n\\n한 언어를 다른 언어로 번역하기 위해서, 각각의 언어들의 형태론과 구문론을 포함한 문법을 이해해야 했다. 구문론을 이해하기 위해서는, 또한 의미론과 사전학(또는 어휘), 심지어 언어 사용의 화용론에 대해서도 이해해야 했다. 따라서, 어떻게 표상되는가를 이해하기 위한 전체 분야로 진화하는 언어들과 컴퓨터를 이용한 자연 언어 처리 사이를 번역하기 위한 노력으로써 시작되었다고 볼 수 있다.', '소비에트 연방을 지구 역사상 제일 위험한 제국주의 국가로 분류한 마오쩌둥은 미국과의 타협 노선을 결정하였다. 이러한 결정은 현 시대의 주요 모순을 제3세계와 제국주의 국가 사이의 모순이라고 판단하고 있던 마오쩌둥 사상 특유의 입장 때문이었다. 그러나 엔베르 호자는 『제국주의와 혁명』에서 밝힌 것과 같이, 이것은 마오쩌둥 사상의 심대한 오류라고 하였다. 마오쩌둥은 『모순론』을 통하여 적대적 모순인 계급 사이의 모순이 여러 현실 조건에 따라 다양한 모순으로 화(化)할 수 있다고 하였다. 엔베르 호자는 이러한 모순론이 이오시프 스탈린의 모순론과 크게 다를 것이 없다고 하였으며, 소비에트 연방이 수정주의 영향으로 인해 사회제국주의 국가가 되었다는 것에도 동의하였다.\\n\\n그러나 이러한 이론적 기반을 ‘제3세계와 소비에트 연방 사이의 모순’이라고 판단한 것은 기존 모순론에 대한 오류적 적용이라고 하였다. 일단 ‘사회제국주의’는 레닌주의에서 일반적으로 이해되는 ‘제국주의’와 다르다. 블라디미르 레닌에 따르면, 제국주의는 자본주의의 최고 단계이다. 그러나 스탈린 사후에 등장한 ‘사회제국주의’는 자본주의의 최고 단계로서 등장하는 제국주의가 아닌, 사회주의 국가 사이 패권 행사라는 단순한 형태의 패권주의에 불과하다. 수정주의를 받아들인 1956년 이후부터 소비에트 연방 내 몇몇 부문에서 자본주의적 생산 관계가 부활됐지만 그럼에도 불구하고 사회주의 국가로서의 정체성을 확보하고 있으며, 세계 규모의 자본주의에 대항하고 있던 역할을 일정 수행하고 있었다고 하였다. 그것은 쿠바 혁명에 관한 지원, 알제리 내전 및 앙골라 내전에서의 항미(抗美) 지원으로도 드러난다. 이러한 지원은 자본주의와 사회주의 사이의 투쟁의 연장선이었다. 그러나 마오쩌둥의 논리대로라면, 이러한 투쟁을 주도하는 소비에트 연방이 동시에 주요 모순으로서 ‘제3세계와 제국주의 국가 사이의 모순’에서 반동적 입장을 지지하는 집단이 된다. 그러나 모순은 한 국가 단위로 부분적일 수 있으나 근본적으로 하나의 일관성을 향하여 진행되는 것이다. 만약 마오쩌둥의 주장에 근거한다면 소비에트 연방은 적대적 모순(본질적)의 진행이라는 의미에서 사회주의 투쟁을 이끄는 집단인 동시에, 그것이 다른 모순으로 화한 제3세계 모순에서 반동적 입장을 견지하는 반혁명의 진영이다. 이것은 명백히 모순이며 양립할 수 없는 입장이다. 적대적 모순이 어떠한 사회적 조건, 지역적 조건으로 인해 다양한 모순으로 화한다고 하더라도, 결국 그러한 파생된 산발적 주요 모순은 적대적 모순과 최종적으로 합치하기 때문이다.', '‘오네긴’ ‘잠자는 숲속의 미녀’ ‘로미오와 줄리엣’…. 발레를 좋아하는 관객이라면 이름만 들어도 두근거리는 레퍼토리를 한자리에서 볼 수 있는 공연이 열린다. 올해 서른 살을 맞는 유니버설발레단(UBC)이 오는 21~23일 서울 서초동 예술의전당 오페라극장에서 마련하는 ‘30주년 스페셜 갈라’(사진) 무대다.공연은 2부로 전개된다. 1부의 문은 ‘라 바야데르’의 주요 장면인 ‘망령들의 왕국’이 연다. 32명의 무용수들이 부드러운 선율에 맞춰 하늘에서 땅으로 천천히 내려오는 장면이 압권. 그 뒤를 이어 ‘잠자는 숲속의 미녀’ ‘돈키호테’ ‘오네긴’ ‘베니스 카니발’ ‘해적’의 하이라이트가 펼쳐진다.2부의 커튼은 UBC가 만든 창작발레 ‘발레 춘향’이 연다. 이어 ‘로미오와 줄리엣’ ‘팡파르LX’ ‘두엔데’ ‘인 더 미들, 썸왓 엘레베이티드’ ‘마이너스 7’의 주요 장면이 공연된다.이번 공연엔 UBC의 30주년을 축하하기 위해 세계적인 무용수들의 특별 무대가 마련됐다. 서희(아메리칸발레시어터 수석무용수) 강효정(슈투트가르트발레단 수석무용수) 알렉산더 존스(슈투트가르트발레단 수석무용수) 이고르 콜브(마린스키발레단 수석무용수) 이반 푸트로프(전 로열 발레단 수석무용수)가 UBC를 축하하는 무대를 꾸미기 위해 내한했다. 황혜민, 엄재용, 강미선, 콘스탄틴 노보셀로프, 김나은, 이승현 등 UBC의 스타 무용수와 군무진도 풍성한 무대를 만들 예정이다.러시아의 마린스키 발레단을 23년간 이끈 올레그 비노그라도프가 연출을 맡았으며, 미하일 그라노프스키 볼쇼이극장 지휘자가 강남심포니 오케스트라와 함께 연주한다.  1만~10만원. 070-7124-1737', '“고령자를 위한 스마트폰 애플리케이션(앱) 등 특화된 혁신 기술이 있다면 폴란드에서 창업을 시도해볼 만합니다.”휴버트 레빈스키 폴란드 창업개발부 선임연구원(사진)은 “스타트업(신생 벤처기업)이 폴란드 창업 시장을 이끌고 있는 데다 스타트업을 지원하는 엔젤투자 시장의 저변도 넓어지고 있다”며 폴란드에서의 창업을 권고했다.폴란드 창업개발부는 중소기업의 금융지원 주선과 창업 상담을 맡고 있는 정부 기관이다. 폴란드 기업뿐 아니라 해외 기업도 지원 대상이다.레빈스키 선임연구원은 “현지 상황 변화에 맞는 스타트업이면 더욱 좋다”며 고령자를 위한 스마트폰 앱을 예로 들었다. 최근 폴란드에서는 고령자의 스마트폰 수요가 빠르게 증가하고 있다. 작년 판매량은 전년 대비 20% 증가했다. 각 기업들은 고령자를 주요 소비자로 여기고 관련 서비스와 상품 개발에 주력하고 있다.‘댓글 정리 서비스’도 마찬가지다. 기업 홈페이지나 소셜네트워크서비스(SNS)에 의견을 남긴 이용자 목록과 이들이 다른 사이트에 들어가 남긴 글을 분석해 기업들에 제공하는 서비스다. 이런 정보는 제품 마케팅에 활용 가능한 데다 서비스 이용료도 비싸지 않아 빠르게 입소문이 나면서 크게 성공했다는 설명이다. 근육 발달이 더딘 아이들의 재활 치료를 도와주는 로봇 개발 스타트업에도 투자금이 몰리고 있다고 한다.폴란드의 정보기술(IT) 시장 규모는 56억유로(약 6조8300억원·2014년 기준) 정도다. 글로벌 시장 조사 업체 비즈니스 모니터 인터내셔널은 올해 폴란드 IT시장이 작년보다 6% 성장할 것으로 예상했다.레빈스키 선임연구원은 폴란드에 진출하려는 IT기업은 폴란드만의 소비 문화를 잘 파악할 필요가 있다고 조언했다. 그는 “폴란드 사람은 상대적으로 다른 사람에게 보여주고 싶은 욕구가 강하다”며 “미국 전자상거래 업체 이베이는 폴란드 온라인 쇼핑몰에 비해 이런 욕구를 충족시킬 만한 서비스를 제공하지 못해 폴란드에서 실패한 대표적인 기업으로 꼽힌다”고 설명했다.', '햄버거 프랜차이즈 한국 맥도날드(대표 조 엘린저·사진)가 가맹점 확대에 본격 나섰다.한국 맥도날드는 올해 중 가맹점 50개를 새로 열어 총 103개의 가맹점을 운영할 계획이라고 10일 발표했다. 한국 맥도날드는 2010년 가맹사업을 시작해 4년간 가맹점 53개를 열었다. 전체 매장 수(344개) 대비 가맹점 비중은 15.4%다. 한연미 맥도날드 이사는 “가맹점을 확대하는 것은 글로벌 맥도날드의 프랜차이즈 전략을 한국에 적용하는 것”이라고 설명했다. 전 세계적으로 맥도날드는 3만4000여개 매장 중 80%를 가맹점으로 운영하고 있다.맥도날드는 매장을 열기 전 수개월간 운영과 마케팅, 제품 관리 등에 대한 교육을 진행한다고 강조했다. 부업으로 매장을 운영하려고 하는 경우에는 가맹점 승인을 내주지 않는다는 방침이다. 또 이미 성공적으로 가맹점을 운영하고 있는 점주에게는 두 번째 매장 개점을 허가하는 등 적극 지원할 계획이라고 밝혔다.맥도날드는 현재 가맹점을 열기 위해서는 가맹비와 영업권, 인테리어 등 시설투자비를 포함해 6억~8억원의 비용이 든다고 설명했다. 매장을 연 첫해 예상 이익률은 18~19%다.지난해부터 논란이 돼온 햄버거 프랜차이즈의 중소기업적합업종 지정과 관련해 맥도날드 측은 “출점 계획은 중기적합업종 지정 여부와 별개로 회사의 성장 전략 차원에서 세운 것”이라며 “지난해 말 한국휴게음식업중앙회가 이사회 의결을 한 이후 회사 측에 새롭게 전달된 내용은 없다”고 설명했다. 또 “다만 동반성장위원회가 햄버거 프랜차이즈를 중기적합업종으로 지정한다면 규제에 적극적으로 따를 것”이라고 덧붙였다.맥도날드는 가맹점과 함께 직영점 출점도 이어간다는 계획이다. 올해 직영점 50개를 새로 여는 것이 목표다. 올해 말까지 총 점포 수는 444개 정도가 될 것이라고 회사 측은 설명했다.', '2010년 봄. 스티브 발머 마이크로소프트(MS) 최고경영자(CEO·사진)는 ‘쿠리어’ 개발을 중단한다고 발표했다. 쿠리어는 책처럼 접을 수 있고 터치스크린에 스케치를 하거나 메모할 수 있는 태블릿PC다. 발머는 쿠리어에 투자할 금액을 출시까지 2년도 넘게 남은 차세대 윈도 개발에 투자하겠다고 했다. 애플 아이패드보다도 먼저 세상에 나왔던 MS 태블릿PC는 그렇게 자취를 감췄다. 월스트리트저널(WSJ)은 “그동안 MS는 혁신을 통해 제품을 개발하기보다는 단기적 수익을 좇는 안전한 행보만 지속해왔다”며 “발머의 뒤를 잇는 CEO는 누구든 이런 MS의 기업문화를 혁신해야 할 것”이라고 26일(현지시간) 보도했다. 발머는 최근 은퇴 의사를 밝혔다.웹사이트에서 워드, 엑셀 등을 사용할 수 있는 ‘넷독스’도 발머가 막은 제품 중 하나다. 넷독스는 MS오피스에 통합됐지만 오피스 매출이 줄어들 것을 걱정한 회사는 넷독스 서비스를 철수했다. 자동차 안에서 음악을 듣고 이메일을 볼 수 있도록 개발한 자동차 소프트웨어도 빛을 보지 못했다. 아이폰에서 사용할 수 있는 오피스 프로그램도 윈도8에 투자해야 하는 자금과 인력을 빼앗는다는 이유로 폐기됐다. WSJ는 “MS에서는 실패를 두려워하지 않고 목표를 정해 노력하는 자세를 오히려 나쁘게 본다”며 “위험을 감수하지 않는 문화가 커졌다”고 전했다. 이어 “직원들은 틀을 깨고 독창적인 사고를 하는 개발자를 중용할 수 있는 외부 인사를 CEO로 기다리고 있다”고 덧붙였다.', '서진우 SK플래닛 사장(사진)은 “SK플래닛이 온·오프라인 통합 커머스(상거래) 시대의 선봉에 서겠다”고 14일 선언했다. 이날 서울 코엑스인터컨티넨탈호텔에서 열린 ‘테크 플래닛 2013’의 기조연설자로 나선 서 사장은 “인터넷과 모바일 기술에 의해 지난 10여년간 괄목할 만한 성장을 이룬 온라인 커머스는 이제 콘텐츠와의 연계를 통해 한 단계 더 성장하려 한다”며 “오프라인 커머스 역시 모바일과 사물인터넷기술(IoT) 발전에 따라 소비자와 판매자, 생산자 간의 관계가 근본적으로 변화하며 이전에 볼 수 없었던 모습으로 진화하고 있다”고 말했다. 테크 플래닛은 SK플래닛 주최로 매년 열리는 정보기술(IT) 콘퍼런스다. 글로벌 IT의 세계적 흐름과 지향점을 살펴보기 위해 지난해에 이어 올해 두 번째로 열렸다. 온·오프라인 통합 커머스의 예로 서 사장은 SK플래닛의 ‘뉴 OK캐쉬백’과 한국에 곧 출시할 예정인 패션 키워드 기반 콘텐츠 커머스 ‘스타일태그’를 소개했다. 뉴 OK캐쉬백은 스마트폰 이용자의 현재 위치를 파악해 주변 OK캐쉬백 가맹 음식점이나 상점의 할인 쿠폰을 스마트폰으로 보내 준다. 스타일태그는 길을 가다 발견한 패션 상품을 사진으로 찍어 올리면 이에 해당하거나 가까운 상품의 정보를 받아볼 수 있다. 미국에서 먼저 나와 100만다운로드를 기록했으며 한국에는 연말 출시될 예정이다. 그는 “이런 혁신은 온라인과 오프라인 각각에 한정되는 것이 아니라 온·오프라인에 걸쳐 전방위로 나타나게 될 것”이라며 “온·오프라인 통합 커머스로의 혁신은 인간에 대한 이해를 바탕으로 창의적인 생각과 혁신적인 기술 접목을 통해 가능하다”고 말했다.', '금융위원회가 27일 발표한 ‘금융업 경쟁력 강화 방안’은 6개월간의 준비를 거쳐 나온 박근혜 정부의 ‘금융 비전’이다. 정부 초기 금융을 홀대한다는 업계의 불만을 반영한 때문인지 규제완화로 경쟁을 촉진하겠다는 내용이 핵심을 이루고 있다. 이를 통해 10년 뒤 국내총생산(GDP)에서 금융업 부가가치가 차지하는 비중을 10%로 늘린다는 중장기 목표도 제시했다. 금융권에서는 그러나 “고민한 흔적은 엿보이지만 한국 금융산업을 재도약시킬 획기적인 대안은 보이지 않는다”는 혹평도 적지 않다. 규제완화에 따른 부작용을 우려하는 목소리도 나온다.각종 칸막이 걷어내 무한경쟁 촉진금융위는 우선 무한경쟁 환경을 조성해 금융권 스스로 파이를 키우고 경쟁력을 갖추도록 유도하기로 했다.2016년부터 시행될 ‘은행 계좌이동제’가 대표적이다. 지금은 금융소비자가 주거래 예금계좌를 다른 은행 계좌로 변경하려면 각종 이체 거래도 일일이 바꿔야 한다. 이 과정에서 이체 거래를 변경하지 않아 카드비 등을 연체하는 경우도 있다. 하지만 계좌이동제가 도입되면 소비자는 기존 은행에서 자동이체 내역을 일일이 해지하고 신규 은행에서 자동이체를 새로 신청하는 불편을 겪지 않아도 된다. 금융위 관계자는 “길게는 수십년간 같은 주거래은행 예금계좌를 사용해온 소비자들도 금리와 수수료 등에 따라 손쉽게 은행을 바꿀 수 있어 은행권에 큰 변화가 불어닥칠 것”이라고 말했다. 여기에 금융당국이 무인·이동점포, 모바일 판매채널 등 다양한 판매채널까지 허용하기로 함에 따라 은행들은 점포 구조조정에 직면할 것으로 예상된다.진입 및 영업규제도 크게 완화된다. 금융투자업은 과도하게 세분화한 인허가 단위를 대단위로 통합하고 여신전문금융업도 비슷한 업무를 하고 있는 할부금융, 리스, 신기술 등 3개 업권의 인가 및 등록 기준을 하나로 통합해 기업금융 특화 기관으로 육성하기로 했다. 보험사에는 해외 환자 유치업에 참여할 수 있도록 허용해 신수익원을 확보하고 국내 의료관광 활성화에 기여할 수 있게 할 계획이다.기업-금융사 동반 해외 진출 지원금융사들이 포화 상태인 국내 시장을 벗어나 해외에 진출할 수 있는 지원 방안도 포함됐다. 금융위는 우선 단기 성과에 대한 부담을 줄여 중장기적인 해외 진출 전략을 수립할 수 있도록 해외 점포의 경영실태 평가 유예기간을 은행은 현재의 1년에서 3년으로 금융투자사와 보험사(현행 2년)는 5년으로 늘려주기로 했다. 현재 50%인 지주회사의 해외 자회사 지분 의무보유 비율도 완화해 자회사 설립을 활성화하기로 했다. 금융위는 특히 전국경제인연합회 등과 협의해 기업과 은행이 함께 해외 진출을 추진하는 ‘동반 진출 활성화’ 전략도 곧 내놓기로 했다. 금융권 ‘백화점식, 새로운 내용이 적다’이 같은 경쟁력 강화 방안에 대해 금융권에서는 백과사전식 나열인 데다 새로운 내용이 많지 않다는 냉담한 평가가 적지 않다. 은행권은 계좌이동제의 부작용을 우려했다. 한 시중은행 관계자는 “계좌이동제가 시행되면 고객 유치를 위해 은행 간 금리 및 서비스 경쟁이 과열될 수밖에 없다”며 “수익성 악화가 당면 과제인 은행엔 오히려 부담이 돼 경쟁력 강화로 이어질지 의문”이라고 말했다.여신업계 관계자는 “기업금융으로 특화시키겠다는 게 정부의 의도지만 상대적으로 리스크가 큰 기업금융을 강화할 수 있겠느냐”면서 “업계의 자금과 여력을 고려하면 정부의 지원이 필수적인데 정책자금 지원 등 구체적인 내용이 없다”고 지적했다.'], 'answers': [[{'text': '서강대 메리홀 대극장', 'answer_start': 246}], [{'text': '저축은행중앙회', 'answer_start': 345}, {'text': '중앙회', 'answer_start': 774}], [{'text': '구문론', 'answer_start': 521}], [{'text': '1956년', 'answer_start': 634}, {'text': '1956', 'answer_start': 634}], [{'text': '1부', 'answer_start': 187}], [{'text': '이베이', 'answer_start': 889}], [{'text': '50개', 'answer_start': 65}], [{'text': '‘쿠리어’', 'answer_start': 43}, {'text': '쿠리어', 'answer_start': 44}], [{'text': '스타일태그', 'answer_start': 561}], [{'text': '‘은행 계좌이동제’', 'answer_start': 386}, {'text': '은행 계좌이동제', 'answer_start': 387}, {'text': '계좌이동제', 'answer_start': 390}, {'text': '계좌이동제', 'answer_start': 1405}, {'text': '계좌이동제', 'answer_start': 1436}]], 'question': ['윤광진 교수가 연출한 연극이 앙코르 공연을 하는 장소는 어디인가?', '자체 신용평가시스템이 없는 저축은행은 어느 기관의 시스템을 따르는가?', '한 언어를 다른 언어로 번역하기 위해 필요하며, 의미론, 사전학, 화용론을 이해해야 하는 문법은?', '소비에트 연방이 수정주의를 도입한 해는?', '돈키호테의 하이라이트를 볼 수 있는 것은 몇 부인가?', '폴란드인의 과시욕을 만족시키지 못해 폴란드 시장에서 실패한 전자거래소는?', '이번 해에 증가될 국내 맥도날드 가맹점 수는?', 'MS에서 개발한 태블릿PC 이름은?', '의류의 사진을 찍고 업로드하면, 그 제품을 바로 찾아낼 수 있는 콘텐츠는?', '자동이체에 관한 소비자의 불편을 해소할 수 있게해 주는 것의 명칭은?']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizer load \n",
        "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
        "\n",
        "def load_tokenizer(model_id, test_sentence):\n",
        "  tokenizer = AutoTokenizer.from_pretrained(hf_model_id)\n",
        "  return tokenizer"
      ],
      "metadata": {
        "id": "a6tsyntuC_XX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#학습된 모델 불러오기\n",
        "\n",
        "sentence = '위메프의 배달∙픽업 서비스 위메프오가 23~25일 3일간 ‘BBQ 50% 페이백’ 이벤트를 진행한다고 23일 밝혔다'\n",
        "\n",
        "#hf_model_id = 'kykim/electra-kor-base'\n",
        "#tokenizer = load_tokenizer(hf_model_id, sentence)\n",
        "\n",
        "# hf_model_id = 'monologg/kobert'\n",
        "# tokenizer = load_tokenizer(hf_model_id, sentence)\n",
        "\n",
        "\n",
        "hf_model_id = 'kykim/bert-kor-base'\n",
        "tokenizer = load_tokenizer(hf_model_id, sentence)\n",
        "\n",
        "\n",
        "#hf_model_id = 'Jinhwan/krelectra-base-mecab'\n",
        "#tokenizer = load_tokenizer(hf_model_id, sentence)\n",
        "\n",
        "# hf_model_id = 'monologg/kobigbird-bert-base'\n",
        "# #https://github.com/monologg/KoBigBird\n",
        "config = AutoConfig.from_pretrained(hf_model_id, max_position_embeddings=1024)\n",
        "model = AutoModel.from_pretrained(hf_model_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221,
          "referenced_widgets": [
            "5881e11444aa48a8ac5c8e0e146b76b8",
            "69ead85cc60242eaa537662010eacb91",
            "78f609b3e77147d39a479f5de4472585",
            "8284ba80ff4c4764a4615d5618d5b95a",
            "93c1076499f14c2691b99edd35e57dd3",
            "19c23dd96fe14f8d91339df508976953",
            "870e257011554e43abc83ee384268a91",
            "89c8aba0ac314cb698754a0073c9e0eb",
            "b79563cd8c0f4fd293fa471aba222193",
            "e76ed75d061f402e8a16504493c95619",
            "74d72780fe254b55844132cbd8919a75",
            "1e922005e9404a219f336027eb305c19",
            "dc98bbfead18413ebce741e71b22e2d2",
            "4be8e8d8ca8e48ecb8e45447c7a35295",
            "4c78a627b1b84cf1a905f5aa8d09b7dd",
            "270c2261e2084300ba18e2b98e0894b7",
            "9b44a1dfb03043a49f8e92c8d389a3b8",
            "31147d20714f459fbc25fbe9c8b5b2e4",
            "88f8ca538fde48158e173fab9c197672",
            "9b17be4f58764e47a2b762bb6457565d",
            "a803bed50ac844fbb37620e7a24cd519",
            "a7fafe42326f4ce6a264d707be365f73",
            "0b72aa76271c4246b3d5eea309d17058",
            "ee75d1c3f6f34c0988ae3bbb83065f41",
            "b76d8d4a25b64fdaacb72edca24b35a5",
            "27857de3626b430bb1843a1c18c8fe48",
            "f54c1719a3f144fe9f209117e7da7ddd",
            "803aad3a03b04cd092ffb11e2ff64c7c",
            "fc6cf49180464a97ab218c9088c84f2f",
            "ccbf3f6a891f4f55a98ff90937aa89ed",
            "681b2ff69dea4e278a618f7188aacf6b",
            "abd69173de6a4c1a8123fce745de2503",
            "bd23c527454f4f4e8bd3b2723f6f1b52",
            "52ac3cb9c9394221b0a652eaba07df8a",
            "4c199c10f1fc4ced95802058baffc92e",
            "cc7901be85964c45b29914415d557246",
            "143120b401674f5387a48ad80c1ee5cc",
            "60213d8ea19042389f81c71e3fe04236",
            "daa31a90026f465e93ac0a7ddd42d41c",
            "1cd7e2b2807740e1879a530490307a24",
            "9ba077b488844d1e81a69d634031b58d",
            "2c548db94e704c77bb700339d40caee6",
            "64c2a6dbcfe641d997f68e0a01d5b204",
            "0dac962745a748f88d440a339358c84e"
          ]
        },
        "id": "EG-ZcjH5DDNB",
        "outputId": "ecbeca4b-e2db-4cd0-d8ca-ed7817fe4c16"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/80.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5881e11444aa48a8ac5c8e0e146b76b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/725 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e922005e9404a219f336027eb305c19"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/344k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b72aa76271c4246b3d5eea309d17058"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/476M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52ac3cb9c9394221b0a652eaba07df8a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(hf_model_id)\n",
        "print(tokenizer) \n",
        "question = '무슨 이벤트를 하나?'\n",
        "aa =tokenizer(question, sentence, return_offsets_mapping=True)\n",
        "print(aa)\n",
        "print(tokenizer.unk_token_id)\n",
        "print(tokenizer.cls_token_id)\n",
        "print(tokenizer.sep_token_id)\n",
        "\n",
        "# answer (16,) => 7,8\n",
        "# context position (\n",
        "print(aa.offset_mapping)\n",
        "print(aa['input_ids'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QE0TljP4DPDc",
        "outputId": "ed14733c-1975-434e-bd4e-c47e4cf0bde8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kykim/bert-kor-base\n",
            "PreTrainedTokenizerFast(name_or_path='kykim/bert-kor-base', vocab_size=42000, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n",
            "{'input_ids': [2, 15440, 21346, 14023, 2033, 3, 5842, 8593, 21573, 1, 15549, 5842, 8593, 8247, 24677, 15292, 2070, 20085, 16445, 8154, 1, 23483, 8671, 14654, 2008, 20643, 8326, 1, 21346, 28630, 8014, 20506, 14875, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'offset_mapping': [(0, 0), (0, 2), (3, 7), (8, 10), (10, 11), (0, 0), (0, 1), (1, 2), (2, 4), (5, 10), (11, 14), (15, 16), (16, 17), (17, 18), (18, 20), (21, 23), (23, 24), (24, 27), (28, 30), (30, 31), (32, 33), (33, 35), (35, 36), (37, 39), (39, 40), (41, 43), (43, 44), (44, 45), (46, 50), (51, 55), (55, 56), (57, 60), (61, 64), (0, 0)]}\n",
            "1\n",
            "2\n",
            "3\n",
            "[(0, 0), (0, 2), (3, 7), (8, 10), (10, 11), (0, 0), (0, 1), (1, 2), (2, 4), (5, 10), (11, 14), (15, 16), (16, 17), (17, 18), (18, 20), (21, 23), (23, 24), (24, 27), (28, 30), (30, 31), (32, 33), (33, 35), (35, 36), (37, 39), (39, 40), (41, 43), (43, 44), (44, 45), (46, 50), (51, 55), (55, 56), (57, 60), (61, 64), (0, 0)]\n",
            "[2, 15440, 21346, 14023, 2033, 3, 5842, 8593, 21573, 1, 15549, 5842, 8593, 8247, 24677, 15292, 2070, 20085, 16445, 8154, 1, 23483, 8671, 14654, 2008, 20643, 8326, 1, 21346, 28630, 8014, 20506, 14875, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm \n",
        "class TKIndexerWrappedDataset:\n",
        "    def __init__(self, dataset: KoMRC, tokenizer) -> None:\n",
        "        self._indexer = tokenizer\n",
        "        self._dataset = self._sample2ids_with_tk(dataset)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self._dataset['input_ids'])\n",
        "\n",
        "\n",
        "    def _sample2ids_with_tk(self, sample):\n",
        "      tokenizer = self._indexer\n",
        "\n",
        "      # return_offsets_mapping\n",
        "      tokenized = tokenizer(sample['question'], \n",
        "                            sample['context'],\n",
        "                            return_overflowing_tokens=True, \n",
        "                            return_offsets_mapping=True, \n",
        "                            # stride = 128,\n",
        "                            return_tensors = 'pt',\n",
        "                            max_length=512, \n",
        "                            truncation='only_second', \n",
        "                            padding='max_length')\n",
        "      offset_map = tokenized.pop('offset_mapping')\n",
        "      overflow_map = tokenized.pop('overflow_to_sample_mapping')\n",
        "      tokenized['start'] = []\n",
        "      tokenized['end'] = []\n",
        "      tokenized['guid'] = []\n",
        "      cls_id = tokenizer.cls_token_id\n",
        "\n",
        "      for i, offsets in enumerate(tqdm(offset_map)):\n",
        "        input_ids = tokenized['input_ids'][i]\n",
        "        cls_index = input_ids.tolist().index(cls_id)\n",
        "        seq_ids = tokenized.sequence_ids(i)\n",
        "\n",
        "        # check\n",
        "        example_idx = overflow_map[i]\n",
        "        answers = sample['answers'][example_idx]\n",
        "        guid = sample['guid'][example_idx]\n",
        "        tokenized['guid'].append(guid)\n",
        "\n",
        "        # \n",
        "        if not answers :\n",
        "          continue \n",
        "\n",
        "        ans_start = answers[0]['answer_start']\n",
        "        ans_end = answers[0]['answer_start'] + len(answers[0]['text'])\n",
        "\n",
        "        # question, context 분리 \n",
        "        ans_token_start = 0 \n",
        "        while seq_ids[ans_token_start] != 1 :\n",
        "          ans_token_start += 1 \n",
        "\n",
        "        ans_token_end = len(input_ids) - 1\n",
        "        while seq_ids[ans_token_end] != 1 :\n",
        "          ans_token_end -= 1 \n",
        "\n",
        "        if not (offsets[ans_token_start][0] <= ans_start and offsets[ans_token_end][1] >= ans_end):\n",
        "          tokenized['start'].append(cls_index)\n",
        "          tokenized['end'].append(cls_index)      \n",
        "        else : \n",
        "          while (ans_token_start < len(offsets) \n",
        "          and offsets[ans_token_start][0] <= ans_start): \n",
        "            ans_token_start += 1 \n",
        "          \n",
        "          while offsets[ans_token_end][1] >= ans_end:\n",
        "            ans_token_end -= 1 \n",
        "\n",
        "          tokenized['start'].append(ans_token_start)\n",
        "          tokenized['end'].append(ans_token_end)        \n",
        "      return tokenized\n",
        "      \n",
        "    \n",
        "    def __getitem__(self, slices) -> Any:\n",
        "\n",
        "        if isinstance(slices, (int, np.int64)):\n",
        "          # row \n",
        "          return {\n",
        "              'input_ids': self._dataset['input_ids'][slices],\n",
        "              'token_type_ids': self._dataset['token_type_ids'][slices],\n",
        "              'attention_mask': self._dataset['attention_mask'][slices],\n",
        "              'start': self._dataset['start'][slices] if len(self._dataset['start']) > slices else None,\n",
        "              'end': self._dataset['end'][slices] if len(self._dataset['end']) > slices else None,\n",
        "              'guid': self._dataset['guid'][slices]\n",
        "          }\n",
        "        elif isinstance(slices, str):\n",
        "          return self._dataset[slices]\n",
        "        elif isinstance(slices, slice):\n",
        "          return {\n",
        "              'input_ids': [self._dataset['input_ids'][i] for i in range(slices.start, slices.stop)],\n",
        "              'token_type_ids': [self._dataset['token_type_ids'][i] for i in range(slices.start, slices.stop)],\n",
        "              'attention_mask': [self._dataset['attention_mask'][i] for i in range(slices.start, slices.stop)],\n",
        "              'guid': [self._dataset['guid'][i] for i in range(slices.start, slices.stop)],\n",
        "              'start': [self._dataset['start'][i] for i in range(slices.start, slices.stop)],\n",
        "              'end': [self._dataset['end'][i] for i in range(slices.start, slices.stop)]\n",
        "          }\n",
        "        raise ValueError(f'unhanled slices : {slices}, type={type(slices)}')\n",
        "\n",
        "        return sample"
      ],
      "metadata": {
        "id": "6vMciViFDa5y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train,dev data 불러온 모델에 적용\n",
        "indexed_train_dataset = TKIndexerWrappedDataset(train_dataset, tokenizer)\n",
        "indexed_dev_dataset = TKIndexerWrappedDataset(dev_dataset, tokenizer)\n",
        "print(f'\\nlen origin train_dataset : {len(train_dataset)}')\n",
        "print(f'len indexed_train_dataset : {len(indexed_train_dataset)}')\n",
        "sample = indexed_dev_dataset[0]\n",
        "print(sample['input_ids'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypU9SA1LDeT9",
        "outputId": "2ccbeb69-31ac-4dea-ddf9-1748ca6763b5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14362/14362 [00:31<00:00, 461.34it/s]\n",
            "100%|██████████| 1578/1578 [00:03<00:00, 466.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "len origin train_dataset : 10834\n",
            "len indexed_train_dataset : 14362\n",
            "tensor([    2,  5862,  8597,  8250, 32285, 15439,  8112, 21650,  8018,  5525,\n",
            "        39620, 23877, 14032, 38250, 14508, 14674,  2033,     3, 15080, 15815,\n",
            "        21650, 14331, 16376, 34116,  8109,  4983, 16836, 24675,  5691,  8358,\n",
            "         8008, 22738,  5525, 39620, 32085, 34431,  2016, 16809,  8099,  8719,\n",
            "        22578, 18397,     1, 21601, 19593,  8017,  2014, 21303,  8099,  8719,\n",
            "         8017, 14706,     1,  7974,  8680,     1, 18397,  8017, 14475, 33165,\n",
            "            1, 24169, 16040, 31609,  8143,     1,  2010, 14801,  2070, 19472,\n",
            "        15169,  8054, 18048,  8246, 19593, 38125,  3137, 38125,  2014, 20085,\n",
            "         2070, 15686, 16856,  8066,  4956,  8007,  8201, 19602,  8719,  8139,\n",
            "        28828,  8829,  8020,  8222,  8448, 38125,  2011,  2014, 21650, 22578,\n",
            "        13970, 17020,  8289,  7974,  8680, 14331, 15034,     1, 20570, 20723,\n",
            "         8013,     1,  2010, 20521,  2070, 15686, 21363,  8066, 15169,  8054,\n",
            "         5645,  8177,  8047, 38125,  2011,  2014, 21650, 22578, 14706,     1,\n",
            "        15439, 20882, 30570,  8736,  8099,  8719,  8017, 17128,  8296,  8159,\n",
            "            1, 19008,  8114,     1,  2010, 15686,  8062,  2070, 20521,  4956,\n",
            "         8228,  8152, 23497,  9056,  3137, 38125,  2011, 18811,  2016,  6665,\n",
            "         8099, 14791, 16771,  4902,  8099, 15385,  8289, 16684, 27006, 16203,\n",
            "        23877,  2950,  8406, 21650, 25086,  8887,  7475, 17997, 14008, 14706,\n",
            "        14294, 40856,  5099, 26275, 18396,  8150,  5099, 13979, 18804,  8013,\n",
            "         2016,     1, 24169, 16040, 31609,  8143,     1,  3052,  7974, 25128,\n",
            "        14616, 15439,  8112, 28865,  8888,  8107, 14559, 16187, 18876,  8112,\n",
            "        34253, 19874, 16146,  8013,  2016, 20383, 14510,  8008, 22065,  7653,\n",
            "        22064,  4882, 14009, 31609, 14036, 18188,  2430, 31023, 27041, 14300,\n",
            "        26099, 15108, 14074, 24635, 13977, 16735, 14035,  2016, 15439, 14196,\n",
            "            1, 40660,  8159, 25357,  8018,  4882, 14009, 31897, 15782, 17513,\n",
            "        14017, 36612, 14006, 34490, 15962, 14147, 14990,  8025, 16466, 14423,\n",
            "         8078, 16475, 34769,  8273, 23579, 14186, 26306, 17339, 15782, 30546,\n",
            "        14032,     1, 24169, 16040,  8107, 31609,  8143,     1, 16466, 14955,\n",
            "        15441,     1,  2260, 17495,  2016, 14147,  8099,  8719,  8599, 32080,\n",
            "        20060,  8034,  5921, 19579,     1, 17912, 32143, 21650, 18250,  8138,\n",
            "            1,  3828, 16165, 14186,     1, 23175, 13973, 31489, 13977, 29525,\n",
            "         6611,  8497,  8010, 14423,  8289, 39048, 14083,  5921,  8239,  8532,\n",
            "         8322,  2290, 14832, 19746, 14035,  2016, 15172,  8719,  8008, 14083,\n",
            "        14567, 22855, 40405,     1,  2260,  7475, 13990,  2016,  5921, 32329,\n",
            "        18397, 14331,  7926,  9130,  2797,  8350,  8904,  8051, 19361,  6266,\n",
            "         8701,  8238, 23492,  8181,  3408,  6665,  8099, 15615, 13987, 14624,\n",
            "        37178,  8013,  2016,     1, 20570, 20723,  8013,     1,  3052,  7722,\n",
            "         8555, 13973,  4492,  8218, 14143,     1, 20676, 15651,     1,  5907,\n",
            "        34568, 15470, 18218, 15583, 18316, 32167,  8289, 27184, 15701, 14706,\n",
            "         2016,     1,  6540,  8503, 16293,  5504, 37840,  8384,     1,     1,\n",
            "        15669, 16573,     1,  3966, 14496, 26573, 16670,  8329,  8107,  5970,\n",
            "         8177,  8559, 25051, 14232,  3137, 29778, 14616, 15439, 13990,  2016,\n",
            "        32651, 21392,  8051, 14352, 20340,  8054, 18189, 34568, 15470, 14567,\n",
            "        15527, 13969, 24172,     1, 14018,  8016, 32587,     1,  3258, 33114,\n",
            "            1, 28063, 34568,  8267, 24629, 14229,  5809, 16282, 18728, 27145,\n",
            "         8013,     1,  2260, 19720, 14167, 24772, 18512, 39980, 17917,  4559,\n",
            "         8013,  2016,  2791,  8422, 34228,  6267,  8605,  7821, 20653, 17274,\n",
            "        28300, 23747, 16082, 14996,  8061, 40204,  8283, 20952,  2431,  8322,\n",
            "        25361,     1,  6282,     1,  5907,  4489,  8267,  8322, 14782,  8061,\n",
            "        29525, 14083,  4976,  8369,  8107, 18675, 23661,  8034, 20903, 17030,\n",
            "         2016,  5977,  8099, 14111, 35110, 15615,  2482,  8016, 17422,  5970,\n",
            "         8472,     3])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data 준비\n",
        "Collator : 데이터를 batch에 맞게 자르고 묶어주고, 준비하는 모듈 DataLoader : 데이터를 iterative (돌아가면서 훈련할 수 있게) Load하는 모듈"
      ],
      "metadata": {
        "id": "l_A7i4g8DsHh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "class Collator:\n",
        "    def __init__(self, indexer) -> None:\n",
        "        self._indexer = indexer\n",
        "\n",
        "    def __call__(self, samples: List[Dict[str, Any]]) -> Dict[str, torch.Tensor]:\n",
        "        samples = {\n",
        "            key: [sample[key] for sample in samples]\n",
        "            for key in samples[0]\n",
        "        }\n",
        "\n",
        "        for key in 'start', 'end':\n",
        "            if samples[key][0] is None:\n",
        "                samples[key] = None\n",
        "            else:\n",
        "                samples[key] = torch.tensor(samples[key], dtype=torch.long)\n",
        "        for key in 'input_ids', 'attention_mask', 'token_type_ids':\n",
        "            samples[key] = pad_sequence(\n",
        "                [torch.tensor(sample, dtype=torch.long) for sample in samples[key]],\n",
        "                batch_first=True, padding_value=self._indexer.pad_token_id\n",
        "            )\n",
        "\n",
        "        return samples"
      ],
      "metadata": {
        "id": "CPv_7_BqDx62"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 64\n",
        "#num_workers = core num\n",
        "accumulation = 4 # 메모리를 아끼기 위하여 Gradient accumulation을 해보자\n",
        "collator = Collator(tokenizer)\n",
        "train_loader = DataLoader(indexed_train_dataset, batch_size=batch_size//accumulation, shuffle=True, collate_fn=collator, num_workers=2)\n",
        "dev_loader = DataLoader(indexed_dev_dataset, batch_size=batch_size//accumulation, shuffle=False, collate_fn=collator, num_workers=2)"
      ],
      "metadata": {
        "id": "oxiiVyUcEGQn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(dev_loader))\n",
        "print(batch['input_ids'].shape)\n",
        "print(list(batch.keys()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLuETD0sEdK6",
        "outputId": "d1849513-ad0e-4f6e-e895-a855596aa9b3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 512])\n",
            "['input_ids', 'token_type_ids', 'attention_mask', 'start', 'end', 'guid']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_loader))\n",
        "print(len(indexed_train_dataset))\n",
        "print(len(indexed_train_dataset)/16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmJW_EXyEguu",
        "outputId": "8343ec52-bae6-4086-82b8-54d62b5d0972"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "898\n",
            "14362\n",
            "897.625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 본격적으로 훈련하기\n",
        "1.모델 hyperparameter 정하기\n",
        "\n",
        "2.Training"
      ],
      "metadata": {
        "id": "7X2Q7Ew-Ejr2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "import torch.nn as nn\n",
        "\n",
        "from transformers.models.bert.modeling_bert import (\n",
        "    BertModel,\n",
        "    BertPreTrainedModel\n",
        ")\n",
        "from transformers import AutoModel\n",
        "## Simple Version for Bert QA: https://huggingface.co/transformers/_modules/transformers/models/bert/modeling_bert.html#BertForQuestionAnswering.forward\n",
        "class BertForQuestionAnswering(nn.Module):\n",
        "    _keys_to_ignore_on_load_unexpected = [r\"pooler\"]\n",
        "\n",
        "    def __init__(self, config, hf_model_id):\n",
        "        # super().__init__(config)\n",
        "        # self.bert = BertModel(config, add_pooling_layer=False)\n",
        "        # self.start_linear = nn.Linear(config.hidden_size, 1)\n",
        "        # self.end_linear = nn.Linear(config.hidden_size, 1)\n",
        "        # self.init_weights()\n",
        "\n",
        "        super().__init__()\n",
        "        self.bert = AutoModel.from_pretrained(hf_model_id)\n",
        "        self.start_linear = nn.Linear(self.bert.config.hidden_size, 1)\n",
        "        self.end_linear = nn.Linear(self.bert.config.hidden_size, 1)\n",
        "\n",
        "\n",
        "    def forward(\n",
        "        self, input_ids, attention_mask, token_type_ids\n",
        "    ):\n",
        "        outputs = self.bert(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "        )\n",
        "\n",
        "        start_logits = self.start_linear(outputs.last_hidden_state).squeeze(-1)\n",
        "        end_logits = self.end_linear(outputs.last_hidden_state).squeeze(-1)\n",
        "\n",
        "        return start_logits, end_logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owq52LbyEqBm",
        "outputId": "1306f033-ffdf-4cd9-965b-e38215c27bd2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (5.0.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.9.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertConfig\n",
        "\n",
        "\n",
        "print(f'Encoder model to use : {hf_model_id}')\n",
        "model = BertForQuestionAnswering({}, hf_model_id)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_Tdi3U5E1TT",
        "outputId": "e494c761-6596-41bc-fce8-d77c81c25c80"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder model to use : kykim/bert-kor-base\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# device set\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zfn6o2I6E5jG",
        "outputId": "a3903f74-278b-43d1-ca03-f9e1c37443d1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForQuestionAnswering(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(42000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (start_linear): Linear(in_features=768, out_features=1, bias=True)\n",
              "  (end_linear): Linear(in_features=768, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################################################\n",
        "from torch.utils.data import RandomSampler, DataLoader, Subset\n",
        "import numpy as np \n",
        "\n",
        "num_train_samples = 16\n",
        "sample_ds = Subset(indexed_train_dataset, np.arange(num_train_samples))\n",
        "sample_sampler = RandomSampler(sample_ds)\n",
        "sample_dl = DataLoader(sample_ds, collate_fn=collator, sampler=sample_sampler, batch_size=4)\n",
        "next(iter(sample_dl))\n",
        "\n",
        "num_dev_samples = 2\n",
        "sample_ds_dev = Subset(indexed_dev_dataset, np.arange(num_dev_samples))\n",
        "sample_sampler_dev = RandomSampler(sample_ds_dev)\n",
        "sample_dl_dev = DataLoader(sample_ds_dev, collate_fn=collator, sampler=sample_sampler_dev, batch_size=4)\n",
        "next(iter(sample_dl_dev))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3all7sLE_GO",
        "outputId": "bb6d4edb-7c7a-405f-f74a-274cfb3c6f46"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[   2, 5862, 8597,  ...,    0,    0,    0],\n",
              "         [   2, 5862, 8597,  ..., 5970, 8472,    3]]),\n",
              " 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 1, 1, 1]]),\n",
              " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 1, 1, 1]]),\n",
              " 'start': tensor([  0, 150]),\n",
              " 'end': tensor([  0, 154]),\n",
              " 'guid': ['844e22ab28924c1697d5ac28801b34c1',\n",
              "  '844e22ab28924c1697d5ac28801b34c1']}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from statistics import mean\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "print(f'device : {device}')\n",
        "os.makedirs('dump', exist_ok=True)\n",
        "train_losses = []\n",
        "dev_losses = []\n",
        "\n",
        "step = 0\n",
        "\n",
        "\n",
        "for epoch in range(1, 31):\n",
        "    print(\"Epoch\", epoch)\n",
        "    # Training\n",
        "    running_loss = 0.\n",
        "    losses = []\n",
        "    progress_bar = tqdm(sample_dl, desc='Train')\n",
        "    for batch in progress_bar:\n",
        "        del batch['guid'] #, batch['context'], batch['question'], batch['position']\n",
        "        # batch = {key: value.cuda() for key, value in batch.items()}\n",
        "        batch['input_ids'] = batch['input_ids'].to(device)\n",
        "        batch['token_type_ids'] = batch['token_type_ids'].to(device)\n",
        "        batch['attention_mask'] = batch['attention_mask'].to(device)\n",
        "        batch['start'] = batch['start'].to(device)\n",
        "        batch['end'] = batch['end'].to(device)\n",
        "\n",
        "        start = batch.pop('start')\n",
        "        end = batch.pop('end')\n",
        "        \n",
        "        model_output = model(**batch)\n",
        "        \n",
        "        try :\n",
        "          start_logits, end_logits = model_output\n",
        "        except Exception as e :\n",
        "          print(model_output)\n",
        "          raise e \n",
        "        \n",
        "        try :\n",
        "          print('loss')\n",
        "          loss = F.cross_entropy(start_logits, start) + F.cross_entropy(end_logits, end)\n",
        "\n",
        "          print(torch.argmax(start_logits, dim=1))\n",
        "          print(start)\n",
        "          print(f'ce1 : {F.cross_entropy(start_logits, start)}')\n",
        "          print(f'ce2 : {F.cross_entropy(end_logits, end)}')\n",
        "\n",
        "          loss.backward()\n",
        "          running_loss += loss.item()\n",
        "          print(f'running_loss : {running_loss}')\n",
        "        except Exception as e :\n",
        "          print(f'start_logits : {start_logits}')\n",
        "          print(f'end_logits : {end_logits}')\n",
        "          print(f'start : {start}')\n",
        "          print(f'end : {end}')\n",
        "          print(f'loss : {loss}')\n",
        "          raise e \n",
        "        del batch, start, end, start_logits, end_logits, loss\n",
        "        \n",
        "        step += 1\n",
        "        # if step % accumulation:\n",
        "        #     continue\n",
        "\n",
        "        clip_grad_norm_(model.parameters(), max_norm=1.)\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        losses.append(running_loss)\n",
        "        running_loss = 0.\n",
        "        progress_bar.set_description(f\"Train - Loss: {losses[-1]:.3f}\")\n",
        "\n",
        "    train_losses.append(mean(losses))\n",
        "    print(f\"train score: {train_losses[-1]:.3f}\")\n",
        "\n",
        "    # Evaluation\n",
        "    losses = []\n",
        "    for batch in tqdm(sample_dl_dev, desc=\"Evaluation\"):\n",
        "        del batch['guid'] #, batch['context'], batch['question'], batch['position']\n",
        "        # batch = {key: value.cuda() for key, value in batch.items()}\n",
        "        batch['input_ids'] = batch['input_ids'].to(device)\n",
        "        batch['token_type_ids'] = batch['token_type_ids'].to(device)\n",
        "        batch['attention_mask'] = batch['attention_mask'].to(device)\n",
        "        batch['start'] = batch['start'].to(device)\n",
        "        batch['end'] = batch['end'].to(device)\n",
        "\n",
        "        start = batch.pop('start')\n",
        "        end = batch.pop('end')\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            start_logits, end_logits = model(**batch)\n",
        "        loss = F.cross_entropy(start_logits, start) + F.cross_entropy(end_logits, end)\n",
        "\n",
        "        losses.append(loss.item())\n",
        "        del batch, start, end, start_logits, end_logits, loss\n",
        "    dev_losses.append(mean(losses))\n",
        "    print(f\"Evaluation score: {dev_losses[-1]:.3f}\")\n",
        "\n",
        "    torch.save(model, f'dump/model.{epoch}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aippurJMFFM5",
        "outputId": "198f4e79-2498-4093-9ceb-774fcc5d2635"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device : cuda\n",
            "Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss\n",
            "tensor([  4,   9, 453,  92], device='cuda:0')\n",
            "tensor([121,   0,  24,   0], device='cuda:0')\n",
            "ce1 : 6.232970714569092\n",
            "ce2 : 6.467718124389648\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "Train - Loss: 12.701:  25%|██▌       | 1/4 [00:00<00:01,  2.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 12.700689315795898\n",
            "loss\n",
            "tensor([264, 420,  16, 210], device='cuda:0')\n",
            "tensor([ 23, 484,  75, 351], device='cuda:0')\n",
            "ce1 : 5.721076011657715\n",
            "ce2 : 5.846167087554932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 11.567:  50%|█████     | 2/4 [00:00<00:00,  2.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 11.567243576049805\n",
            "loss\n",
            "tensor([ 71, 314,   1, 200], device='cuda:0')\n",
            "tensor([288,  44,   0,  69], device='cuda:0')\n",
            "ce1 : 5.991205215454102\n",
            "ce2 : 6.037653923034668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 12.029:  75%|███████▌  | 3/4 [00:01<00:00,  2.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 12.02885913848877\n",
            "loss\n",
            "tensor([262, 482,   5, 276], device='cuda:0')\n",
            "tensor([446, 328,   0, 173], device='cuda:0')\n",
            "ce1 : 6.290277481079102\n",
            "ce2 : 6.373520851135254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 12.664: 100%|██████████| 4/4 [00:01<00:00,  2.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 12.663798332214355\n",
            "train score: 12.240\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 15.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation score: 10.574\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss\n",
            "tensor([188,   2,   0,  44], device='cuda:0')\n",
            "tensor([328,   0,   0,  44], device='cuda:0')\n",
            "ce1 : 4.571890354156494\n",
            "ce2 : 4.488036632537842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 9.060:  25%|██▌       | 1/4 [00:00<00:01,  2.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 9.059926986694336\n",
            "loss\n",
            "tensor([  0,  19, 262, 121], device='cuda:0')\n",
            "tensor([  0,   0, 446, 121], device='cuda:0')\n",
            "ce1 : 3.5929384231567383\n",
            "ce2 : 3.710402488708496\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 7.303:  50%|█████     | 2/4 [00:00<00:00,  2.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 7.303340911865234\n",
            "loss\n",
            "tensor([288,  23, 351,   2], device='cuda:0')\n",
            "tensor([288,  23, 351,  24], device='cuda:0')\n",
            "ce1 : 3.5913283824920654\n",
            "ce2 : 3.5994322299957275\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 7.191:  75%|███████▌  | 3/4 [00:01<00:00,  2.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 7.190760612487793\n",
            "loss\n",
            "tensor([ 69, 122, 484, 230], device='cuda:0')\n",
            "tensor([ 69,  75, 484, 173], device='cuda:0')\n",
            "ce1 : 3.676973581314087\n",
            "ce2 : 3.4049580097198486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 7.082: 100%|██████████| 4/4 [00:01<00:00,  2.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 7.0819315910339355\n",
            "train score: 7.659\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation score: 8.808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss\n",
            "tensor([262,   0, 173,  69], device='cuda:0')\n",
            "tensor([446,   0, 173,  69], device='cuda:0')\n",
            "ce1 : 3.119781255722046\n",
            "ce2 : 3.115370512008667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 6.235:  25%|██▌       | 1/4 [00:00<00:01,  2.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 6.235151767730713\n",
            "loss\n",
            "tensor([ 44, 328, 484,   0], device='cuda:0')\n",
            "tensor([ 44, 328, 484,   0], device='cuda:0')\n",
            "ce1 : 1.8464653491973877\n",
            "ce2 : 1.8028099536895752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 3.649:  50%|█████     | 2/4 [00:00<00:00,  2.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 3.649275302886963\n",
            "loss\n",
            "tensor([121,   0,  24, 288], device='cuda:0')\n",
            "tensor([121,   0,  24, 288], device='cuda:0')\n",
            "ce1 : 1.430064082145691\n",
            "ce2 : 1.4765620231628418\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 2.907:  75%|███████▌  | 3/4 [00:01<00:00,  2.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 2.9066262245178223\n",
            "loss\n",
            "tensor([  0,  75,  23, 351], device='cuda:0')\n",
            "tensor([  0,  75,  23, 351], device='cuda:0')\n",
            "ce1 : 1.3020060062408447\n",
            "ce2 : 1.2745482921600342\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 2.577: 100%|██████████| 4/4 [00:01<00:00,  2.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 2.576554298400879\n",
            "train score: 3.842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 15.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation score: 7.727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss\n",
            "tensor([173,   0, 328, 446], device='cuda:0')\n",
            "tensor([173,   0, 328, 446], device='cuda:0')\n",
            "ce1 : 1.1851024627685547\n",
            "ce2 : 1.5206915140151978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 2.706:  25%|██▌       | 1/4 [00:00<00:01,  2.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 2.705793857574463\n",
            "loss\n",
            "tensor([ 75,   0,   0, 288], device='cuda:0')\n",
            "tensor([ 75,   0,   0, 288], device='cuda:0')\n",
            "ce1 : 0.3714038133621216\n",
            "ce2 : 0.31894543766975403\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.690:  50%|█████     | 2/4 [00:00<00:00,  2.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.6903492212295532\n",
            "loss\n",
            "tensor([ 23, 351,  44, 121], device='cuda:0')\n",
            "tensor([ 23, 351,  44, 121], device='cuda:0')\n",
            "ce1 : 0.12576964497566223\n",
            "ce2 : 0.19571584463119507\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.321:  75%|███████▌  | 3/4 [00:01<00:00,  2.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.3214854896068573\n",
            "loss\n",
            "tensor([  0, 484,  69,  24], device='cuda:0')\n",
            "tensor([  0, 484,  69,  24], device='cuda:0')\n",
            "ce1 : 0.24556851387023926\n",
            "ce2 : 0.31459081172943115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.560: 100%|██████████| 4/4 [00:01<00:00,  2.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.5601593255996704\n",
            "train score: 1.069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 15.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation score: 7.907\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss\n",
            "tensor([ 23,  69, 328,  44], device='cuda:0')\n",
            "tensor([ 23,  69, 328,  44], device='cuda:0')\n",
            "ce1 : 0.07574223726987839\n",
            "ce2 : 0.0567752867937088\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.133:  25%|██▌       | 1/4 [00:00<00:01,  2.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.1325175166130066\n",
            "loss\n",
            "tensor([484, 351,   0,   0], device='cuda:0')\n",
            "tensor([484, 351,   0,   0], device='cuda:0')\n",
            "ce1 : 0.0216984860599041\n",
            "ce2 : 0.024246763437986374\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.046:  50%|█████     | 2/4 [00:00<00:00,  2.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.04594524949789047\n",
            "loss\n",
            "tensor([121,  24,   0, 173], device='cuda:0')\n",
            "tensor([121,  24,   0, 173], device='cuda:0')\n",
            "ce1 : 0.06536117196083069\n",
            "ce2 : 0.7881587743759155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.854:  75%|███████▌  | 3/4 [00:01<00:00,  2.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.8535199165344238\n",
            "loss\n",
            "tensor([288,   0,  75, 446], device='cuda:0')\n",
            "tensor([288,   0,  75, 446], device='cuda:0')\n",
            "ce1 : 0.04390781745314598\n",
            "ce2 : 0.04118958115577698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.085: 100%|██████████| 4/4 [00:01<00:00,  2.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.08509740233421326\n",
            "train score: 0.279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 15.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation score: 6.732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss\n",
            "tensor([ 44, 446,  69,  24], device='cuda:0')\n",
            "tensor([ 44, 446,  69,  24], device='cuda:0')\n",
            "ce1 : 0.02723061293363571\n",
            "ce2 : 0.024791782721877098\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.052:  25%|██▌       | 1/4 [00:00<00:01,  2.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.05202239751815796\n",
            "loss\n",
            "tensor([351, 484,   0,   0], device='cuda:0')\n",
            "tensor([351, 484,   0,   0], device='cuda:0')\n",
            "ce1 : 0.0058105215430259705\n",
            "ce2 : 0.006779422052204609\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.013:  50%|█████     | 2/4 [00:00<00:00,  2.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.01258994359523058\n",
            "loss\n",
            "tensor([328, 121, 288, 173], device='cuda:0')\n",
            "tensor([328, 121, 288, 173], device='cuda:0')\n",
            "ce1 : 0.011053328402340412\n",
            "ce2 : 0.52120041847229\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.532:  75%|███████▌  | 3/4 [00:01<00:00,  2.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.5322537422180176\n",
            "loss\n",
            "tensor([75,  0,  0, 23], device='cuda:0')\n",
            "tensor([75,  0,  0, 23], device='cuda:0')\n",
            "ce1 : 0.00347633333876729\n",
            "ce2 : 0.00453108549118042\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.008: 100%|██████████| 4/4 [00:01<00:00,  2.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.008007418364286423\n",
            "train score: 0.151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 15.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation score: 6.746\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss\n",
            "tensor([23, 24,  0,  0], device='cuda:0')\n",
            "tensor([23, 24,  0,  0], device='cuda:0')\n",
            "ce1 : 0.004185165744274855\n",
            "ce2 : 0.010275794193148613\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.014:  25%|██▌       | 1/4 [00:00<00:01,  2.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.014460960403084755\n",
            "loss\n",
            "tensor([  0,  75, 288, 121], device='cuda:0')\n",
            "tensor([  0,  75, 288, 121], device='cuda:0')\n",
            "ce1 : 0.00397625844925642\n",
            "ce2 : 0.0032149087637662888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.007:  50%|█████     | 2/4 [00:00<00:00,  2.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.007191167213022709\n",
            "loss\n",
            "tensor([328, 173,  44, 351], device='cuda:0')\n",
            "tensor([328, 173,  44, 351], device='cuda:0')\n",
            "ce1 : 0.3242195248603821\n",
            "ce2 : 0.1128040999174118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.437:  75%|███████▌  | 3/4 [00:01<00:00,  2.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.4370236396789551\n",
            "loss\n",
            "tensor([  0, 446,  69, 484], device='cuda:0')\n",
            "tensor([  0, 446,  69, 484], device='cuda:0')\n",
            "ce1 : 0.00427699601277709\n",
            "ce2 : 0.001987694064155221\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.006: 100%|██████████| 4/4 [00:01<00:00,  2.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.006264690309762955\n",
            "train score: 0.116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 15.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation score: 6.351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss\n",
            "tensor([ 69,  75, 351,   0], device='cuda:0')\n",
            "tensor([ 69,  75, 351,   0], device='cuda:0')\n",
            "ce1 : 0.0008282119524665177\n",
            "ce2 : 0.0013675997033715248\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.002:  25%|██▌       | 1/4 [00:00<00:01,  2.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.0021958115976303816\n",
            "loss\n",
            "tensor([ 23, 484,   0,  24], device='cuda:0')\n",
            "tensor([ 23, 484,   0,  24], device='cuda:0')\n",
            "ce1 : 0.000644933432340622\n",
            "ce2 : 0.0005703970091417432\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.001:  50%|█████     | 2/4 [00:00<00:00,  2.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.0012153304414823651\n",
            "loss\n",
            "tensor([ 44, 288, 446, 173], device='cuda:0')\n",
            "tensor([ 44, 288, 446, 173], device='cuda:0')\n",
            "ce1 : 0.016340041533112526\n",
            "ce2 : 0.0676371231675148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.084:  75%|███████▌  | 3/4 [00:01<00:00,  2.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.08397716283798218\n",
            "loss\n",
            "tensor([328, 121,   0,   0], device='cuda:0')\n",
            "tensor([328, 121,   0,   0], device='cuda:0')\n",
            "ce1 : 0.0007962967501953244\n",
            "ce2 : 0.0008262195624411106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.002: 100%|██████████| 4/4 [00:01<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.001622516312636435\n",
            "train score: 0.022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation score: 6.239\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss\n",
            "tensor([ 0, 24,  0, 44], device='cuda:0')\n",
            "tensor([ 0, 24,  0, 44], device='cuda:0')\n",
            "ce1 : 0.00030139542650431395\n",
            "ce2 : 0.0004354120756033808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.001:  25%|██▌       | 1/4 [00:00<00:01,  2.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.0007368074730038643\n",
            "loss\n",
            "tensor([ 23, 351,  69, 484], device='cuda:0')\n",
            "tensor([ 23, 351,  69, 484], device='cuda:0')\n",
            "ce1 : 0.00045401862007565796\n",
            "ce2 : 0.0001891935826279223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.001:  50%|█████     | 2/4 [00:00<00:00,  2.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.0006432122318074107\n",
            "loss\n",
            "tensor([173, 328, 446, 121], device='cuda:0')\n",
            "tensor([173, 328, 446, 121], device='cuda:0')\n",
            "ce1 : 0.0010600271634757519\n",
            "ce2 : 0.004683686885982752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.006:  75%|███████▌  | 3/4 [00:01<00:00,  2.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.005743714049458504\n",
            "loss\n",
            "tensor([288,   0,   0,  75], device='cuda:0')\n",
            "tensor([288,   0,   0,  75], device='cuda:0')\n",
            "ce1 : 0.0012791547924280167\n",
            "ce2 : 0.0009137282031588256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.002: 100%|██████████| 4/4 [00:01<00:00,  2.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.002192883053794503\n",
            "train score: 0.002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 15.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation score: 6.658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss\n",
            "tensor([ 0,  0, 24, 69], device='cuda:0')\n",
            "tensor([ 0,  0, 24, 69], device='cuda:0')\n",
            "ce1 : 0.0002582032175268978\n",
            "ce2 : 0.00011547665053512901\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  25%|██▌       | 1/4 [00:00<00:01,  2.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.00037367985351011157\n",
            "loss\n",
            "tensor([ 44, 446, 351, 328], device='cuda:0')\n",
            "tensor([ 44, 446, 351, 328], device='cuda:0')\n",
            "ce1 : 0.00023206777404993773\n",
            "ce2 : 0.0005561953294090927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.001:  50%|█████     | 2/4 [00:00<00:00,  2.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.0007882631034590304\n",
            "loss\n",
            "tensor([173,   0,   0, 288], device='cuda:0')\n",
            "tensor([173,   0,   0, 288], device='cuda:0')\n",
            "ce1 : 0.0006993780843913555\n",
            "ce2 : 0.0007611799519509077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.001:  75%|███████▌  | 3/4 [00:01<00:00,  2.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.0014605580363422632\n",
            "loss\n",
            "tensor([ 23,  75, 121, 484], device='cuda:0')\n",
            "tensor([ 23,  75, 121, 484], device='cuda:0')\n",
            "ce1 : 0.0004992297035641968\n",
            "ce2 : 6.791690975660458e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.001: 100%|██████████| 4/4 [00:01<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.0005671466351486742\n",
            "train score: 0.001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 15.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation score: 6.699\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss\n",
            "tensor([  0,   0,  24, 328], device='cuda:0')\n",
            "tensor([  0,   0,  24, 328], device='cuda:0')\n",
            "ce1 : 0.0002450612373650074\n",
            "ce2 : 0.00011404356337152421\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  25%|██▌       | 1/4 [00:00<00:01,  2.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.0003591048007365316\n",
            "loss\n",
            "tensor([ 44, 484,  69,  23], device='cuda:0')\n",
            "tensor([ 44, 484,  69,  23], device='cuda:0')\n",
            "ce1 : 0.0002244433999294415\n",
            "ce2 : 8.052209159359336e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  50%|█████     | 2/4 [00:00<00:00,  2.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.00030496547697111964\n",
            "loss\n",
            "tensor([121,   0, 173,   0], device='cuda:0')\n",
            "tensor([121,   0, 173,   0], device='cuda:0')\n",
            "ce1 : 0.0006481457385234535\n",
            "ce2 : 0.00023239231086336076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.001:  75%|███████▌  | 3/4 [00:01<00:00,  2.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.0008805380202829838\n",
            "loss\n",
            "tensor([ 75, 446, 351, 288], device='cuda:0')\n",
            "tensor([ 75, 446, 351, 288], device='cuda:0')\n",
            "ce1 : 8.922372944653034e-05\n",
            "ce2 : 0.0002566502953413874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000: 100%|██████████| 4/4 [00:01<00:00,  2.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.00034587402478791773\n",
            "train score: 0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 15.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation score: 6.736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss\n",
            "tensor([121, 446,   0,  23], device='cuda:0')\n",
            "tensor([121, 446,   0,  23], device='cuda:0')\n",
            "ce1 : 0.00016082719957921654\n",
            "ce2 : 0.00013516774924937636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  25%|██▌       | 1/4 [00:00<00:01,  2.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.0002959949488285929\n",
            "loss\n",
            "tensor([328,  24,  75,   0], device='cuda:0')\n",
            "tensor([328,  24,  75,   0], device='cuda:0')\n",
            "ce1 : 0.00018707659910432994\n",
            "ce2 : 0.00020545917504932731\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  50%|█████     | 2/4 [00:00<00:00,  2.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.00039253575960174203\n",
            "loss\n",
            "tensor([  0,  44, 484, 288], device='cuda:0')\n",
            "tensor([  0,  44, 484, 288], device='cuda:0')\n",
            "ce1 : 0.00016240922559518367\n",
            "ce2 : 9.232234879164025e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  75%|███████▌  | 3/4 [00:01<00:00,  2.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.0002547315671108663\n",
            "loss\n",
            "tensor([  0,  69, 173, 351], device='cuda:0')\n",
            "tensor([  0,  69, 173, 351], device='cuda:0')\n",
            "ce1 : 0.00027605408104136586\n",
            "ce2 : 0.00010862202907446772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000: 100%|██████████| 4/4 [00:01<00:00,  2.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.00038467609556391835\n",
            "train score: 0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 15.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation score: 6.806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss\n",
            "tensor([  0, 328,  24, 484], device='cuda:0')\n",
            "tensor([  0, 328,  24, 484], device='cuda:0')\n",
            "ce1 : 0.00018356442160438746\n",
            "ce2 : 0.0001500666403444484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  25%|██▌       | 1/4 [00:00<00:01,  2.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.00033363106194883585\n",
            "loss\n",
            "tensor([  0,  23,   0, 288], device='cuda:0')\n",
            "tensor([  0,  23,   0, 288], device='cuda:0')\n",
            "ce1 : 0.00010293176455888897\n",
            "ce2 : 6.833354564150795e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  50%|█████     | 2/4 [00:00<00:00,  2.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.0001712653029244393\n",
            "loss\n",
            "tensor([ 69, 351, 121, 446], device='cuda:0')\n",
            "tensor([ 69, 351, 121, 446], device='cuda:0')\n",
            "ce1 : 8.710782276466489e-05\n",
            "ce2 : 0.00010522604134166613\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  75%|███████▌  | 3/4 [00:01<00:00,  2.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.0001923338568303734\n",
            "loss\n",
            "tensor([ 75, 173,  44,   0], device='cuda:0')\n",
            "tensor([ 75, 173,  44,   0], device='cuda:0')\n",
            "ce1 : 0.0001913585583679378\n",
            "ce2 : 0.00011613049719016999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000: 100%|██████████| 4/4 [00:01<00:00,  2.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.000307489070110023\n",
            "train score: 0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 15.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation score: 6.884\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss\n",
            "tensor([351,  44,   0, 288], device='cuda:0')\n",
            "tensor([351,  44,   0, 288], device='cuda:0')\n",
            "ce1 : 9.13095282157883e-05\n",
            "ce2 : 8.850870653986931e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  25%|██▌       | 1/4 [00:00<00:01,  2.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.0001798182347556576\n",
            "loss\n",
            "tensor([  0,   0,  24, 446], device='cuda:0')\n",
            "tensor([  0,   0,  24, 446], device='cuda:0')\n",
            "ce1 : 0.00010215678048552945\n",
            "ce2 : 0.00010415119322715327\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  50%|█████     | 2/4 [00:00<00:00,  2.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.00020630797371268272\n",
            "loss\n",
            "tensor([ 75, 484,  23, 121], device='cuda:0')\n",
            "tensor([ 75, 484,  23, 121], device='cuda:0')\n",
            "ce1 : 6.842333823442459e-05\n",
            "ce2 : 9.083143231691793e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  75%|███████▌  | 3/4 [00:01<00:00,  2.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.0001592547632753849\n",
            "loss\n",
            "tensor([328, 173,  69,   0], device='cuda:0')\n",
            "tensor([328, 173,  69,   0], device='cuda:0')\n",
            "ce1 : 0.00016455200966447592\n",
            "ce2 : 8.359145431313664e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000: 100%|██████████| 4/4 [00:01<00:00,  2.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.0002481434494256973\n",
            "train score: 0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 15.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation score: 6.942\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss\n",
            "tensor([  0,  24,  75, 351], device='cuda:0')\n",
            "tensor([  0,  24,  75, 351], device='cuda:0')\n",
            "ce1 : 5.569847780861892e-05\n",
            "ce2 : 8.779247582424432e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  25%|██▌       | 1/4 [00:00<00:01,  2.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.00014349094999488443\n",
            "loss\n",
            "tensor([  0, 121, 484,   0], device='cuda:0')\n",
            "tensor([  0, 121, 484,   0], device='cuda:0')\n",
            "ce1 : 8.061187691055238e-05\n",
            "ce2 : 9.610753477318212e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  50%|█████     | 2/4 [00:00<00:00,  2.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.00017671941895969212\n",
            "loss\n",
            "tensor([ 23, 446,  69, 328], device='cuda:0')\n",
            "tensor([ 23, 446,  69, 328], device='cuda:0')\n",
            "ce1 : 9.101151954382658e-05\n",
            "ce2 : 5.936413799645379e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  75%|███████▌  | 3/4 [00:01<00:00,  2.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.00015037565026432276\n",
            "loss\n",
            "tensor([  0,  44, 173, 288], device='cuda:0')\n",
            "tensor([  0,  44, 173, 288], device='cuda:0')\n",
            "ce1 : 0.00012435653479769826\n",
            "ce2 : 7.033028668956831e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000: 100%|██████████| 4/4 [00:01<00:00,  2.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.00019468681421130896\n",
            "train score: 0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 15.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation score: 6.974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss\n",
            "tensor([446,  24,   0,  44], device='cuda:0')\n",
            "tensor([446,  24,   0,  44], device='cuda:0')\n",
            "ce1 : 7.444337825290859e-05\n",
            "ce2 : 4.950034053763375e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  25%|██▌       | 1/4 [00:00<00:01,  2.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.00012394372606649995\n",
            "loss\n",
            "tensor([173, 484,   0, 121], device='cuda:0')\n",
            "tensor([173, 484,   0, 121], device='cuda:0')\n",
            "ce1 : 8.573667582822964e-05\n",
            "ce2 : 9.187602699967101e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  50%|█████     | 2/4 [00:00<00:00,  2.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.00017761270282790065\n",
            "loss\n",
            "tensor([351,  23, 288,   0], device='cuda:0')\n",
            "tensor([351,  23, 288,   0], device='cuda:0')\n",
            "ce1 : 7.637988164788112e-05\n",
            "ce2 : 4.336121855885722e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  75%|███████▌  | 3/4 [00:01<00:00,  2.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.00011974110384471714\n",
            "loss\n",
            "tensor([ 75,  69,   0, 328], device='cuda:0')\n",
            "tensor([ 75,  69,   0, 328], device='cuda:0')\n",
            "ce1 : 6.964488420635462e-05\n",
            "ce2 : 8.23402515379712e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000: 100%|██████████| 4/4 [00:01<00:00,  2.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.00015198513574432582\n",
            "train score: 0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 15.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation score: 6.979\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss\n",
            "tensor([ 24, 288,  75,   0], device='cuda:0')\n",
            "tensor([ 24, 288,  75,   0], device='cuda:0')\n",
            "ce1 : 7.152242324082181e-05\n",
            "ce2 : 6.815527740400285e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  25%|██▌       | 1/4 [00:00<00:01,  2.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.00013967769336886704\n",
            "loss\n",
            "tensor([  0, 484, 351, 173], device='cuda:0')\n",
            "tensor([  0, 484, 351, 173], device='cuda:0')\n",
            "ce1 : 6.171811401145533e-05\n",
            "ce2 : 7.295265095308423e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  50%|█████     | 2/4 [00:00<00:00,  2.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.00013467075768858194\n",
            "loss\n",
            "tensor([328,  23,  69,  44], device='cuda:0')\n",
            "tensor([328,  23,  69,  44], device='cuda:0')\n",
            "ce1 : 6.708249566145241e-05\n",
            "ce2 : 5.084124131826684e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  75%|███████▌  | 3/4 [00:01<00:00,  2.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.00011792373697971925\n",
            "loss\n",
            "tensor([  0, 121,   0, 446], device='cuda:0')\n",
            "tensor([  0, 121,   0, 446], device='cuda:0')\n",
            "ce1 : 6.735092756571248e-05\n",
            "ce2 : 5.6473640142939985e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000: 100%|██████████| 4/4 [00:01<00:00,  2.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.00012382457498461008\n",
            "train score: 0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 15.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation score: 6.974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss\n",
            "tensor([44,  0,  0, 75], device='cuda:0')\n",
            "tensor([44,  0,  0, 75], device='cuda:0')\n",
            "ce1 : 4.589436139212921e-05\n",
            "ce2 : 5.504311411641538e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  25%|██▌       | 1/4 [00:00<00:01,  2.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.0001009374755085446\n",
            "loss\n",
            "tensor([121, 484, 288,  24], device='cuda:0')\n",
            "tensor([121, 484, 288,  24], device='cuda:0')\n",
            "ce1 : 6.562229827977717e-05\n",
            "ce2 : 5.4745283705415204e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  50%|█████     | 2/4 [00:00<00:00,  2.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.00012036757834721357\n",
            "loss\n",
            "tensor([351,  23, 328,   0], device='cuda:0')\n",
            "tensor([351,  23, 328,   0], device='cuda:0')\n",
            "ce1 : 5.6980141380336136e-05\n",
            "ce2 : 5.2629271522164345e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  75%|███████▌  | 3/4 [00:01<00:00,  2.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.00010960941290250048\n",
            "loss\n",
            "tensor([446,  69, 173,   0], device='cuda:0')\n",
            "tensor([446,  69, 173,   0], device='cuda:0')\n",
            "ce1 : 6.97349023539573e-05\n",
            "ce2 : 6.41913793515414e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000: 100%|██████████| 4/4 [00:01<00:00,  2.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.0001339262817054987\n",
            "train score: 0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 15.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation score: 6.959\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss\n",
            "tensor([351,   0,   0, 173], device='cuda:0')\n",
            "tensor([351,   0,   0, 173], device='cuda:0')\n",
            "ce1 : 5.4536543757421896e-05\n",
            "ce2 : 6.204569945111871e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  25%|██▌       | 1/4 [00:00<00:01,  2.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.00011658224684651941\n",
            "loss\n",
            "tensor([484, 121,  75,  24], device='cuda:0')\n",
            "tensor([484, 121,  75,  24], device='cuda:0')\n",
            "ce1 : 4.19904499722179e-05\n",
            "ce2 : 5.861939280293882e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  50%|█████     | 2/4 [00:00<00:00,  2.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.00010060984641313553\n",
            "loss\n",
            "tensor([23, 44, 69,  0], device='cuda:0')\n",
            "tensor([23, 44, 69,  0], device='cuda:0')\n",
            "ce1 : 4.649052789318375e-05\n",
            "ce2 : 4.598375744535588e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  75%|███████▌  | 3/4 [00:01<00:00,  2.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 9.247428533853963e-05\n",
            "loss\n",
            "tensor([288,   0, 446, 328], device='cuda:0')\n",
            "tensor([288,   0, 446, 328], device='cuda:0')\n",
            "ce1 : 7.506917609134689e-05\n",
            "ce2 : 4.327192436903715e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000: 100%|██████████| 4/4 [00:01<00:00,  2.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.00011834110046038404\n",
            "train score: 0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation score: 6.941\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss\n",
            "tensor([  0,   0, 121, 288], device='cuda:0')\n",
            "tensor([  0,   0, 121, 288], device='cuda:0')\n",
            "ce1 : 5.72186618228443e-05\n",
            "ce2 : 4.574534614221193e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  25%|██▌       | 1/4 [00:00<00:01,  2.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.00010296401160303503\n",
            "loss\n",
            "tensor([ 24, 351, 484,   0], device='cuda:0')\n",
            "tensor([ 24, 351, 484,   0], device='cuda:0')\n",
            "ce1 : 4.6013643441256136e-05\n",
            "ce2 : 3.9844864659244195e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  50%|█████     | 2/4 [00:00<00:00,  2.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 8.585851173847914e-05\n",
            "loss\n",
            "tensor([446,   0, 328,  23], device='cuda:0')\n",
            "tensor([446,   0, 328,  23], device='cuda:0')\n",
            "ce1 : 5.6950510042952374e-05\n",
            "ce2 : 4.061959043610841e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  75%|███████▌  | 3/4 [00:01<00:00,  2.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 9.757009684108198e-05\n",
            "loss\n",
            "tensor([173,  44,  69,  75], device='cuda:0')\n",
            "tensor([173,  44,  69,  75], device='cuda:0')\n",
            "ce1 : 4.2795039917109534e-05\n",
            "ce2 : 6.776776717742905e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000: 100%|██████████| 4/4 [00:01<00:00,  2.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.00011056280345655978\n",
            "train score: 0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 15.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation score: 6.915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss\n",
            "tensor([  0, 351,  23, 173], device='cuda:0')\n",
            "tensor([  0, 351,  23, 173], device='cuda:0')\n",
            "ce1 : 4.33613131463062e-05\n",
            "ce2 : 4.714534225058742e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  25%|██▌       | 1/4 [00:00<00:01,  2.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 9.050665539689362e-05\n",
            "loss\n",
            "tensor([121,  24,   0,   0], device='cuda:0')\n",
            "tensor([121,  24,   0,   0], device='cuda:0')\n",
            "ce1 : 5.03348492202349e-05\n",
            "ce2 : 3.942762850783765e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  50%|█████     | 2/4 [00:00<00:00,  2.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 8.976247772807255e-05\n",
            "loss\n",
            "tensor([ 75,   0,  44, 328], device='cuda:0')\n",
            "tensor([ 75,   0,  44, 328], device='cuda:0')\n",
            "ce1 : 4.434468428371474e-05\n",
            "ce2 : 5.4477139201480895e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  75%|███████▌  | 3/4 [00:01<00:00,  2.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 9.882182348519564e-05\n",
            "loss\n",
            "tensor([446, 484,  69, 288], device='cuda:0')\n",
            "tensor([446, 484,  69, 288], device='cuda:0')\n",
            "ce1 : 5.185457848710939e-05\n",
            "ce2 : 4.2348190618213266e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000: 100%|██████████| 4/4 [00:01<00:00,  2.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 9.420276910532266e-05\n",
            "train score: 0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation score: 6.889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss\n",
            "tensor([ 44, 328,  75, 173], device='cuda:0')\n",
            "tensor([ 44, 328,  75, 173], device='cuda:0')\n",
            "ce1 : 4.759295188705437e-05\n",
            "ce2 : 6.487722566816956e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  25%|██▌       | 1/4 [00:00<00:01,  2.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.00011247018119320273\n",
            "loss\n",
            "tensor([484,   0,   0, 288], device='cuda:0')\n",
            "tensor([484,   0,   0, 288], device='cuda:0')\n",
            "ce1 : 4.756326234200969e-05\n",
            "ce2 : 3.0040237106732093e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  50%|█████     | 2/4 [00:00<00:00,  2.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 7.760350126773119e-05\n",
            "loss\n",
            "tensor([ 23,  69, 446,   0], device='cuda:0')\n",
            "tensor([ 23,  69, 446,   0], device='cuda:0')\n",
            "ce1 : 4.354021075414494e-05\n",
            "ce2 : 3.939777525374666e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  75%|███████▌  | 3/4 [00:01<00:00,  2.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 8.29379860078916e-05\n",
            "loss\n",
            "tensor([121,  24,   0, 351], device='cuda:0')\n",
            "tensor([121,  24,   0, 351], device='cuda:0')\n",
            "ce1 : 4.1275332478107885e-05\n",
            "ce2 : 3.924886914319359e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000: 100%|██████████| 4/4 [00:01<00:00,  2.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 8.052420162130147e-05\n",
            "train score: 0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation score: 6.865\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss\n",
            "tensor([484, 121,   0,   0], device='cuda:0')\n",
            "tensor([484, 121,   0,   0], device='cuda:0')\n",
            "ce1 : 4.3659438233589754e-05\n",
            "ce2 : 4.187130616628565e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  25%|██▌       | 1/4 [00:00<00:01,  2.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 8.55307443998754e-05\n",
            "loss\n",
            "tensor([24, 69, 75,  0], device='cuda:0')\n",
            "tensor([24, 69, 75,  0], device='cuda:0')\n",
            "ce1 : 3.5851488064508885e-05\n",
            "ce2 : 4.056012403452769e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  50%|█████     | 2/4 [00:00<00:00,  2.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 7.641161209903657e-05\n",
            "loss\n",
            "tensor([446,  23, 351,   0], device='cuda:0')\n",
            "tensor([446,  23, 351,   0], device='cuda:0')\n",
            "ce1 : 3.558329990482889e-05\n",
            "ce2 : 2.527200740587432e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  75%|███████▌  | 3/4 [00:01<00:00,  2.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 6.0855309129692614e-05\n",
            "loss\n",
            "tensor([328, 288,  44, 173], device='cuda:0')\n",
            "tensor([328, 288,  44, 173], device='cuda:0')\n",
            "ce1 : 5.5609518312849104e-05\n",
            "ce2 : 5.656290159095079e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000: 100%|██████████| 4/4 [00:01<00:00,  2.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.00011217241990379989\n",
            "train score: 0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 14.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation score: 6.849\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss\n",
            "tensor([ 23,   0,   0, 288], device='cuda:0')\n",
            "tensor([ 23,   0,   0, 288], device='cuda:0')\n",
            "ce1 : 4.3271968024782836e-05\n",
            "ce2 : 2.7179308744962327e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  25%|██▌       | 1/4 [00:00<00:01,  2.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 7.045127858873457e-05\n",
            "loss\n",
            "tensor([ 69, 484, 328,  44], device='cuda:0')\n",
            "tensor([ 69, 484, 328,  44], device='cuda:0')\n",
            "ce1 : 4.166271537542343e-05\n",
            "ce2 : 4.24971804022789e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  50%|█████     | 2/4 [00:00<00:00,  2.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 8.415989577770233e-05\n",
            "loss\n",
            "tensor([  0, 173,   0, 121], device='cuda:0')\n",
            "tensor([  0, 173,   0, 121], device='cuda:0')\n",
            "ce1 : 4.491103391046636e-05\n",
            "ce2 : 5.182451423024759e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  75%|███████▌  | 3/4 [00:01<00:00,  2.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 9.673554450273514e-05\n",
            "loss\n",
            "tensor([446,  24, 351,  75], device='cuda:0')\n",
            "tensor([446,  24, 351,  75], device='cuda:0')\n",
            "ce1 : 3.4450815292075276e-05\n",
            "ce2 : 3.483830369077623e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000: 100%|██████████| 4/4 [00:01<00:00,  2.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 6.92891189828515e-05\n",
            "train score: 0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation score: 6.830\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss\n",
            "tensor([ 24,   0, 173,   0], device='cuda:0')\n",
            "tensor([ 24,   0, 173,   0], device='cuda:0')\n",
            "ce1 : 4.431501656654291e-05\n",
            "ce2 : 4.824841016670689e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  25%|██▌       | 1/4 [00:00<00:01,  2.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 9.256342309527099e-05\n",
            "loss\n",
            "tensor([446, 328,  44, 484], device='cuda:0')\n",
            "tensor([446, 328,  44, 484], device='cuda:0')\n",
            "ce1 : 4.3063380871899426e-05\n",
            "ce2 : 3.883164390572347e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  50%|█████     | 2/4 [00:00<00:00,  2.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 8.189502113964409e-05\n",
            "loss\n",
            "tensor([121, 288,   0,   0], device='cuda:0')\n",
            "tensor([121, 288,   0,   0], device='cuda:0')\n",
            "ce1 : 4.3033596739405766e-05\n",
            "ce2 : 3.316940274089575e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  75%|███████▌  | 3/4 [00:01<00:00,  2.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 7.620299584232271e-05\n",
            "loss\n",
            "tensor([ 69,  75,  23, 351], device='cuda:0')\n",
            "tensor([ 69,  75,  23, 351], device='cuda:0')\n",
            "ce1 : 2.6404493837617338e-05\n",
            "ce2 : 3.063626718358137e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000: 100%|██████████| 4/4 [00:01<00:00,  2.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 5.7040761021198705e-05\n",
            "train score: 0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation score: 6.818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss\n",
            "tensor([484, 121,  69,  44], device='cuda:0')\n",
            "tensor([484, 121,  69,  44], device='cuda:0')\n",
            "ce1 : 3.5762135667027906e-05\n",
            "ce2 : 3.6864781577605754e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  25%|██▌       | 1/4 [00:00<00:01,  2.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 7.262692088261247e-05\n",
            "loss\n",
            "tensor([173,  24, 328, 288], device='cuda:0')\n",
            "tensor([173,  24, 328, 288], device='cuda:0')\n",
            "ce1 : 5.197387872613035e-05\n",
            "ce2 : 5.107965262141079e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  50%|█████     | 2/4 [00:00<00:00,  2.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 0.00010305353498551995\n",
            "loss\n",
            "tensor([ 75, 446,   0,   0], device='cuda:0')\n",
            "tensor([ 75, 446,   0,   0], device='cuda:0')\n",
            "ce1 : 3.2424344681203365e-05\n",
            "ce2 : 3.388459299458191e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  75%|███████▌  | 3/4 [00:01<00:00,  2.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 6.630893767578527e-05\n",
            "loss\n",
            "tensor([  0, 351,   0,  23], device='cuda:0')\n",
            "tensor([  0, 351,   0,  23], device='cuda:0')\n",
            "ce1 : 3.0308496206998825e-05\n",
            "ce2 : 2.3483935365220532e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000: 100%|██████████| 4/4 [00:01<00:00,  2.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 5.379243157221936e-05\n",
            "train score: 0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 15.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation score: 6.809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss\n",
            "tensor([  0,   0, 484, 121], device='cuda:0')\n",
            "tensor([  0,   0, 484, 121], device='cuda:0')\n",
            "ce1 : 3.814623778453097e-05\n",
            "ce2 : 3.454023681115359e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  25%|██▌       | 1/4 [00:00<00:01,  2.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 7.268647459568456e-05\n",
            "loss\n",
            "tensor([ 44, 446,   0,  24], device='cuda:0')\n",
            "tensor([ 44, 446,   0,  24], device='cuda:0')\n",
            "ce1 : 3.474888580967672e-05\n",
            "ce2 : 2.7924357709707692e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  50%|█████     | 2/4 [00:00<00:00,  2.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 6.267324351938441e-05\n",
            "loss\n",
            "tensor([288, 173, 328,   0], device='cuda:0')\n",
            "tensor([288, 173, 328,   0], device='cuda:0')\n",
            "ce1 : 4.714611714007333e-05\n",
            "ce2 : 4.9083027988672256e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  75%|███████▌  | 3/4 [00:01<00:00,  2.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 9.622914512874559e-05\n",
            "loss\n",
            "tensor([351,  75,  69,  23], device='cuda:0')\n",
            "tensor([351,  75,  69,  23], device='cuda:0')\n",
            "ce1 : 2.4765411581029184e-05\n",
            "ce2 : 2.8103155273129232e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000: 100%|██████████| 4/4 [00:01<00:00,  2.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 5.2868566854158416e-05\n",
            "train score: 0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation score: 6.798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss\n",
            "tensor([  0, 446,   0, 121], device='cuda:0')\n",
            "tensor([  0, 446,   0, 121], device='cuda:0')\n",
            "ce1 : 3.507670044200495e-05\n",
            "ce2 : 2.6464067559572868e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  25%|██▌       | 1/4 [00:00<00:01,  2.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 6.154076982056722e-05\n",
            "loss\n",
            "tensor([484,  24,  44, 288], device='cuda:0')\n",
            "tensor([484,  24,  44, 288], device='cuda:0')\n",
            "ce1 : 3.719258165801875e-05\n",
            "ce2 : 3.1172741728369147e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  50%|█████     | 2/4 [00:00<00:00,  2.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 6.836531974840909e-05\n",
            "loss\n",
            "tensor([ 69,  23,  75, 328], device='cuda:0')\n",
            "tensor([ 69,  23,  75, 328], device='cuda:0')\n",
            "ce1 : 3.057663707295433e-05\n",
            "ce2 : 3.248394205002114e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  75%|███████▌  | 3/4 [00:01<00:00,  2.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 6.306057912297547e-05\n",
            "loss\n",
            "tensor([173, 351,   0,   0], device='cuda:0')\n",
            "tensor([173, 351,   0,   0], device='cuda:0')\n",
            "ce1 : 3.695413761306554e-05\n",
            "ce2 : 4.50896768597886e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000: 100%|██████████| 4/4 [00:01<00:00,  2.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 8.204381447285414e-05\n",
            "train score: 0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation score: 6.786\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss\n",
            "tensor([484,   0, 351,   0], device='cuda:0')\n",
            "tensor([484,   0, 351,   0], device='cuda:0')\n",
            "ce1 : 3.0248882467276417e-05\n",
            "ce2 : 2.8490550903370604e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  25%|██▌       | 1/4 [00:00<00:01,  2.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 5.873943155165762e-05\n",
            "loss\n",
            "tensor([ 0, 44, 69,  0], device='cuda:0')\n",
            "tensor([ 0, 44, 69,  0], device='cuda:0')\n",
            "ce1 : 2.9772076231893152e-05\n",
            "ce2 : 2.8371385269565508e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  50%|█████     | 2/4 [00:00<00:00,  2.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 5.814346150145866e-05\n",
            "loss\n",
            "tensor([ 23, 328, 121, 446], device='cuda:0')\n",
            "tensor([ 23, 328, 121, 446], device='cuda:0')\n",
            "ce1 : 3.746077709365636e-05\n",
            "ce2 : 3.191772339050658e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  75%|███████▌  | 3/4 [00:01<00:00,  2.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 6.937849684618413e-05\n",
            "loss\n",
            "tensor([288,  24,  75, 173], device='cuda:0')\n",
            "tensor([288,  24,  75, 173], device='cuda:0')\n",
            "ce1 : 3.7460733437910676e-05\n",
            "ce2 : 4.2616222344804555e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000: 100%|██████████| 4/4 [00:01<00:00,  2.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 8.007695578271523e-05\n",
            "train score: 0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation score: 6.778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss\n",
            "tensor([  0,   0, 328, 446], device='cuda:0')\n",
            "tensor([  0,   0, 328, 446], device='cuda:0')\n",
            "ce1 : 3.659654612420127e-05\n",
            "ce2 : 3.3824991987785324e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  25%|██▌       | 1/4 [00:00<00:01,  2.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 7.042153447400779e-05\n",
            "loss\n",
            "tensor([121,   0, 351,  75], device='cuda:0')\n",
            "tensor([121,   0, 351,  75], device='cuda:0')\n",
            "ce1 : 2.7119713195133954e-05\n",
            "ce2 : 2.893762939493172e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  50%|█████     | 2/4 [00:00<00:00,  2.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 5.605734259006567e-05\n",
            "loss\n",
            "tensor([ 23,  24,   0, 173], device='cuda:0')\n",
            "tensor([ 23,  24,   0, 173], device='cuda:0')\n",
            "ce1 : 3.477865539025515e-05\n",
            "ce2 : 3.415259561734274e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000:  75%|███████▌  | 3/4 [00:01<00:00,  2.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 6.89312510075979e-05\n",
            "loss\n",
            "tensor([484,  69,  44, 288], device='cuda:0')\n",
            "tensor([484,  69,  44, 288], device='cuda:0')\n",
            "ce1 : 3.215616743545979e-05\n",
            "ce2 : 3.072571416851133e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train - Loss: 0.000: 100%|██████████| 4/4 [00:01<00:00,  2.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running_loss : 6.288188160397112e-05\n",
            "train score: 0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation score: 6.770\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "t = list(range(1, 31))\n",
        "plt.plot(t, train_losses, label=\"Train Loss\")\n",
        "plt.plot(t, dev_losses, label=\"Dev Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "JUoxnKMfFeCT",
        "outputId": "b4a5f01d-d2a9-4871-a8ce-0e6a44794e13"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('dump/model.30')\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BayrTZeUFglg",
        "outputId": "a858c2a0-c621-498e-8ca1-9d298400ebdb"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForQuestionAnswering(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(42000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (start_linear): Linear(in_features=768, out_features=1, bias=True)\n",
              "  (end_linear): Linear(in_features=768, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, sample in zip(range(1, 11), sample_ds):\n",
        "    print(f'------{idx}------')\n",
        "    \n",
        "    input_ids, token_type_ids, attention_mask = [\n",
        "        torch.tensor(sample[key], dtype=torch.long, device=\"cuda\")\n",
        "        for key in (\"input_ids\", \"token_type_ids\",\"attention_mask\")\n",
        "    ]\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        start_logits, end_logits = model(input_ids=input_ids[None, :], token_type_ids=token_type_ids[None, :], attention_mask=attention_mask[None, :])\n",
        "    start_logits.squeeze_(0), end_logits.squeeze_(0)\n",
        "    \n",
        "    start_prob = start_logits[token_type_ids.bool()][1:-1].softmax(-1)\n",
        "    end_prob = end_logits[token_type_ids.bool()][1:-1].softmax(-1)\n",
        "    probability = torch.triu(start_prob[:, None] @ end_prob[None, :])\n",
        "    index = torch.argmax(probability).item()\n",
        "    \n",
        "    start = index // len(end_prob)\n",
        "    end = index % len(end_prob)\n",
        "    print(sample['input_ids'].shape)\n",
        "    answer = sample[\"input_ids\"][int(start) : int(end) + 1]\n",
        "    print(tokenizer.decode(answer))\n",
        "    print(start_logits, end_logits)\n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "    # start = sample['position'][start][0]\n",
        "    # end = sample['position'][end][1]\n",
        "\n",
        "   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "169602MVFmib",
        "outputId": "23b786e0-b7d1-4f58-f2d0-5a4a1eda5aae"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------1------\n",
            "torch.Size([512])\n",
            "이르는\n",
            "tensor([-7.5908, -8.6982, -8.8808, -8.7660, -9.0423, -8.8141, -9.1434, -9.0241,\n",
            "        -9.2442, -9.0139, -8.9533, -9.2031, -9.1084, -9.1385, -8.9601, -9.2613,\n",
            "        -8.6175, -8.5485, -8.6329, -8.8884, -8.2432, -8.9139, -9.0785, -8.8417,\n",
            "        -8.7770, -8.8617, -9.0721, -9.0217, -9.0884, -9.0392, -8.8062, -8.8649,\n",
            "        -9.1086, -9.0610, -9.1205, -9.1552, -9.0314, -9.2553, -9.1514, -9.0955,\n",
            "        -8.8750, -8.6594, -8.2736, -8.9949, -8.4618, -9.1663, -8.8654, -9.1548,\n",
            "        -9.1051, -8.9640, -8.9792, -8.8815, -8.8658, -8.9528, -8.9553, -8.9092,\n",
            "        -8.7774, -8.9578, -9.2875, -8.5972, -8.9922, -9.0422, -8.9553, -9.2722,\n",
            "        -9.0630, -9.4037, -9.2012, -8.9877, -9.0589, -9.1227, -8.9123, -9.1561,\n",
            "        -8.9410, -8.9117, -9.0632, -9.1918, -8.7280, -8.9478, -9.0211, -8.8823,\n",
            "        -9.0522, -8.8023, -8.7647, -8.9590, -8.9469, -8.8244, -9.1463, -9.0646,\n",
            "        -9.0685, -9.0212, -8.8801, -8.7421, -9.0444, -9.0609, -8.9327, -8.9348,\n",
            "        -9.1186, -9.0415, -9.0312, -9.1855, -9.1815, -8.8895, -9.0630, -8.9521,\n",
            "        -8.9903, -8.9430, -8.8475, -8.9499, -9.0328, -8.8482, -9.2247, -9.0856,\n",
            "        -8.7462, -8.9069, -9.0805, -8.8830, -8.7887, -8.8596, -8.9403, -8.9677,\n",
            "        -8.6244, -9.0013, -9.0544, -9.1423, -8.9543, -8.9286, -8.9776, -8.9457,\n",
            "        -8.8881, -8.6212, -9.0401, -8.9242, -8.9724, -9.0577, -9.0275, -9.0101,\n",
            "        -9.1475, -9.1228, -8.9964, -8.7312, -8.8727, -8.5649, -9.2206, -8.7732,\n",
            "        -8.7631, -9.0043, -8.9417, -9.3316, -9.2649, -9.0523, -9.2875, -9.0094,\n",
            "        -9.0915, -8.9956, -9.1935, -9.2052, -9.0693, -9.0823, -9.0305, -9.0682,\n",
            "        -9.2876, -9.0049, -9.2459, -9.1901, -9.1550, -9.3647, -9.2072, -9.1887,\n",
            "        -8.9246, -9.1566, -9.1037, -8.9458, -9.0245, -9.0838, -9.1207, -8.9158,\n",
            "        -8.9626, -9.0312, -9.1975, -9.0473, -9.1325, -9.2530, -9.1517, -8.9913,\n",
            "        -8.9378, -8.9029, -8.7961, -8.9924, -9.1433, -9.0749, -8.8409, -8.8786,\n",
            "        -9.1527, -9.2264, -8.9330, -8.9490, -9.1035, -8.9510, -8.9954, -9.0064,\n",
            "        -9.0307, -9.1713, -9.0961, -9.0437, -9.0954, -9.0116, -9.0935, -9.1064,\n",
            "        -8.9647, -8.8503, -8.7701, -9.1096, -8.9248, -9.0617, -9.0248, -8.9585,\n",
            "        -9.2107, -9.0531, -9.1973, -9.0580, -9.0813, -9.0019, -9.0473, -8.9739,\n",
            "        -9.1638, -8.9856, -9.0228, -8.8820, -9.0845, -8.9616, -9.0851, -8.9832,\n",
            "        -9.0181, -9.0130, -9.0639, -8.9858, -9.0401, -8.9742, -8.9267, -8.9094,\n",
            "        -8.8923, -8.6742, -8.9074, -9.0945, -9.0793, -9.4479, -9.2250, -9.2166,\n",
            "        -9.1602, -9.0358, -9.1582, -9.1289, -9.0781, -9.1135, -9.2366, -9.2321,\n",
            "        -9.1412, -9.1582, -9.1863, -8.9890, -9.2626, -9.0961, -9.1579, -8.8415,\n",
            "        -9.0162, -8.7910, -9.3079, -9.1733, -9.1046, -9.1332, -9.0173, -8.5618,\n",
            "        -8.8542, -8.9841, -8.9125, -8.9011, -9.0733, -9.0514, -9.1432, -9.0794,\n",
            "        -9.0778, -8.8764, -8.8948, -8.5245, -8.4743, -8.5655, -8.3569, -8.5822,\n",
            "        -9.1911, -8.8512, -8.9809, -8.9594, -8.8353, -9.0260, -9.0782, -8.8665,\n",
            "        -9.0202, -8.9739, -9.2708, -9.0381, -8.8856, -9.0748, -8.9559, -9.1247,\n",
            "        -9.0186, -8.9165, -9.0923, -9.0562, -8.9497, -9.0850, -9.1054, -9.1494,\n",
            "        -8.8471, -9.1424, -8.8733, -8.7796, -8.5649, -8.5918, -8.8179, -8.4737,\n",
            "        -8.9277, -8.6935, -9.2445, -8.9636, -9.0883, -9.3136, -8.9651, -8.7509,\n",
            "        -9.2298, -8.8913, -8.9373, -9.2104, -8.8579, -8.8616, -9.3409, -8.6797,\n",
            "        -8.9053, -8.4661, -8.8820, -8.6721, -9.0582, -9.0212, -9.0427, -8.9021,\n",
            "        -8.5963, -9.0518, -8.4700, -8.4638, -7.6389, -2.5409, -7.4745,  8.7354,\n",
            "        -7.3362, -8.3456, -8.5907, -8.7796, -8.9775, -9.1960, -8.7457, -9.2203,\n",
            "        -7.4328, -8.8821, -8.5063, -8.8245, -8.5683, -9.1143, -9.0264, -8.9343,\n",
            "        -8.2458, -8.7691, -8.3969, -8.9049, -8.4276, -9.1083, -8.9885, -8.9415,\n",
            "        -9.0370, -9.0773, -8.8667, -9.3292, -8.9393, -9.1385, -8.9512, -9.4343,\n",
            "        -8.6523, -8.3158, -8.9729, -8.7803, -8.6785, -8.9609, -8.8016, -9.2015,\n",
            "        -8.8717, -8.6573, -8.3121, -8.0960, -8.9975, -9.2219, -8.8076, -8.7478,\n",
            "        -8.7514, -9.1472, -8.9532, -8.7892, -8.9223, -9.0389, -9.2509, -9.3929,\n",
            "        -9.0437, -9.3305, -8.9891, -9.2930, -8.9297, -8.7868, -8.7774, -8.7643,\n",
            "        -8.5891, -8.6585, -8.4263, -8.7366, -8.9672, -8.5190, -8.2620, -8.7546,\n",
            "        -8.9669, -8.9025, -9.4308, -9.1275, -9.1302, -9.0339, -9.1810, -9.1843,\n",
            "        -9.2388, -8.8894, -8.9250, -9.2474, -9.2305, -9.1470, -9.1229, -8.9651,\n",
            "        -9.1501, -9.1412, -9.2305, -9.0463, -9.1286, -8.6384, -8.8804, -8.7903,\n",
            "        -9.1101, -8.6900, -8.7631, -8.7427, -9.0398, -9.2635, -8.9440, -9.1842,\n",
            "        -9.0662, -8.9718, -8.9338, -9.0091, -8.9591, -9.0549, -9.1316, -9.1667,\n",
            "        -9.0109, -9.1859, -9.1019, -9.1844, -9.0581, -9.1104, -8.9541, -9.0482,\n",
            "        -9.2600, -8.9703, -8.9380, -8.8542, -8.8975, -8.5096, -8.5466, -8.8101,\n",
            "        -9.0109, -8.8782, -8.9198, -8.9054, -8.7746, -9.0168, -9.1327, -9.1041,\n",
            "        -9.0904, -9.1576, -9.0507, -9.2085, -9.2615, -8.8034, -9.1337, -9.1125,\n",
            "        -9.0794, -9.2301, -9.0422, -9.0888, -8.9141, -8.8216, -9.0831, -8.9706,\n",
            "        -8.5239, -9.0539, -9.0300, -8.9156, -8.5332, -9.0075, -8.8532, -9.0214],\n",
            "       device='cuda:0') tensor([ -7.9027,  -9.4027,  -9.4935,  -9.4218,  -9.3083,  -9.6417,  -9.5857,\n",
            "         -9.7434,  -9.4334,  -9.7847,  -9.7369,  -9.1365,  -9.3670,  -9.3458,\n",
            "         -9.4279,  -9.5258,  -9.4261,  -9.4979,  -9.5589,  -9.5002,  -9.9726,\n",
            "         -9.4470,  -9.1313,  -9.4658,  -9.5600,  -9.4052,  -9.4056,  -9.2036,\n",
            "         -9.4717,  -9.7848,  -9.9818,  -9.8445,  -9.6099,  -9.5387,  -9.7132,\n",
            "         -9.7971,  -9.7303,  -9.6508,  -9.5562,  -9.3264,  -9.4991,  -9.3914,\n",
            "         -9.4906,  -9.5450,  -9.8741,  -9.5238,  -9.7657,  -9.5129,  -9.6675,\n",
            "         -9.9971,  -9.7763,  -9.8305,  -9.8423,  -9.6792,  -9.4171,  -9.4030,\n",
            "         -9.5279,  -9.5217,  -9.2555, -10.1092,  -9.5553,  -9.4490,  -9.7547,\n",
            "         -9.5779,  -9.5855,  -9.1530,  -9.5495,  -9.4249,  -9.4954,  -9.2011,\n",
            "         -9.5868,  -9.4586,  -9.7720,  -9.4784,  -9.3862,  -9.4152,  -9.5191,\n",
            "         -9.4085,  -9.4947,  -9.4753,  -9.5087,  -9.6538,  -9.4893,  -9.5872,\n",
            "         -9.6679,  -9.8016,  -9.6309,  -9.6649,  -9.5993,  -9.4697,  -9.9332,\n",
            "         -9.9944,  -9.4982,  -9.6589, -10.0433,  -9.9267,  -9.6474,  -9.5191,\n",
            "         -9.5602,  -9.4365,  -9.5522,  -9.7511,  -9.7590,  -9.7599,  -9.7201,\n",
            "         -9.6448,  -9.6421,  -9.5348,  -9.7120,  -9.8222,  -9.5469,  -9.7303,\n",
            "         -9.9031,  -9.5804,  -9.4444,  -9.5996,  -9.6591,  -9.5344,  -9.5422,\n",
            "         -9.6053,  -9.7283,  -9.5441,  -9.5594,  -9.6345,  -9.7714,  -9.5254,\n",
            "         -9.3930,  -9.3297,  -9.7410,  -9.8038,  -9.8839,  -9.8499,  -9.7775,\n",
            "         -9.6162,  -9.7223,  -9.6705,  -9.6666,  -9.5108,  -9.6101,  -9.6671,\n",
            "         -9.7071,  -9.8400,  -9.5033,  -9.9588, -10.0244,  -9.8301,  -9.8206,\n",
            "         -9.6242,  -9.8240,  -9.8124,  -9.4874,  -9.7980,  -9.5199,  -9.7412,\n",
            "         -9.5669,  -9.7879, -10.0193,  -9.8769,  -9.8769,  -9.9399,  -9.7726,\n",
            "         -9.9924,  -9.7476,  -9.7154,  -9.3711,  -8.4774,  -9.5493,  -9.6663,\n",
            "         -9.7529,  -9.5673,  -9.7007,  -9.9291,  -9.8513,  -9.8057,  -9.7649,\n",
            "         -9.8440,  -9.8806,  -9.8831,  -9.7683,  -9.9103,  -9.8024,  -9.6804,\n",
            "         -9.7002,  -9.7127,  -9.7592,  -9.8371,  -9.8918,  -9.6635,  -9.6226,\n",
            "         -9.7303,  -9.7660,  -9.8510,  -9.6869,  -9.6060,  -9.8419,  -9.8331,\n",
            "         -9.6485,  -9.8453,  -9.8696,  -9.8224,  -9.8723,  -9.7308,  -9.8344,\n",
            "         -9.8480,  -9.7863,  -9.9312,  -9.7794,  -9.6281,  -9.7039,  -9.6324,\n",
            "         -9.8531,  -9.7883,  -9.9265,  -9.7954,  -9.7840,  -9.7828,  -9.6420,\n",
            "         -9.7034,  -9.4737,  -9.6767,  -9.5647,  -9.7245,  -9.7125,  -9.8191,\n",
            "         -9.5167,  -9.7338,  -9.6072,  -9.7876,  -9.7342,  -9.7994,  -9.6711,\n",
            "         -9.7217,  -9.6377,  -9.7675,  -9.7206,  -9.8198,  -9.6471,  -9.8112,\n",
            "         -9.6628,  -9.7536,  -9.8322,  -9.7843,  -9.6568,  -9.7926,  -9.7238,\n",
            "         -9.6213,  -9.7959,  -9.5434,  -9.7087,  -9.7650,  -9.7260,  -9.6743,\n",
            "         -9.8812,  -9.7326,  -9.7494,  -9.7527,  -9.8649,  -9.8158,  -9.8577,\n",
            "        -10.0397,  -9.8150,  -9.7325,  -9.6266,  -9.8327,  -9.7614, -10.0769,\n",
            "         -9.6402,  -9.7239,  -9.6351,  -9.5555,  -9.8909,  -9.7704,  -9.8642,\n",
            "         -9.8404,  -9.8627,  -9.9302,  -9.7739,  -9.8316,  -9.7982,  -9.8000,\n",
            "         -9.5903,  -9.6433,  -9.6488,  -9.6849,  -9.5280,  -9.7665, -10.1983,\n",
            "         -9.7845,  -9.5012,  -9.7404,  -9.4587,  -9.4674,  -9.7130,  -9.5891,\n",
            "         -9.7342,  -9.7601,  -9.5209,  -9.6193,  -9.4784,  -9.6889,  -9.7149,\n",
            "         -9.6182,  -9.8207,  -9.8001,  -9.8396,  -9.8931,  -9.8548,  -9.8040,\n",
            "         -9.7595,  -9.6520,  -9.3251,  -9.4861,  -9.6555,  -9.5691,  -9.8516,\n",
            "         -9.7614,  -9.3943,  -9.4541,  -9.6697,  -9.4449,  -9.4526,  -9.4383,\n",
            "         -9.2665,  -9.5715,  -9.2053,  -8.8997,  -9.7552,  -9.7813,  -9.5525,\n",
            "         -9.6015,  -9.6081,  -9.2682,  -9.4302,  -8.6858,  -8.2479,  -9.5824,\n",
            "         -9.7152,  -9.8166,  -9.6789,  -9.7971,  -9.8075,  -9.8684,  -9.8353,\n",
            "         -9.6108,  -9.4546,  -9.1561,  -8.9795,  -7.9680,  -5.0497,   8.7059,\n",
            "         -9.1502,  -2.4040,  -8.5644,  -9.4760,  -9.7820,  -9.2913,  -9.1820,\n",
            "         -8.9995,  -9.1419,  -7.1150,  -9.3832,  -9.6666,  -9.6686,  -9.5903,\n",
            "         -9.4937,  -9.6373,  -9.6053,  -9.3254,  -9.3090,  -9.8668,  -9.6942,\n",
            "         -9.6112,  -9.7526,  -9.4435,  -9.3590,  -9.3105,  -9.6311,  -9.7456,\n",
            "         -9.8313,  -9.3918,  -9.8067,  -9.4707,  -9.6170,  -6.6101,  -9.8373,\n",
            "         -9.8323,  -9.6490,  -9.8379,  -9.5566,  -9.7817,  -9.8467,  -9.6244,\n",
            "         -9.5293,  -5.8744,  -9.3037,  -9.6906,  -9.7609,  -9.7347,  -9.6700,\n",
            "         -9.2635,  -9.4545,  -9.6624,  -9.8666,  -9.9343,  -9.9433,  -9.8098,\n",
            "         -9.6548,  -9.6827,  -9.8565,  -9.7013,  -9.8965,  -9.6105,  -9.8201,\n",
            "         -9.3569,  -6.1343,  -9.4424,  -9.1571,  -9.2512,  -9.2313,  -9.5912,\n",
            "         -9.5280,  -9.5683,  -9.7589,  -9.6164,  -9.6715,  -9.8836,  -9.5946,\n",
            "         -9.7417,  -9.8845,  -9.8797,  -9.7737,  -9.7241,  -9.4028,  -9.6536,\n",
            "         -9.8959,  -9.7345,  -9.7838,  -9.8558,  -9.4156,  -9.5761,  -9.5726,\n",
            "         -9.4770,  -9.5589,  -9.7338,  -9.3432,  -9.0965,  -9.3845,  -9.3516,\n",
            "         -9.3742,  -9.4823,  -9.4237,  -9.5118,  -9.4940,  -9.5391,  -9.7514,\n",
            "         -9.4751,  -9.5662,  -9.4626,  -9.4409,  -9.5584,  -9.4147,  -9.5893,\n",
            "         -9.6019,  -9.5204,  -9.6914,  -9.4494,  -9.6353,  -9.5215,  -9.6349,\n",
            "         -9.4985,  -9.5470,  -9.4511,  -9.4523,  -9.7392,  -9.6815,  -9.4425,\n",
            "         -9.5587,  -9.9458,  -9.2111,  -9.8636,  -9.6578,  -9.8293,  -9.7507,\n",
            "         -9.3264,  -9.3569,  -9.4556,  -9.4828,  -9.6155,  -9.6031,  -9.4462,\n",
            "         -9.5421,  -9.3079,  -9.2377,  -9.4645,  -9.4521,  -9.5484,  -9.5547,\n",
            "         -9.3999,  -9.5699,  -9.4537,  -9.3965,  -9.4039,  -9.5733,  -9.6949,\n",
            "         -9.3404,  -9.5520,  -9.3355,  -9.6361,  -9.2818,  -9.7621,  -9.8011,\n",
            "         -9.2433], device='cuda:0')\n",
            "------2------\n",
            "torch.Size([512])\n",
            "% ) 등 곡물류는 15년 후에 관세를 없앨 계획이다. 최경림 산업통상자원부 통상차관보는 [UNK] 한국은 수출 주력 제품의 북미시장 점유율을 높일 수 있고, 캐나다는 미국 [UNK] eu와 fta를 체결한 한국을 아시아 진출의 교두보로 삼을 수 있다는 점에서 상호 접점을 찾았다 [UNK] 고 설명했다. 한국은 캐나다와 [UNK] fta 동맹 [UNK] 으로 묶이면서 세계 최대 다자간 fta인 환태\n",
            "tensor([ 7.9598, -7.3163, -6.2917, -6.6681, -8.8282, -8.5819, -8.6846, -8.3036,\n",
            "        -8.9489, -8.5512, -7.7957, -8.7962, -8.1616, -8.4459, -8.0644, -7.6361,\n",
            "        -8.9147, -8.3848, -8.2632, -8.4023, -8.4636, -8.8903, -8.7765, -8.9939,\n",
            "        -8.6851, -8.8836, -9.0013, -8.7915, -8.9043, -8.9655, -8.6512, -8.9181,\n",
            "        -8.9715, -8.8047, -8.8811, -8.7122, -8.4917, -7.9644, -8.4011, -8.2907,\n",
            "        -8.0829, -8.5323, -7.7777, -8.8612, -8.6786, -8.0863, -7.9563, -8.7397,\n",
            "        -8.5442, -8.9539, -9.0178, -8.8932, -8.8483, -8.9126, -9.0271, -8.8431,\n",
            "        -8.6545, -9.0191, -9.1039, -8.9080, -8.9441, -8.9670, -8.8819, -8.9382,\n",
            "        -8.6242, -8.2975, -7.8364, -8.5194, -8.2891, -8.6270, -8.0773, -8.9925,\n",
            "        -8.6850, -8.6571, -8.1815, -9.0272, -8.5968, -8.5607, -8.2359, -7.1336,\n",
            "        -7.7643, -8.5801, -8.0943, -8.2785, -8.7332, -8.7992, -8.8321, -8.5616,\n",
            "        -8.7793, -8.6881, -8.7832, -8.9674, -8.8292, -8.9572, -8.8830, -9.0923,\n",
            "        -9.0824, -9.1976, -8.9630, -8.9091, -8.6821, -8.9031, -9.0856, -8.9300,\n",
            "        -8.8260, -8.9547, -8.7930, -9.1587, -9.0836, -8.8273, -8.8749, -9.0210,\n",
            "        -8.9312, -9.2055, -8.9484, -8.8469, -8.9538, -8.9630, -9.0195, -9.0914,\n",
            "        -9.0234, -8.9042, -9.0740, -9.0338, -9.1552, -9.0338, -9.1342, -9.1355,\n",
            "        -8.8384, -8.5408, -8.7417, -8.8549, -9.0668, -8.9428, -8.9277, -9.0500,\n",
            "        -9.0669, -9.0652, -9.1045, -8.9462, -8.8020, -8.7619, -8.6497, -8.7326,\n",
            "        -8.7887, -8.8361, -8.9206, -8.4292, -8.7564, -8.8060, -8.6633, -8.7596,\n",
            "        -8.8343, -8.7503, -8.9886, -9.0494, -8.7967, -8.7317, -9.0717, -9.1121,\n",
            "        -8.8719, -9.1197, -8.9606, -8.8603, -8.4764, -8.6569, -8.5367, -8.7679,\n",
            "        -8.7581, -8.8477, -8.7523, -8.9036, -8.7014, -8.8107, -8.6905, -8.7480,\n",
            "        -8.8876, -8.7416, -8.8100, -8.8548, -8.8391, -8.8416, -8.8799, -8.9520,\n",
            "        -8.7903, -8.9667, -8.9964, -8.8906, -8.7761, -9.0552, -8.8913, -9.0070,\n",
            "        -8.8807, -8.6690, -8.7798, -8.8158, -8.7660, -8.7213, -8.8181, -8.7732,\n",
            "        -9.0895, -8.7839, -8.7529, -8.7891, -8.6907, -9.0616, -8.9859, -8.7621,\n",
            "        -8.9414, -8.7695, -8.8472, -8.5992, -9.1067, -8.8443, -9.0849, -9.1028,\n",
            "        -8.9886, -8.8640, -8.9835, -8.8553, -8.9671, -8.9986, -8.7207, -8.9010,\n",
            "        -8.7298, -8.8961, -8.7687, -8.8256, -9.1350, -8.6995, -8.9016, -8.7275,\n",
            "        -8.7892, -9.0662, -9.0625, -8.8234, -8.4107, -8.9390, -8.9454, -8.6177,\n",
            "        -8.7438, -8.4696, -9.2310, -9.2868, -9.2975, -9.2766, -9.2773, -9.2879,\n",
            "        -9.2812, -9.2609, -9.3068, -9.2813, -9.2860, -9.2786, -9.2689, -9.3333,\n",
            "        -9.3352, -9.3200, -9.2801, -9.2829, -9.2570, -9.2646, -9.2400, -9.2435,\n",
            "        -9.2664, -9.2507, -9.2571, -9.2449, -9.2456, -9.2456, -9.2236, -9.2424,\n",
            "        -9.2299, -9.2187, -9.2553, -9.2775, -9.2740, -9.3004, -9.2900, -9.2852,\n",
            "        -9.3204, -9.3206, -9.3199, -9.3068, -9.2844, -9.2983, -9.2577, -9.2852,\n",
            "        -9.2648, -9.2842, -9.2643, -9.2368, -9.2776, -9.2542, -9.2425, -9.2330,\n",
            "        -9.2255, -9.1866, -9.2184, -9.2074, -9.2381, -9.2117, -9.1788, -9.2146,\n",
            "        -9.2537, -9.2261, -9.2557, -9.2704, -9.2826, -9.2432, -9.2631, -9.2712,\n",
            "        -9.2767, -9.2674, -9.3074, -9.3034, -9.2951, -9.2965, -9.3230, -9.2887,\n",
            "        -9.2747, -9.2583, -9.2745, -9.2443, -9.2360, -9.2651, -9.2438, -9.2347,\n",
            "        -9.2553, -9.2604, -9.2519, -9.2595, -9.2573, -9.2451, -9.2217, -9.2390,\n",
            "        -9.2510, -9.2527, -9.2496, -9.2466, -9.2706, -9.3002, -9.3217, -9.3264,\n",
            "        -9.2951, -9.2977, -9.3010, -9.2985, -9.3026, -9.3036, -9.3099, -9.3230,\n",
            "        -9.2999, -9.3049, -9.2992, -9.3154, -9.3087, -9.2404, -9.2229, -9.2755,\n",
            "        -9.2543, -9.2454, -9.2481, -9.2493, -9.2515, -9.2540, -9.2799, -9.2744,\n",
            "        -9.2867, -9.2857, -9.2874, -9.2968, -9.2980, -9.3039, -9.2785, -9.3153,\n",
            "        -9.2836, -9.2937, -9.3039, -9.3199, -9.3265, -9.2831, -9.2564, -9.3025,\n",
            "        -9.2711, -9.2650, -9.2433, -9.2511, -9.2530, -9.2694, -9.2370, -9.2579,\n",
            "        -9.2527, -9.2688, -9.2734, -9.2705, -9.2531, -9.2652, -9.2526, -9.2169,\n",
            "        -9.2467, -9.2900, -9.3138, -9.3101, -9.3064, -9.2268, -9.2687, -9.2935,\n",
            "        -9.3363, -9.3173, -9.3096, -9.3007, -9.2608, -9.2654, -9.2654, -9.3127,\n",
            "        -9.2871, -9.3031, -9.2796, -9.2797, -9.2719, -9.2848, -9.2705, -9.2511,\n",
            "        -9.2390, -9.2830, -9.2846, -9.2742, -9.2758, -9.3021, -9.3034, -9.3382,\n",
            "        -9.3331, -9.3262, -9.3232, -9.3259, -9.3113, -9.3038, -9.3022, -9.3012,\n",
            "        -9.2607, -9.2986, -9.2849, -9.2850, -9.2846, -9.2723, -9.2751, -9.2762,\n",
            "        -9.2592, -9.2550, -9.2655, -9.2551, -9.2526, -9.2085, -9.2436, -9.2555,\n",
            "        -9.2968, -9.2747, -9.2843, -9.3006, -9.2889, -9.2876, -9.3100, -9.3012,\n",
            "        -9.3140, -9.3092, -9.3289, -9.3422, -9.3632, -9.3396, -9.3458, -9.3383,\n",
            "        -9.3130, -9.3043, -9.3166, -9.3220, -9.3326, -9.2816, -9.2862, -9.2769,\n",
            "        -9.3125, -9.3290, -9.3051, -9.3006, -9.3231, -9.3222, -9.3406, -9.3614,\n",
            "        -9.3552, -9.3264, -9.3393, -9.3366, -9.3360, -9.3567, -9.3552, -9.3565,\n",
            "        -9.3637, -9.3428, -9.3456, -9.3387, -9.3378, -9.3198, -9.3022, -9.2939,\n",
            "        -9.2967, -9.3058, -9.2946, -9.2807, -9.2214, -9.1752, -9.1876, -8.4653],\n",
            "       device='cuda:0') tensor([  7.8584,  -8.1732,  -7.0044,  -7.7107,  -8.9465,  -9.1298,  -9.1751,\n",
            "         -8.7191,  -8.9858,  -9.3930,  -8.7016,  -8.3230,  -8.3088,  -8.4191,\n",
            "         -8.2448,  -7.7099,  -9.0252,  -9.0703,  -8.3783,  -8.9419,  -9.5651,\n",
            "         -9.5465,  -9.6399,  -9.4771,  -9.2964,  -9.4024,  -9.2490,  -9.3378,\n",
            "         -9.1138,  -8.8268,  -9.3628,  -9.5829,  -9.3843,  -9.4910,  -9.4176,\n",
            "         -9.2688,  -8.8987,  -9.2441,  -8.9301,  -8.9625,  -9.0494,  -9.3755,\n",
            "         -8.8852,  -8.9761,  -9.1498,  -7.7234,  -7.9981,  -9.1499,  -9.4786,\n",
            "         -9.3137,  -9.5643,  -9.5329,  -9.4002,  -9.1937,  -8.7970,  -9.3847,\n",
            "         -9.6909,  -9.4472,  -9.5081,  -9.7045,  -9.6805,  -9.4274,  -9.6305,\n",
            "         -9.4437,  -9.2015,  -8.7899,  -8.9037,  -8.9990,  -9.3823,  -9.3536,\n",
            "         -9.1334,  -9.3177,  -9.2891,  -8.5781,  -8.8763,  -9.3298,  -9.6964,\n",
            "         -9.0871,  -9.5402,  -9.7281,  -9.0663,  -8.9399,  -9.4201,  -9.6594,\n",
            "         -9.4076,  -9.4644,  -9.3766,  -9.2214,  -9.8838,  -9.9176,  -9.8147,\n",
            "         -9.6106, -10.0342,  -9.7793,  -9.9574,  -9.5997,  -9.6360,  -9.3508,\n",
            "         -9.0435,  -9.3019,  -9.6194,  -9.7674,  -9.5814,  -9.6599,  -9.9393,\n",
            "         -9.7658, -10.0175,  -9.5679,  -9.6641,  -9.5634,  -9.6267,  -9.9240,\n",
            "         -9.9568,  -9.6518,  -9.7418,  -9.7486,  -9.6037,  -9.7818,  -9.7094,\n",
            "         -9.5914,  -9.6455,  -9.7329,  -9.7876,  -9.7208,  -9.1893,  -9.4580,\n",
            "         -9.0682,  -9.3364,  -9.2620,  -9.3000,  -9.6194,  -9.7247,  -9.2893,\n",
            "         -9.8206,  -9.8680,  -9.6577,  -9.4965,  -9.4834,  -9.4968,  -9.7481,\n",
            "         -9.9785,  -9.8918,  -9.9082,  -9.8200,  -9.8415,  -9.8045,  -9.7607,\n",
            "        -10.0020,  -9.5853,  -9.3465,  -9.8145,  -9.7609,  -9.6172,  -9.6109,\n",
            "         -9.4903,  -9.4180,  -9.5753,  -9.7100,  -9.6474,  -9.7758,  -9.7934,\n",
            "         -9.6415,  -9.6495,  -9.3573,  -5.9654,  -9.6158,  -9.7166,  -9.7835,\n",
            "         -9.8792,  -9.8172,  -9.8776,  -9.7148,  -9.9171,  -9.7822,  -9.8969,\n",
            "         -9.9283,  -9.7884,  -9.9497,  -9.9029,  -9.8767,  -9.8902,  -9.8702,\n",
            "         -9.8420,  -9.8011,  -9.9005,  -9.7457,  -9.8205,  -9.7634,  -9.9220,\n",
            "         -9.8356,  -9.8161,  -9.4934,  -9.3911,  -9.6125,  -9.5196,  -9.8418,\n",
            "         -9.8428,  -9.9656,  -9.9291, -10.0094,  -9.6395,  -9.7767,  -9.6843,\n",
            "         -9.9042, -10.1082,  -9.5571,  -9.5176,  -9.4638,  -9.3404,  -9.5947,\n",
            "         -9.6276,  -9.8404,  -9.7065,  -9.9912,  -9.7758,  -9.7012,  -9.7152,\n",
            "         -9.6919,  -9.8140,  -9.8750,  -9.9091,  -9.8406,  -9.7853,  -9.6837,\n",
            "         -9.9643,  -9.7600,  -9.8490,  -9.8817,  -9.3225,  -9.5533,  -9.3878,\n",
            "         -9.7703,  -9.7974,  -9.4007,  -9.4831,  -9.8519,  -9.9165,  -9.6944,\n",
            "         -9.2195,  -9.6325,  -9.5966,  -9.3286,  -9.8932,  -9.9331,  -9.9276,\n",
            "         -9.9311,  -9.9281,  -9.9528,  -9.9466,  -9.9699,  -9.9278,  -9.9338,\n",
            "         -9.9490,  -9.9454,  -9.9669,  -9.8691,  -9.8663,  -9.8447,  -9.8709,\n",
            "         -9.8789,  -9.8959,  -9.8845,  -9.9103,  -9.8630,  -9.8811,  -9.9266,\n",
            "         -9.9014,  -9.8971,  -9.8612,  -9.8695,  -9.9254,  -9.8755,  -9.8822,\n",
            "         -9.8972,  -9.8855,  -9.8906,  -9.8968,  -9.8774,  -9.8550,  -9.8690,\n",
            "         -9.8120,  -9.8335,  -9.8295,  -9.8205,  -9.7996,  -9.8182,  -9.8801,\n",
            "         -9.8305,  -9.8497,  -9.7777,  -9.8254,  -9.8104,  -9.7874,  -9.8553,\n",
            "         -9.8332,  -9.8146,  -9.8219,  -9.8779,  -9.8872,  -9.8680,  -9.8260,\n",
            "         -9.8596,  -9.8707,  -9.8869,  -9.8446,  -9.9049,  -9.8396,  -9.8078,\n",
            "         -9.8410,  -9.9350,  -9.9281,  -9.9309,  -9.9145,  -9.9083,  -9.8603,\n",
            "         -9.8831,  -9.8910,  -9.8914,  -9.8710,  -9.8788,  -9.8683,  -9.9063,\n",
            "         -9.7732,  -9.8567,  -9.9126,  -9.8133,  -9.8672,  -9.9054,  -9.8810,\n",
            "         -9.9116,  -9.9092,  -9.8965,  -9.8923,  -9.8968,  -9.9162,  -9.9052,\n",
            "         -9.8815,  -9.8992,  -9.9176,  -9.9170,  -9.9073,  -9.9100,  -9.8790,\n",
            "         -9.8695,  -9.8988,  -9.8366,  -9.8383,  -9.8672,  -9.8935,  -9.8838,\n",
            "         -9.7964,  -9.8177,  -9.8290,  -9.7937,  -9.8527,  -9.8362,  -9.7969,\n",
            "         -9.8571,  -9.8874,  -9.8467,  -9.8665,  -9.8786,  -9.8454,  -9.8258,\n",
            "         -9.8508,  -9.8586,  -9.8431,  -9.8427,  -9.7586,  -9.8107,  -9.7886,\n",
            "         -9.7895,  -9.8567,  -9.8451,  -9.8542,  -9.8100,  -9.8206,  -9.8702,\n",
            "         -9.8635,  -9.8339,  -9.8024,  -9.8635,  -9.8776,  -9.7750,  -9.8401,\n",
            "         -9.8605,  -9.8531,  -9.8691,  -9.8394,  -9.8699,  -9.9444,  -9.9006,\n",
            "         -9.8923,  -9.8734,  -9.8686,  -9.8970,  -9.9144,  -9.9003,  -9.9103,\n",
            "         -9.9611,  -9.9425,  -9.9106,  -9.9129,  -9.9199,  -9.9001,  -9.9678,\n",
            "         -9.9303,  -9.9208,  -9.9049,  -9.9118,  -9.9058,  -9.8971,  -9.9203,\n",
            "         -9.9114,  -9.9318,  -9.8578,  -9.8754,  -9.8538,  -9.8407,  -9.9017,\n",
            "         -9.9023,  -9.8497,  -9.8401,  -9.8794,  -9.8486,  -9.8571,  -9.8704,\n",
            "         -9.8711,  -9.8779,  -9.8560,  -9.8900,  -9.8543,  -9.8559,  -9.8273,\n",
            "         -9.7972,  -9.8317,  -9.8585,  -9.8700,  -9.8621,  -9.8471,  -9.9000,\n",
            "         -9.8028,  -9.7745,  -9.8645,  -9.8082,  -9.7528,  -9.7944,  -9.7909,\n",
            "         -9.7803,  -9.8735,  -9.8304,  -9.8287,  -9.8258,  -9.8762,  -9.8320,\n",
            "         -9.8515,  -9.8435,  -9.8530,  -9.8222,  -9.8340,  -9.8931,  -9.8815,\n",
            "         -9.8750,  -9.8921,  -9.8809,  -9.8723,  -9.8567,  -9.8618,  -9.8208,\n",
            "         -9.8578,  -9.8403,  -9.8220,  -9.8318,  -9.7898,  -9.8355,  -9.8274,\n",
            "         -9.7901,  -9.8349,  -9.8416,  -9.8440,  -9.8210,  -9.8030,  -9.8617,\n",
            "         -9.8561,  -9.8371,  -9.8350,  -9.8405,  -9.8367,  -9.8252,  -9.8227,\n",
            "         -9.7981,  -9.8250,  -9.8483,  -9.8351,  -9.8160,  -9.7707,  -9.7806,\n",
            "         -9.7141,  -9.7708,  -9.7807,  -9.7834,  -9.7694,  -9.7879,  -9.7882,\n",
            "         -9.8129,  -9.7845,  -9.8004,  -9.7933,  -9.7629,  -9.7381,  -9.7162,\n",
            "         -9.3325], device='cuda:0')\n",
            "------3------\n",
            "torch.Size([512])\n",
            "##부\n",
            "tensor([-8.7862, -9.1376, -8.8639, -9.0835, -9.0877, -8.9092, -8.9552, -9.0101,\n",
            "        -9.1008, -9.1618, -8.8600, -8.9531, -9.0273, -9.1971, -9.0022, -8.7882,\n",
            "        -9.0212, -7.9773, -6.9945, -7.6765, -8.0061, -8.5104, -8.3417, -9.0040,\n",
            "        -8.9882, -8.8768, -9.0778, -8.5686, -8.9068, -8.8985, -8.9986, -8.8658,\n",
            "        -8.6788, -8.8104, -8.8333, -8.6522, -9.1157, -8.7967, -9.1373, -8.9525,\n",
            "        -8.8061, -9.0731, -9.0944, -8.7253, -9.0189, -9.0103, -8.7438, -9.0426,\n",
            "        -8.9616, -9.0262, -8.7678, -8.9017, -8.7684, -9.0300, -8.7160, -8.7030,\n",
            "        -9.0129, -8.8354, -9.2432, -8.9665, -8.9103, -9.0639, -8.7670, -8.8268,\n",
            "        -7.7929, -8.7216, -9.1106, -8.7509, -9.1067, -8.9597, -8.8178, -9.0006,\n",
            "        -8.9825, -8.8479, -8.7802, -8.9771, -9.1031, -9.0443, -8.9071, -8.9331,\n",
            "        -9.0638, -8.8173, -8.7337, -8.8266, -9.0596, -8.7055, -8.9310, -8.7873,\n",
            "        -9.0643, -8.8866, -8.8975, -8.4591, -8.0765, -7.4796, -8.3430, -8.4261,\n",
            "        -8.8897, -8.6299, -8.8659, -8.5344, -9.1073, -8.7344, -9.1928, -9.0071,\n",
            "        -8.9921, -8.9318, -9.0320, -8.9375, -9.1788, -8.8728, -9.0844, -8.8337,\n",
            "        -8.9758, -8.9610, -8.6664, -9.0595, -8.7613, -8.7575, -9.0364, -8.9712,\n",
            "        -8.9550, -9.1006, -9.0961, -9.0999, -8.9788, -9.0294, -9.1631, -8.8789,\n",
            "        -8.8392, -9.0203, -8.9632, -9.0060, -8.9501, -8.8855, -8.5140, -8.6450,\n",
            "        -8.9525, -8.7463, -8.8941, -9.0102, -8.9957, -8.9985, -8.9942, -8.8248,\n",
            "        -8.6732, -9.0610, -9.0205, -9.1288, -9.0669, -9.0059, -8.8848, -8.8435,\n",
            "        -8.8991, -8.8584, -9.0405, -8.8775, -9.0311, -8.8401, -9.0627, -9.2599,\n",
            "        -9.0439, -9.0982, -9.1049, -9.1758, -9.0044, -9.0982, -8.8251, -9.0932,\n",
            "        -9.0666, -9.0825, -8.8302, -1.9040, -6.3504,  8.3723, -5.3731, -8.6644,\n",
            "        -8.1044, -8.4507, -8.9477, -8.4748, -8.7332, -8.8513, -9.0003, -8.9878,\n",
            "        -8.9455, -8.8238, -9.0992, -9.1197, -8.9171, -9.0033, -9.0948, -8.9495,\n",
            "        -9.0338, -9.0134, -8.9981, -9.0307, -8.8570, -8.8959, -8.6676, -8.7920,\n",
            "        -9.0437, -8.9166, -8.9204, -8.9819, -9.0069, -8.8530, -8.9694, -9.0290,\n",
            "        -9.0421, -9.0650, -9.1821, -9.1545, -8.9900, -9.1304, -8.9582, -8.9691,\n",
            "        -9.0577, -8.9775, -8.9689, -9.0934, -8.9710, -8.9797, -9.1110, -9.1605,\n",
            "        -9.0674, -9.1897, -9.0084, -8.8538, -8.9337, -8.7684, -8.9004, -8.9125,\n",
            "        -8.9881, -9.0429, -8.8900, -9.0412, -9.0443, -8.9675, -8.8813, -9.0278,\n",
            "        -8.8945, -8.9561, -8.9666, -9.0273, -8.8348, -8.8459, -8.9700, -9.0002,\n",
            "        -9.0599, -9.0264, -9.0008, -8.9417, -8.9102, -8.8993, -8.9964, -8.9846,\n",
            "        -8.8866, -8.9993, -8.9150, -8.8690, -9.0116, -8.8570, -8.8196, -8.9125,\n",
            "        -8.9406, -8.8023, -8.9994, -8.9220, -9.0299, -8.9315, -8.9692, -9.0682,\n",
            "        -9.0052, -8.9199, -8.8893, -8.8329, -8.9461, -8.9102, -8.8390, -9.0155,\n",
            "        -8.9252, -8.9230, -9.0730, -8.9208, -8.7648, -8.8900, -8.9364, -9.1787,\n",
            "        -9.0567, -8.9536, -9.2095, -8.9406, -8.9265, -8.8825, -9.1014, -8.8704,\n",
            "        -8.7578, -8.8792, -8.9053, -8.9697, -8.9211, -9.0443, -8.9850, -8.8522,\n",
            "        -8.9115, -8.6018, -8.8816, -9.2052, -8.8525, -8.9668, -9.0697, -8.9759,\n",
            "        -9.1510, -9.3132, -9.1397, -9.1293, -9.0651, -8.9383, -9.1407, -9.0257,\n",
            "        -8.9818, -8.8277, -9.0953, -8.7757, -9.1449, -9.1721, -9.1779, -9.1461,\n",
            "        -9.1663, -9.2027, -9.2072, -9.2127, -9.2162, -9.2138, -9.1895, -9.1890,\n",
            "        -9.2347, -9.2536, -9.2522, -9.2662, -9.2740, -9.2870, -9.3396, -9.3610,\n",
            "        -9.3433, -9.3635, -9.3834, -9.3429, -9.3574, -9.3822, -9.3776, -9.3813,\n",
            "        -9.3649, -9.3796, -9.3968, -9.3907, -9.3798, -9.3624, -9.3340, -9.3208,\n",
            "        -9.3321, -9.3183, -9.3316, -9.3171, -9.3244, -9.3396, -9.3516, -9.3535,\n",
            "        -9.3668, -9.3834, -9.4411, -9.3764, -9.3912, -9.3636, -9.4063, -9.4020,\n",
            "        -9.3937, -9.3802, -9.3853, -9.3661, -9.3621, -9.3612, -9.3568, -9.3123,\n",
            "        -9.3003, -9.3588, -9.3663, -9.3675, -9.3248, -9.3416, -9.3575, -9.3560,\n",
            "        -9.3622, -9.3658, -9.3615, -9.3537, -9.3492, -9.3639, -9.3694, -9.3482,\n",
            "        -9.3553, -9.3655, -9.3821, -9.4226, -9.3976, -9.4017, -9.4685, -9.4884,\n",
            "        -9.4772, -9.4508, -9.4119, -9.3933, -9.3642, -9.3552, -9.3862, -9.3670,\n",
            "        -9.3652, -9.3654, -9.3741, -9.3790, -9.3750, -9.3478, -9.3414, -9.2824,\n",
            "        -9.2690, -9.3373, -9.3633, -9.3713, -9.3710, -9.4141, -9.3797, -9.4699,\n",
            "        -9.4485, -9.4038, -9.4479, -9.4969, -9.4544, -9.4141, -9.3030, -9.4275,\n",
            "        -9.4202, -9.3862, -9.3830, -9.4013, -9.3766, -9.3517, -9.3473, -9.3030,\n",
            "        -9.2759, -9.2739, -9.2979, -9.3021, -9.2949, -9.2969, -9.3072, -9.3060,\n",
            "        -9.2962, -9.3114, -9.3289, -9.3618, -9.3594, -9.3437, -9.3642, -9.3498,\n",
            "        -9.3622, -9.3331, -9.3333, -9.3188, -9.3550, -9.3635, -9.3685, -9.3629,\n",
            "        -9.3578, -9.3205, -9.3118, -9.3319, -9.3373, -9.3168, -9.2789, -9.2886,\n",
            "        -9.3048, -9.3139, -9.3112, -9.3344, -9.3529, -9.3449, -9.3613, -9.4039,\n",
            "        -9.4298, -9.3992, -9.3947, -9.4064, -9.3603, -9.4197, -9.3983, -9.4101,\n",
            "        -9.4044, -9.3951, -9.4168, -9.4145, -9.3910, -9.3759, -9.3592, -9.3333,\n",
            "        -9.3245, -9.3283, -9.3272, -9.3183, -9.2945, -9.2428, -9.2903, -9.1490],\n",
            "       device='cuda:0') "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-8.4481, -9.1720, -9.4995, -9.1741, -9.1653, -9.3607, -9.3793, -9.2856,\n",
            "        -9.0141, -9.3446, -9.4085, -9.1273, -8.9229, -9.1583, -9.2211, -9.1161,\n",
            "        -8.8746, -7.3296, -7.4426, -7.7554, -8.2980, -8.7746, -9.1622, -8.7201,\n",
            "        -9.1904, -8.8396, -9.4880, -9.7095, -9.5067, -9.4281, -9.1845, -9.3680,\n",
            "        -9.3165, -9.1179, -8.5817, -8.6186, -8.8254, -9.3122, -8.7633, -9.1441,\n",
            "        -9.2365, -9.1134, -9.2996, -9.4202, -9.1986, -9.3918, -9.2870, -9.5147,\n",
            "        -9.5553, -9.3341, -9.4973, -9.5557, -9.4296, -9.3872, -9.6593, -9.4831,\n",
            "        -9.3915, -9.4843, -9.2856, -9.5371, -9.4979, -9.3859, -9.3644, -8.6142,\n",
            "        -8.9570, -9.0801, -9.2356, -9.4489, -9.4349, -9.4986, -9.3391, -9.1002,\n",
            "        -8.9560, -9.1847, -8.7388, -9.0117, -9.4287, -9.3447, -9.5550, -9.6508,\n",
            "        -9.3775, -9.5581, -9.5114, -9.3889, -9.2302, -9.4720, -9.4541, -9.5407,\n",
            "        -9.3546, -9.3297, -9.1066, -8.7028, -7.6901, -7.8781, -8.6913, -9.0133,\n",
            "        -9.1595, -9.1587, -9.3529, -9.1666, -8.9591, -9.3113, -9.2649, -9.2801,\n",
            "        -9.1731, -9.3347, -9.0171, -8.9315, -9.2719, -9.2298, -9.1613, -9.5447,\n",
            "        -9.1776, -8.9536, -9.0657, -8.4907, -9.2467, -9.2125, -9.2612, -9.3797,\n",
            "        -9.4255, -9.1807, -9.1840, -9.3223, -9.4618, -9.2937, -9.2541, -9.4193,\n",
            "        -9.2455, -9.1416, -9.2832, -9.0498, -8.6510, -9.0176, -9.4072, -9.4374,\n",
            "        -9.1605, -9.1500, -9.2366, -9.2837, -9.4085, -9.3049, -9.1307, -9.2303,\n",
            "        -9.4911, -9.2892, -9.3343, -9.2339, -9.2782, -9.1749, -9.4381, -9.5853,\n",
            "        -9.5474, -9.5622, -9.3590, -9.4027, -9.4771, -9.6166, -9.4526, -9.2996,\n",
            "        -9.3901, -9.3521, -9.3275, -9.3753, -9.5086, -9.4336, -9.5707, -9.3799,\n",
            "        -9.2664, -9.3416, -9.4435,  7.0704, -7.3272, -3.2722, -7.3542, -9.2859,\n",
            "        -9.4549, -9.0563, -8.9836, -8.8118, -8.3339, -9.1194, -8.9373, -8.9785,\n",
            "        -9.2385, -9.1319, -9.1270, -9.3399, -9.5586, -9.2391, -9.2673, -9.3532,\n",
            "        -9.3443, -9.2862, -9.1701, -9.1614, -9.3500, -9.5377, -9.5838, -9.5049,\n",
            "        -9.3889, -9.3966, -9.3402, -9.2323, -9.3967, -9.6557, -9.3511, -9.2582,\n",
            "        -9.4218, -9.3931, -9.3578, -9.4272, -9.5620, -9.3771, -9.4681, -9.3570,\n",
            "        -9.3298, -9.4292, -9.3507, -9.1071, -9.4613, -9.4699, -9.2049, -9.3728,\n",
            "        -9.3576, -9.2279, -9.3577, -9.1835, -9.3959, -9.4567, -9.1723, -9.2893,\n",
            "        -9.2113, -9.3162, -9.4569, -9.1833, -9.2672, -9.4494, -9.3365, -9.3304,\n",
            "        -9.4867, -9.4406, -9.2418, -9.3587, -9.4997, -9.4533, -9.4314, -9.2770,\n",
            "        -9.2229, -9.3270, -9.4309, -9.4076, -9.4226, -9.3924, -9.3016, -9.4525,\n",
            "        -9.3940, -9.2986, -9.2408, -9.1010, -9.2725, -9.2904, -9.4314, -9.3059,\n",
            "        -9.3272, -9.4308, -9.4339, -9.2126, -9.2648, -9.4588, -9.3107, -9.2295,\n",
            "        -9.4457, -9.4251, -9.3952, -9.4600, -9.3675, -9.5172, -9.4349, -9.3254,\n",
            "        -9.2926, -9.2812, -9.0447, -9.2461, -9.1753, -9.2963, -9.2239, -9.1298,\n",
            "        -9.2399, -9.0940, -8.9960, -9.0608, -9.2474, -9.1586, -8.9582, -9.2879,\n",
            "        -9.5101, -9.1148, -9.0993, -9.2249, -9.1255, -9.0132, -9.1350, -9.0989,\n",
            "        -8.9849, -9.1192, -9.3066, -9.3044, -9.3090, -9.2712, -9.2983, -9.2825,\n",
            "        -9.2471, -9.2147, -9.4185, -9.2002, -9.4862, -9.4289, -9.3568, -9.3649,\n",
            "        -9.5353, -9.4473, -9.2642, -9.4429, -8.6642, -9.2689, -9.3566, -9.3599,\n",
            "        -9.3754, -9.3721, -9.4122, -9.4116, -9.4309, -9.4384, -9.4678, -9.4350,\n",
            "        -9.4331, -9.4405, -9.4648, -9.4257, -9.4107, -9.4456, -9.4748, -9.4811,\n",
            "        -9.4733, -9.4978, -9.4088, -9.4733, -9.4940, -9.4696, -9.4796, -9.4791,\n",
            "        -9.4254, -9.3556, -9.3698, -9.4282, -9.4515, -9.4488, -9.4625, -9.4732,\n",
            "        -9.4918, -9.5165, -9.4808, -9.4548, -9.4519, -9.4786, -9.4980, -9.5111,\n",
            "        -9.4838, -9.4548, -9.3269, -9.4209, -9.4325, -9.4851, -9.4341, -9.4421,\n",
            "        -9.4209, -9.4361, -9.4232, -9.4053, -9.3966, -9.3944, -9.3915, -9.3799,\n",
            "        -9.3834, -9.4067, -9.4662, -9.4970, -9.5555, -9.5271, -9.5198, -9.5443,\n",
            "        -9.5432, -9.5462, -9.5747, -9.5768, -9.5753, -9.5494, -9.5658, -9.6083,\n",
            "        -9.6047, -9.6338, -9.6229, -9.5538, -9.5892, -9.5781, -9.5054, -9.4889,\n",
            "        -9.4764, -9.5341, -9.5833, -9.6040, -9.5984, -9.6272, -9.5947, -9.6105,\n",
            "        -9.5972, -9.6070, -9.5973, -9.5905, -9.5841, -9.5983, -9.5832, -9.6617,\n",
            "        -9.6782, -9.6007, -9.5801, -9.5797, -9.5649, -9.5208, -9.5161, -9.4391,\n",
            "        -9.4899, -9.5775, -9.5270, -9.4368, -9.4890, -9.5584, -9.6540, -9.4472,\n",
            "        -9.5130, -9.5422, -9.5440, -9.4855, -9.5506, -9.5757, -9.5730, -9.6408,\n",
            "        -9.6738, -9.6727, -9.5953, -9.6255, -9.6212, -9.6270, -9.6588, -9.6564,\n",
            "        -9.6769, -9.6535, -9.6454, -9.5832, -9.5557, -9.6043, -9.5716, -9.6090,\n",
            "        -9.5808, -9.6302, -9.5866, -9.6074, -9.5424, -9.5744, -9.6020, -9.5956,\n",
            "        -9.5719, -9.5718, -9.5698, -9.5638, -9.5772, -9.6028, -9.6406, -9.6371,\n",
            "        -9.6340, -9.6230, -9.6258, -9.5863, -9.5543, -9.5791, -9.5283, -9.5410,\n",
            "        -9.5038, -9.5654, -9.5627, -9.5202, -9.6051, -9.5395, -9.5572, -9.5409,\n",
            "        -9.5034, -9.4756, -9.3982, -9.4165, -9.4274, -9.4720, -9.4964, -9.5263,\n",
            "        -9.5356, -9.5104, -9.5406, -9.5590, -9.5388, -9.4835, -9.3030, -8.6597],\n",
            "       device='cuda:0')\n",
            "------4------\n",
            "torch.Size([512])\n",
            "날짜\n",
            "tensor([-7.5938, -9.0118, -8.8492, -8.9684, -9.1395, -9.1203, -8.9372, -9.2553,\n",
            "        -9.0704, -9.1177, -9.1233, -8.8285, -8.9748, -8.7751, -7.8109, -8.8235,\n",
            "        -8.0964, -8.8992, -8.4075, -8.5258, -8.5342, -8.7785, -8.6940,  7.8720,\n",
            "        -7.1164, -8.8095, -7.9985, -8.8272, -8.8805, -8.2961, -8.2367, -8.6509,\n",
            "        -8.8911, -9.0221, -8.7044, -9.1963, -9.0981, -9.0674, -8.7858, -9.0278,\n",
            "        -9.1785, -8.9325, -9.2942, -9.0701, -8.9886, -9.0951, -8.9290, -8.9268,\n",
            "        -8.9386, -9.0401, -9.0602, -9.0728, -8.8737, -8.8971, -8.8470, -8.8794,\n",
            "        -8.8905, -9.1147, -9.0469, -9.1532, -9.0236, -9.0798, -8.8111, -8.8305,\n",
            "        -9.1422, -8.9103, -9.3468, -9.1638, -9.2450, -9.0704, -8.8696, -8.8807,\n",
            "        -8.9012, -8.9231, -9.0901, -8.8890, -9.0631, -8.5786, -9.1444, -9.0397,\n",
            "        -8.9406, -8.9334, -8.9796, -8.4793, -9.0630, -8.8436, -9.0349, -9.1848,\n",
            "        -9.1277, -9.3138, -8.5065, -9.2013, -9.2516, -9.2715, -9.2627, -9.0848,\n",
            "        -8.8657, -9.2004, -9.1353, -9.2114, -9.1998, -9.1021, -9.1675, -8.7888,\n",
            "        -9.1114, -9.1222, -9.1085, -9.0141, -8.9555, -9.0723, -9.0882, -9.1449,\n",
            "        -9.0522, -9.0198, -8.8966, -9.1385, -8.9735, -9.1386, -9.0385, -9.0236,\n",
            "        -8.8189, -8.9101, -8.3973, -9.1517, -8.7733, -9.6778, -8.0889, -8.9778,\n",
            "        -8.9047, -9.0626, -8.7028, -8.9505, -8.7595, -9.2302, -9.2257, -9.2115,\n",
            "        -9.1321, -9.0048, -9.0298, -9.2584, -8.7094, -8.8122, -8.8959, -8.8292,\n",
            "        -8.8810, -8.9634, -9.0289, -8.9772, -9.0982, -8.8734, -9.1168, -8.8749,\n",
            "        -8.8358, -9.1732, -8.7740, -9.1180, -9.0098, -8.9876, -8.7900, -9.1139,\n",
            "        -9.0168, -9.0264, -8.8418, -9.0680, -9.0884, -8.9533, -8.8577, -9.0696,\n",
            "        -9.0216, -8.9983, -8.9701, -9.0878, -8.9873, -8.9971, -9.0576, -8.9044,\n",
            "        -8.9447, -8.9933, -8.9233, -9.1256, -8.9384, -8.9251, -8.9376, -8.9135,\n",
            "        -9.1123, -9.0195, -9.1033, -8.8454, -8.8941, -9.0698, -9.1255, -8.9729,\n",
            "        -9.1394, -8.9534, -8.9799, -9.1093, -8.9072, -8.8096, -8.9623, -9.0483,\n",
            "        -8.9203, -8.9205, -9.1461, -9.1795, -8.9426, -8.8148, -9.2242, -8.7845,\n",
            "        -8.9287, -9.0232, -8.8596, -8.9075, -9.0474, -9.0532, -8.8408, -9.0554,\n",
            "        -8.9064, -9.1755, -9.0761, -8.9497, -9.0817, -8.8932, -8.8890, -8.9009,\n",
            "        -8.8831, -9.0547, -8.9038, -9.1128, -9.1187, -8.9533, -8.8776, -8.8839,\n",
            "        -8.8599, -8.9727, -9.0298, -8.8672, -8.8408, -8.8243, -9.0097, -8.9658,\n",
            "        -8.9188, -9.0778, -9.0411, -8.9672, -8.9219, -9.0800, -8.9243, -9.0246,\n",
            "        -8.8560, -9.0290, -9.0921, -8.8638, -8.8301, -8.9391, -9.0477, -9.0315,\n",
            "        -8.9253, -9.0545, -9.0053, -8.9420, -8.9805, -9.0180, -9.0239, -8.9154,\n",
            "        -8.9742, -8.9090, -9.0275, -9.0744, -8.9087, -8.8131, -9.2149, -8.5239,\n",
            "        -8.5304, -9.0037, -8.6612, -9.0405, -8.9920, -9.1788, -9.1161, -9.1236,\n",
            "        -9.1666, -8.8035, -8.8658, -9.2332, -9.0674, -9.0624, -9.0116, -9.0928,\n",
            "        -9.1754, -9.0841, -9.0270, -9.1139, -8.9119, -9.2001, -9.1312, -8.9201,\n",
            "        -8.9973, -9.0781, -9.0114, -9.0904, -8.8375, -8.8379, -8.9492, -8.7111,\n",
            "        -8.8523, -8.8509, -8.5995, -8.8766, -9.0275, -8.5417, -9.0670, -9.0328,\n",
            "        -9.1009, -8.8564, -9.1446, -9.1781, -9.0043, -9.2414, -9.0418, -9.0411,\n",
            "        -8.9664, -9.0538, -8.6574, -9.1562, -9.0982, -9.0422, -8.9849, -8.6955,\n",
            "        -9.1172, -8.9966, -9.1122, -9.1713, -8.9616, -8.9391, -9.0595, -9.0249,\n",
            "        -9.0324, -9.0439, -8.7710, -9.1927, -8.8354, -8.8744, -8.6656, -8.6691,\n",
            "        -8.7968, -9.1762, -9.1743, -9.1988, -9.1831, -9.2051, -9.2035, -9.2209,\n",
            "        -9.2111, -9.2308, -9.2188, -9.2387, -9.2579, -9.2589, -9.2656, -9.2561,\n",
            "        -9.2386, -9.2344, -9.2256, -9.2522, -9.2406, -9.2464, -9.2770, -9.2400,\n",
            "        -9.2908, -9.3111, -9.2948, -9.3217, -9.3334, -9.3382, -9.3256, -9.3773,\n",
            "        -9.3939, -9.3985, -9.3869, -9.3900, -9.3966, -9.3941, -9.3903, -9.3577,\n",
            "        -9.3362, -9.3329, -9.3369, -9.3338, -9.3369, -9.3360, -9.3446, -9.3346,\n",
            "        -9.3357, -9.3551, -9.3541, -9.3443, -9.3420, -9.3263, -9.3283, -9.3414,\n",
            "        -9.3285, -9.3565, -9.3412, -9.3588, -9.4075, -9.4100, -9.3863, -9.4092,\n",
            "        -9.3896, -9.3969, -9.4014, -9.3863, -9.3638, -9.3681, -9.3957, -9.3523,\n",
            "        -9.3577, -9.3610, -9.3640, -9.3470, -9.3562, -9.3602, -9.3678, -9.3551,\n",
            "        -9.3615, -9.3348, -9.3523, -9.3894, -9.3881, -9.3891, -9.3839, -9.4035,\n",
            "        -9.4165, -9.4314, -9.4128, -9.4259, -9.4018, -9.3922, -9.4085, -9.4154,\n",
            "        -9.4142, -9.4172, -9.3884, -9.4219, -9.4174, -9.4054, -9.3845, -9.3615,\n",
            "        -9.3775, -9.3481, -9.3386, -9.3514, -9.3252, -9.3603, -9.3236, -9.3504,\n",
            "        -9.3980, -9.3342, -9.3914, -9.4047, -9.3712, -9.3611, -9.3849, -9.3874,\n",
            "        -9.3414, -9.4038, -9.4086, -9.3950, -9.3914, -9.3515, -9.3988, -9.4081,\n",
            "        -9.4116, -9.3764, -9.3446, -9.3499, -9.3486, -9.3535, -9.3407, -9.3412,\n",
            "        -9.3459, -9.3276, -9.3361, -9.3519, -9.3816, -9.3736, -9.3852, -9.3611,\n",
            "        -9.3968, -9.4271, -9.4041, -9.3965, -9.4082, -9.3864, -9.3998, -9.4116,\n",
            "        -9.4263, -9.3909, -9.3965, -9.4195, -9.3746, -9.3777, -9.3701, -9.3603,\n",
            "        -9.3311, -9.3681, -9.3467, -9.3410, -9.3292, -9.2576, -9.2735, -8.7968],\n",
            "       device='cuda:0') tensor([ -8.1822,  -9.6481,  -9.8239,  -9.7655,  -9.4911,  -9.3876,  -9.7817,\n",
            "         -9.6000,  -9.6666,  -9.5878,  -9.4784,  -9.4321,  -9.5140,  -9.6255,\n",
            "         -9.6251,  -9.0970,  -9.1991,  -9.6300,  -9.5976,  -9.1185,  -9.4495,\n",
            "         -8.8451,  -8.0018,   7.6929,  -7.5610,  -9.6043,  -9.5746,  -9.0635,\n",
            "         -9.5006,  -9.2294,  -9.4213,  -9.4028,  -9.0592,  -9.8410,  -9.9067,\n",
            "         -9.4920,  -9.6179,  -9.8353, -10.0333,  -9.6868,  -9.5746,  -9.7415,\n",
            "         -9.6119,  -9.7216,  -9.6241,  -9.6977,  -9.9168,  -9.8848,  -9.7946,\n",
            "         -9.6594,  -9.7219,  -9.6403,  -9.8299,  -9.8098,  -9.9021,  -9.9293,\n",
            "         -9.8238,  -9.7313,  -9.6817,  -9.7802,  -9.9475,  -9.6203,  -9.6163,\n",
            "         -9.5357,  -9.4026,  -9.6839,  -9.4188,  -9.6450,  -9.5420,  -9.6668,\n",
            "         -9.7252,  -9.8528,  -9.8829,  -9.7239,  -9.6747,  -9.6896,  -9.6936,\n",
            "         -9.9375,  -9.7813,  -9.6723,  -9.5161,  -9.3711,  -9.7945,  -9.9000,\n",
            "         -9.5509,  -9.7062,  -9.6086,  -9.6508,  -9.6634,  -9.4181,  -9.6951,\n",
            "         -9.5256,  -9.6793,  -9.7215,  -9.6298,  -9.7850, -10.0275,  -9.7338,\n",
            "         -9.7202,  -9.7572,  -9.5056,  -9.6030,  -9.6422,  -9.9568,  -9.7521,\n",
            "         -9.8237,  -9.8804,  -9.7072,  -9.7651,  -9.5820,  -9.8530,  -9.6874,\n",
            "         -9.8613,  -9.6879,  -9.7043,  -9.6815,  -9.7744,  -9.5778,  -9.6842,\n",
            "         -9.3896,  -6.2874,  -9.7616,  -9.7806,  -9.2647,  -9.2921,  -7.6696,\n",
            "         -9.6323,  -9.3951,  -9.3598,  -9.6836,  -9.8255,  -9.7030,  -9.7947,\n",
            "         -9.2937,  -9.5298,  -9.5089,  -9.7750,  -9.7041,  -9.5597,  -9.2543,\n",
            "         -9.6827,  -9.7508,  -9.7476,  -9.8928,  -9.8312,  -9.5930,  -9.7541,\n",
            "         -9.7789,  -9.8486,  -9.9001,  -9.8185,  -9.8220,  -9.8340,  -9.3594,\n",
            "         -9.6908,  -9.5280,  -9.5339,  -9.9255,  -9.9766,  -9.7509,  -9.8032,\n",
            "         -9.8483, -10.0671,  -9.7304,  -9.7181,  -9.9773,  -9.9473,  -9.7718,\n",
            "         -9.8644,  -9.8232,  -9.8266,  -9.6576,  -9.7276,  -9.7483,  -9.7553,\n",
            "         -9.8042,  -9.7282,  -9.8237,  -9.8821,  -9.7485,  -9.9100,  -9.9207,\n",
            "         -9.9877,  -9.8885,  -9.7818,  -9.7580,  -9.7977,  -9.9797,  -9.9762,\n",
            "         -9.7206,  -9.6017,  -9.8588,  -9.8494,  -9.8289,  -9.7248,  -9.5531,\n",
            "         -9.8508,  -9.9540,  -9.6974,  -9.7179,  -9.6962,  -9.8128,  -9.6164,\n",
            "         -9.6741,  -9.8887,  -9.9133,  -9.3407,  -9.6433,  -9.4660,  -9.7845,\n",
            "         -9.9157,  -9.9229,  -9.7347,  -9.6565,  -9.9133,  -9.7945,  -9.9267,\n",
            "         -9.6544,  -9.7524,  -9.9089,  -9.7225,  -9.9563,  -9.9022,  -9.9289,\n",
            "         -9.8602,  -9.8117,  -9.8423,  -9.6883,  -9.8201,  -9.8840,  -9.9590,\n",
            "         -9.7151,  -9.8313,  -9.8007,  -9.8025,  -9.9171, -10.0072,  -9.9664,\n",
            "         -9.7481,  -9.8792,  -9.8619,  -9.7639,  -9.8293,  -9.8710,  -9.9685,\n",
            "         -9.6966,  -9.8965,  -9.7788,  -9.9001,  -9.6611,  -9.7050,  -9.9644,\n",
            "        -10.0739,  -9.8911,  -9.7642,  -9.8790,  -9.7941,  -9.7525,  -9.8786,\n",
            "         -9.8908,  -9.7670,  -9.7327,  -9.7834,  -9.7923,  -9.7475,  -9.8759,\n",
            "         -9.7155,  -9.7620,  -9.5019,  -9.6012,  -9.1043,  -9.3907,  -9.1361,\n",
            "         -9.6956,  -9.7182,  -9.4454,  -9.5700,  -9.5400,  -9.6698,  -9.4624,\n",
            "         -9.7114,  -9.8508,  -9.9992,  -9.6840,  -9.7415,  -9.6351,  -9.6525,\n",
            "         -9.7081,  -9.5793,  -9.7119,  -9.5881,  -9.3684,  -9.5030,  -9.3344,\n",
            "         -9.5371,  -9.7359,  -9.7558,  -9.6370,  -9.7044,  -9.7390,  -9.9138,\n",
            "         -9.7885,  -9.5988,  -9.3273,  -9.7366,  -9.8133,  -9.6115,  -9.5679,\n",
            "         -9.7414,  -9.9342,  -9.5650,  -9.5640,  -9.7561,  -9.8454,  -9.8526,\n",
            "         -9.7731,  -9.8101,  -9.7204,  -9.9553,  -9.8048,  -9.5445,  -9.8096,\n",
            "        -10.0362,  -9.8525,  -9.6599,  -9.5364,  -9.8400,  -9.8491,  -9.5519,\n",
            "         -9.6971,  -9.6413,  -9.8047,  -9.8734,  -9.8643,  -9.8094,  -9.6905,\n",
            "         -9.5025,  -9.8001,  -9.8220,  -9.5269,  -9.5713,  -9.4179,  -9.4838,\n",
            "         -9.6477,  -9.3424,  -9.7653,  -9.8520,  -9.8493,  -9.8423,  -9.8271,\n",
            "         -9.8499,  -9.8250,  -9.8359,  -9.8281,  -9.8334,  -9.8088,  -9.8123,\n",
            "         -9.8246,  -9.8181,  -9.8436,  -9.8477,  -9.8598,  -9.8775,  -9.8461,\n",
            "         -9.8385,  -9.8442,  -9.8040,  -9.8010,  -9.7874,  -9.8114,  -9.8518,\n",
            "         -9.7543,  -9.8228,  -9.8293,  -9.8725,  -9.8125,  -9.7979,  -9.7976,\n",
            "         -9.8098,  -9.7945,  -9.8005,  -9.8091,  -9.8168,  -9.8548,  -9.8601,\n",
            "         -9.8510,  -9.8487,  -9.8753,  -9.8503,  -9.8508,  -9.8489,  -9.8762,\n",
            "         -9.8684,  -9.8443,  -9.8145,  -9.8668,  -9.8510,  -9.8864,  -9.9006,\n",
            "         -9.8851,  -9.8598,  -9.8829,  -9.8952,  -9.8929,  -9.8527,  -9.8626,\n",
            "         -9.9221,  -9.8786,  -9.8755,  -9.8714,  -9.8655,  -9.8619,  -9.8903,\n",
            "         -9.8616,  -9.8636,  -9.9047,  -9.8965,  -9.8859,  -9.8829,  -9.9082,\n",
            "         -9.8768,  -9.8837,  -9.8672,  -9.8654,  -9.8603,  -9.9067,  -9.8828,\n",
            "         -9.8478,  -9.8568,  -9.8336,  -9.8638,  -9.8502,  -9.8297,  -9.8217,\n",
            "         -9.8034,  -9.8159,  -9.8501,  -9.8489,  -9.8465,  -9.8281,  -9.8193,\n",
            "         -9.8087,  -9.8462,  -9.8462,  -9.8362,  -9.8217,  -9.8435,  -9.8706,\n",
            "         -9.8365,  -9.8856,  -9.9016,  -9.8797,  -9.9243,  -9.9019,  -9.9289,\n",
            "         -9.8854,  -9.8254,  -9.8660,  -9.8720,  -9.8638,  -9.9075,  -9.8263,\n",
            "         -9.8921,  -9.8987,  -9.9436,  -9.9008,  -9.9035,  -9.8920,  -9.9126,\n",
            "         -9.9444,  -9.8916,  -9.8782,  -9.8647,  -9.8957,  -9.9246,  -9.9107,\n",
            "         -9.8858,  -9.8909,  -9.8888,  -9.8877,  -9.8792,  -9.9132,  -9.9054,\n",
            "         -9.8962,  -9.8668,  -9.8547,  -9.8419,  -9.8835,  -9.8235,  -9.8234,\n",
            "         -9.8410,  -9.8664,  -9.8451,  -9.8715,  -9.8090,  -9.8132,  -9.8122,\n",
            "         -9.8259,  -9.8380,  -9.7494,  -9.7519,  -9.8209,  -9.8241,  -9.8389,\n",
            "         -9.8379,  -9.8310,  -9.8577,  -9.8486,  -9.8371,  -9.7535,  -9.7295,\n",
            "         -9.3440], device='cuda:0')\n",
            "------5------\n",
            "torch.Size([512])\n",
            "##노버\n",
            "tensor([-7.2506, -9.0384, -8.6610, -8.5975, -8.9161, -8.2844, -8.6921, -8.7504,\n",
            "        -8.8123, -8.5670, -8.6614, -9.1410, -9.0787, -8.9407, -8.4522, -8.5189,\n",
            "        -8.9141, -8.2373, -8.6511, -9.0905, -9.0264, -8.9973, -8.9485, -8.7763,\n",
            "        -8.6913, -9.2163, -9.0416, -9.0026, -8.7352, -8.8895, -8.9949, -8.9821,\n",
            "        -8.8885, -9.0720, -9.0713, -8.7575, -9.0041, -8.9963, -8.7394, -9.0973,\n",
            "        -9.1473, -8.8772, -8.8309, -8.8865, -8.4825, -8.3082, -8.2286, -8.8962,\n",
            "        -8.2912, -9.1396, -8.8022, -9.0665, -8.9707, -8.5871, -9.1971, -9.0643,\n",
            "        -9.0459, -9.0403, -8.9523, -8.9850, -9.2634, -9.1423, -9.0330, -9.1009,\n",
            "        -8.8313, -9.2042, -8.5366, -8.4295, -8.8087, -8.7480, -8.1785, -8.9489,\n",
            "        -8.3842, -8.5759, -7.9898, -8.6321, -8.9436, -9.0319, -8.9408, -9.1174,\n",
            "        -8.9854, -8.7569, -8.9330, -8.6797, -8.9017, -8.7246, -8.7170, -8.9263,\n",
            "        -8.7566, -8.5272, -8.3649, -8.8224, -8.7097, -8.9951, -9.0154, -8.8512,\n",
            "        -8.6207, -9.0947, -8.7344, -9.0589, -9.1484, -8.9640, -9.0515, -8.7819,\n",
            "        -8.8898, -8.9658, -8.7380, -9.0971, -9.0095, -9.2475, -9.0289, -8.9214,\n",
            "        -8.7392, -8.8157, -9.1567, -9.1520, -8.8764, -8.8686, -8.9721, -8.5722,\n",
            "        -8.8666, -8.9458, -9.1422, -8.9138, -9.3328, -8.9940, -9.0916, -9.1512,\n",
            "        -8.9860, -8.9098, -9.0007, -8.8583, -9.0888, -8.8474, -9.0614, -9.0556,\n",
            "        -8.8934, -9.0166, -9.0578, -8.9409, -8.8087, -9.0213, -8.9826, -8.9937,\n",
            "        -9.0504, -9.0085, -8.9623, -9.0438, -9.0480, -8.9241, -8.9050, -9.0087,\n",
            "        -8.9281, -9.0335, -8.9234, -9.1237, -8.9919, -8.8764, -8.9869, -9.0093,\n",
            "        -9.0201, -8.9653, -9.0962, -8.9849, -8.8439, -9.0979, -8.9784, -8.8791,\n",
            "        -9.0488, -8.8803, -8.8320, -9.0167, -8.9047, -8.9436, -8.8056, -9.0913,\n",
            "        -8.9624, -8.8192, -8.9823, -9.2044, -8.8437, -8.8136, -9.0295, -8.5258,\n",
            "        -8.9335, -8.6383, -8.9722, -8.6852, -8.9678, -8.9386, -8.8364, -8.8981,\n",
            "        -8.8626, -8.6569, -9.0093, -8.8312, -9.1383, -9.0600, -8.7649, -8.9001,\n",
            "        -8.8678, -8.8219, -8.9167, -8.6758, -8.9513, -9.1071, -9.0127, -8.9232,\n",
            "        -8.9413, -9.0124, -9.0947, -9.0114, -8.9114, -9.0025, -9.0195, -9.0868,\n",
            "        -9.0601, -8.9518, -9.0434, -9.1085, -9.0096, -9.0197, -9.0664, -9.0891,\n",
            "        -9.0168, -9.0879, -8.8320, -9.0783, -9.0719, -9.0519, -9.1080, -9.1022,\n",
            "        -9.1994, -9.0417, -8.8861, -9.0609, -8.9730, -8.9057, -9.0152, -8.9961,\n",
            "        -9.1680, -8.9710, -8.9634, -8.9493, -8.8988, -8.9290, -8.7722, -9.0644,\n",
            "        -8.8571, -9.0953, -9.1839, -8.9068, -8.8934, -9.1116, -9.0296, -9.1654,\n",
            "        -9.0521, -9.1224, -8.9756, -8.8756, -8.9267, -9.1986, -8.3431, -8.5374,\n",
            "        -8.4860, -8.6353, -8.4729, -8.8396, -8.5850, -8.7597, -9.0522, -8.7237,\n",
            "        -8.7239, -8.8145, -8.5369, -9.0461, -9.1568, -8.8166, -8.8413, -9.1011,\n",
            "        -9.0073, -8.8785, -9.1551, -8.8703, -9.2757, -9.2600, -9.0669, -9.0245,\n",
            "        -8.8774, -9.0545, -9.1320, -8.8240, -9.1320, -9.0433, -8.9503, -8.8519,\n",
            "        -9.0714, -8.9325, -8.9885, -8.4948, -8.4904, -8.8536, -8.7916, -8.9534,\n",
            "        -8.7340, -8.9449, -8.8382, -8.5789, -9.2130, -8.9425, -8.8994, -9.2226,\n",
            "        -9.0883, -9.1024, -8.9406, -8.7091, -8.9877, -8.9966, -8.7329, -9.0359,\n",
            "        -9.2446, -9.1864, -8.8750, -9.0122, -9.0276, -8.8032, -8.9722, -8.9898,\n",
            "        -8.9999, -8.8993, -8.7947, -8.7311, -8.9175, -8.9192, -9.0092, -8.8026,\n",
            "        -9.1173, -9.0627, -8.9315, -9.0545, -9.1413, -9.0535, -9.0002, -9.0689,\n",
            "        -9.1839, -8.8785, -9.1273, -9.1791, -9.2517, -8.9493, -9.1427, -9.0292,\n",
            "        -9.1835, -8.8458, -9.1496, -9.0291, -9.1792, -8.9528, -9.0125, -8.9685,\n",
            "        -8.9383, -8.7113, -9.1653, -8.6940, -8.0532, -8.4836, -8.5707, -8.7903,\n",
            "        -8.6481, -8.9191, -8.8720, -9.0521, -8.8947, -8.8481, -8.8505, -9.0044,\n",
            "        -8.8672, -8.7473, -8.7828, -9.1734, -8.8950, -8.8231, -8.8034, -8.9283,\n",
            "        -9.0003, -8.8294, -8.6476, -8.8919, -8.4239, -8.9305, -8.6992, -8.5306,\n",
            "        -8.4956, -8.9347, -8.9910, -8.6865, -8.8786, -8.9667, -9.2003, -8.8549,\n",
            "        -8.8537, -8.7258, -9.0325, -8.7926, -8.8501, -8.8714, -8.8803, -9.2607,\n",
            "        -8.3235, -8.4366, -8.5344, -8.7782, -8.6579, -8.4621, -8.8352, -8.5979,\n",
            "        -8.7963, -9.2433, -9.0365, -9.1264, -8.6459, -8.8059, -8.5514, -8.9753,\n",
            "        -8.8371, -8.8967, -8.5075, -8.9944, -9.2357, -8.9314, -8.7911, -9.1302,\n",
            "        -8.2017, -8.0488, -8.5989, -8.5243, -8.5361, -8.2327, -8.7166, -8.9593,\n",
            "        -8.5432, -8.4273, -9.0812, -9.1899, -9.0304, -5.3936,  8.6691, -2.0721,\n",
            "        -7.7695, -8.8940, -8.6248, -8.6725, -8.9484, -8.7001, -8.8717, -8.7935,\n",
            "        -8.8413, -8.9004, -8.4300, -8.9374, -8.6749, -8.1701, -8.7228, -8.7218,\n",
            "        -8.6219, -8.9949, -8.3910, -9.0455, -8.9194, -8.9986, -9.0683, -8.9522,\n",
            "        -9.0364, -9.1189, -8.7203, -9.1725, -9.1577, -9.1058, -8.7923, -8.3957,\n",
            "        -8.8481, -8.6223, -8.6637, -8.4635, -9.0970, -8.8880, -9.1114, -8.9752,\n",
            "        -8.9942, -9.1021, -8.7095, -8.7654, -9.2784, -9.2397, -9.2822, -9.2819,\n",
            "        -9.2873, -9.3173, -9.3111, -9.2898, -9.2682, -9.0701, -9.2398, -9.2633,\n",
            "        -9.2671, -9.2535, -9.2203, -9.2418, -9.2267, -9.1755, -9.0785, -8.7637],\n",
            "       device='cuda:0') tensor([ -7.6043,  -9.1973,  -9.1444,  -9.3198,  -9.3842,  -9.2675,  -9.2776,\n",
            "         -8.9604,  -9.3207,  -9.2037,  -9.1744,  -9.3333,  -8.9718,  -9.1285,\n",
            "         -8.8863,  -9.2980,  -9.3460,  -9.2123,  -9.0968,  -9.2874,  -9.3426,\n",
            "         -9.5288,  -9.5825,  -9.6952,  -9.1374,  -9.0945,  -9.4261,  -9.3926,\n",
            "         -9.5772,  -9.1847,  -9.4489,  -9.6505,  -9.6719,  -9.5090,  -9.3089,\n",
            "         -9.4621,  -9.4423,  -9.3595,  -9.6674,  -9.5210,  -9.4463,  -9.6399,\n",
            "         -9.5306,  -9.5488,  -9.5432,  -9.0532,  -9.4460,  -8.9991,  -9.4047,\n",
            "         -9.2393,  -9.5553,  -9.2013,  -9.6279,  -9.9073,  -9.3239,  -9.5164,\n",
            "         -9.4389,  -9.3550,  -9.1333,  -8.7122,  -9.3381,  -9.7181,  -9.5847,\n",
            "         -9.0423,  -9.5232,  -9.1618,  -9.2284,  -9.1249,  -9.3842,  -9.3079,\n",
            "         -9.6755,  -9.6853,  -9.3052,  -9.3002,  -9.2738,  -9.2864,  -9.3011,\n",
            "         -9.6454,  -9.8042,  -9.4332,  -9.5036,  -9.5952,  -9.4216,  -9.5008,\n",
            "         -9.6632,  -9.4219,  -9.5559,  -9.3810,  -9.3811,  -9.2206,  -9.1875,\n",
            "         -9.0613,  -9.4330,  -9.3561,  -9.2519,  -9.2963,  -9.6950,  -8.9921,\n",
            "         -9.4900,  -9.5624,  -9.3897,  -9.4375,  -9.6081,  -9.6477,  -9.3283,\n",
            "         -9.5451,  -9.8568,  -9.5990,  -9.7234,  -9.5714,  -9.5709,  -9.2942,\n",
            "         -9.4062,  -9.4902,  -9.2147,  -9.3188,  -9.6464,  -9.5439,  -9.6375,\n",
            "         -9.7230,  -9.6841,  -9.3538,  -9.4664,  -9.3777,  -9.4469,  -9.6415,\n",
            "         -9.2590,  -9.4001,  -9.6288,  -9.4934,  -9.5609,  -9.5924,  -9.6509,\n",
            "         -9.6867,  -9.5949,  -9.5382,  -9.6551,  -9.5732,  -9.5039,  -9.3924,\n",
            "         -9.7063,  -9.6819,  -9.5767,  -9.4299,  -9.7411,  -9.8480,  -9.7546,\n",
            "         -9.5434,  -9.5726,  -9.7135,  -9.8789,  -9.7913,  -9.8415,  -9.6118,\n",
            "         -9.7619,  -9.6028,  -9.8082,  -9.7478,  -9.8723,  -9.7175,  -9.7920,\n",
            "         -9.7957,  -9.6205,  -9.6317,  -9.7778,  -9.6906,  -9.8349,  -9.4672,\n",
            "         -9.7152,  -9.6788,  -9.5348,  -9.4784,  -9.7098,  -9.7946,  -9.8203,\n",
            "         -9.4999,  -9.7296,  -9.8411,  -9.9682,  -9.6662,  -9.8882,  -9.5465,\n",
            "         -9.3148,  -9.9674,  -9.7478,  -9.8042,  -9.5520,  -9.5083,  -9.4520,\n",
            "         -9.0823,  -9.4884,  -9.4639,  -9.6416,  -9.6949,  -9.6319,  -9.5274,\n",
            "         -9.4861,  -9.7555,  -9.7337,  -9.3336,  -9.6122,  -9.3175,  -9.6965,\n",
            "         -9.3289,  -9.4979,  -9.6640,  -9.6345,  -9.6812,  -9.8564,  -9.6615,\n",
            "         -9.7442,  -9.5571,  -9.6916,  -9.6636,  -9.8413,  -9.7311,  -9.6852,\n",
            "         -9.6896,  -9.8374,  -9.6694,  -9.8560,  -9.7040,  -9.8266,  -9.6101,\n",
            "         -9.5423,  -9.7134,  -9.4988,  -9.5649,  -9.7406,  -9.7818,  -9.6925,\n",
            "         -9.6579,  -9.5586,  -9.6488,  -9.7687,  -9.6624,  -9.7419,  -9.8099,\n",
            "         -9.7744,  -9.6885,  -9.7021,  -9.9106,  -9.7278,  -9.7197,  -9.8763,\n",
            "         -9.5055,  -9.9553,  -9.7667,  -9.7151,  -9.5489,  -9.7898, -10.0412,\n",
            "         -9.8238,  -9.7770,  -9.6664,  -9.7083,  -9.8195,  -9.7193,  -9.6206,\n",
            "         -9.7763,  -9.3045,  -8.6183,  -9.2302,  -9.4083,  -9.6265,  -9.6164,\n",
            "         -9.5070,  -9.3885,  -9.5724,  -9.8285,  -9.5675,  -9.8617,  -9.4114,\n",
            "         -9.5257,  -9.0769,  -9.6495,  -9.5292,  -9.8306,  -9.5421,  -9.6832,\n",
            "         -9.7134,  -9.6221,  -9.5762,  -9.5367,  -9.3544,  -9.5595,  -9.6657,\n",
            "         -9.6367,  -9.8826,  -9.5375,  -9.5976,  -9.7840,  -9.5125,  -9.4726,\n",
            "         -9.7514,  -9.7179,  -9.6230,  -9.6951,  -9.4180,  -9.8395,  -9.7653,\n",
            "         -9.2049,  -9.4925,  -9.1524,  -9.3855,  -9.1185,  -9.5431,  -9.8675,\n",
            "         -9.2550,  -9.7875,  -9.8303,  -9.5525,  -9.5712,  -9.3159,  -9.4377,\n",
            "         -9.2951,  -9.4881,  -9.8739,  -9.9892,  -9.6441,  -9.2977,  -9.5066,\n",
            "         -9.7363,  -9.6097,  -9.5677,  -9.7688,  -9.5101,  -9.5908,  -9.5185,\n",
            "         -9.2414,  -9.1148,  -9.5102,  -9.2802,  -9.4642,  -9.7547,  -9.7994,\n",
            "         -9.5226,  -9.6495,  -9.7746,  -9.5251,  -9.5223,  -9.5883,  -9.4174,\n",
            "         -9.5000,  -9.7740,  -9.6874,  -9.6397,  -9.7559,  -9.7534,  -9.9031,\n",
            "         -9.5752,  -9.5917,  -9.6668,  -9.7505,  -9.7902,  -9.8116,  -9.5648,\n",
            "         -9.6319,  -9.6074,  -9.5546,  -9.2829,  -9.3972,  -8.2270,  -9.4347,\n",
            "         -9.2082,  -9.2718,  -9.0018,  -9.1954,  -9.5181,  -9.6242,  -9.7852,\n",
            "         -9.4299,  -9.6814,  -9.6613,  -9.7447,  -9.3963,  -9.5519,  -9.5990,\n",
            "         -9.8600,  -9.2126,  -9.6019,  -9.5393,  -9.7584,  -9.5427,  -9.4593,\n",
            "         -9.5858,  -9.6721,  -9.4452,  -9.8363,  -9.4053,  -9.6467,  -9.8292,\n",
            "         -9.3932,  -9.2842,  -9.3890,  -9.4653,  -9.5494,  -9.5764,  -9.3711,\n",
            "         -9.3089,  -9.6394,  -9.7998,  -9.5215,  -9.7870,  -9.5877,  -9.4749,\n",
            "         -9.4689,  -8.5139,  -9.7112,  -9.7108,  -9.6716,  -9.5608,  -9.5164,\n",
            "         -9.6850,  -9.7037,  -9.6832,  -9.4817,  -9.5445,  -9.4778,  -9.2660,\n",
            "         -9.2293,  -9.4849,  -9.7163,  -9.4147,  -9.5891,  -9.4568,  -9.4789,\n",
            "         -9.3610,  -9.3290,  -9.4310,  -9.3511,  -9.2587,  -8.6540,  -9.0082,\n",
            "         -8.7894,  -9.1137,  -8.7960,  -9.0178,  -8.5019,  -8.8376,  -9.6549,\n",
            "         -9.1732,  -9.3308,  -8.8623,  -8.8988,  -6.3128,  -1.6652,   8.8628,\n",
            "         -7.1844,  -8.6685,  -9.0997,  -9.0331,  -8.8168,  -9.3839,  -9.1896,\n",
            "         -9.2883,  -9.3277,  -9.4716,  -9.6372,  -9.3343,  -9.5467,  -9.7672,\n",
            "         -9.3252,  -8.8773,  -9.2982,  -8.8972,  -9.1769,  -9.5720,  -9.6042,\n",
            "         -9.6050,  -9.5077,  -9.2734,  -9.5246,  -9.3610,  -9.4643,  -9.4895,\n",
            "         -9.2664,  -9.2627,  -9.2198,  -8.8746,  -9.3968,  -9.1506,  -9.2101,\n",
            "         -9.4437,  -9.1151,  -9.5179,  -9.5753,  -9.5238,  -9.3706,  -9.3751,\n",
            "         -9.7336,  -9.4054,  -9.7168,  -9.7902,  -9.7266,  -9.7212,  -9.6859,\n",
            "         -9.7141,  -9.6983,  -9.6881,  -9.6970,  -9.6927,  -9.6195,  -9.6956,\n",
            "         -9.7305,  -9.7657,  -9.7977,  -9.7421,  -9.7193,  -9.6692,  -9.5766,\n",
            "         -9.4077], device='cuda:0')\n",
            "------6------\n",
            "torch.Size([512])\n",
            "[UNK]\n",
            "tensor([-7.9371, -8.8317, -8.9700, -9.0259, -9.3058, -9.2088, -9.3060, -9.0195,\n",
            "        -9.2710, -9.0249, -8.8287, -9.2733, -8.9356, -8.7660, -8.4594, -9.0430,\n",
            "        -9.1477, -9.1391, -9.2263, -9.0597, -8.9519, -9.2077, -9.2490, -8.9144,\n",
            "        -9.1469, -8.7634, -9.1168, -9.0423, -9.1381, -8.8969, -8.7319, -8.9298,\n",
            "        -9.0531, -8.7525, -8.7403, -8.8009, -8.8116, -9.2498, -9.1365, -9.1683,\n",
            "        -8.7948, -8.7018, -2.5035, -7.5367,  8.5710, -7.5674, -7.3678, -8.1657,\n",
            "        -8.2598, -7.9893, -8.9554, -8.9091, -8.8518, -9.2004, -8.8893, -8.8954,\n",
            "        -8.9978, -9.1295, -9.1257, -9.0517, -9.1422, -9.0680, -9.1122, -8.9748,\n",
            "        -9.1608, -9.1404, -9.0405, -9.0310, -8.9958, -8.9376, -8.9831, -8.8767,\n",
            "        -8.8045, -8.6958, -8.8821, -7.9409, -8.8138, -9.0642, -9.1108, -8.9161,\n",
            "        -9.1356, -8.9726, -9.0395, -9.0132, -9.0794, -8.8552, -9.0280, -8.7301,\n",
            "        -9.1584, -8.8185, -9.2460, -9.0886, -9.0370, -9.2563, -8.8990, -9.1697,\n",
            "        -8.9956, -9.0532, -8.9270, -9.1146, -8.8296, -8.5881, -9.5449, -8.3280,\n",
            "        -8.9198, -8.3048, -8.5951, -8.4317, -8.3264, -8.9004, -8.7666, -9.0621,\n",
            "        -9.0431, -9.3055, -9.0680, -9.2125, -9.0526, -9.2057, -9.1059, -9.0966,\n",
            "        -9.2822, -9.2008, -9.1981, -9.1605, -9.0202, -9.0363, -9.1161, -8.9886,\n",
            "        -8.7954, -8.7281, -8.8732, -8.9092, -8.8584, -9.1406, -9.3110, -9.0760,\n",
            "        -8.9886, -9.0023, -9.2945, -9.0501, -9.0862, -9.1898, -8.7883, -9.0346,\n",
            "        -9.0444, -8.9483, -9.3032, -9.1142, -8.9488, -9.0629, -9.2002, -8.8576,\n",
            "        -9.1345, -8.7912, -8.8170, -9.0374, -9.0720, -9.0624, -9.0529, -9.1555,\n",
            "        -8.9895, -9.0731, -9.0143, -9.0765, -9.1301, -8.9916, -9.2752, -9.1417,\n",
            "        -9.1011, -8.9577, -9.1019, -8.9301, -9.0370, -9.0151, -9.0057, -9.0146,\n",
            "        -9.1245, -9.1679, -9.2159, -8.9463, -9.1012, -9.0604, -9.0647, -9.2219,\n",
            "        -9.1199, -9.0375, -8.7932, -9.0726, -9.1115, -9.0921, -9.0004, -9.0761,\n",
            "        -9.0516, -8.9594, -9.0190, -9.0826, -8.9626, -9.1278, -8.9904, -8.9932,\n",
            "        -8.9879, -8.9944, -8.9221, -9.1673, -9.0248, -9.0272, -8.9750, -9.0433,\n",
            "        -9.0670, -8.9698, -9.0091, -9.0389, -9.0495, -9.0399, -9.0453, -8.9341,\n",
            "        -9.1471, -8.9511, -9.1121, -9.1380, -9.0107, -9.1373, -8.9722, -9.0798,\n",
            "        -8.9743, -8.8831, -9.0496, -8.9801, -8.8385, -8.9935, -8.8403, -9.0309,\n",
            "        -8.9767, -9.2062, -9.0122, -9.1839, -8.9703, -8.9197, -9.0416, -9.1590,\n",
            "        -9.0372, -9.0842, -9.0109, -9.0750, -9.1352, -9.0589, -8.8024, -8.8903,\n",
            "        -9.2087, -9.0795, -9.0903, -9.1595, -9.0333, -9.0536, -9.0120, -8.9989,\n",
            "        -9.0155, -9.1827, -8.9778, -9.2082, -9.0734, -8.9699, -8.9450, -8.8620,\n",
            "        -9.1092, -8.7772, -9.1170, -8.9295, -8.9461, -9.1255, -8.9898, -8.7335,\n",
            "        -8.9064, -9.0585, -8.8191, -9.1416, -9.1154, -9.1910, -8.9704, -9.1342,\n",
            "        -8.9778, -9.0719, -9.1930, -9.0814, -9.0680, -9.0741, -8.8504, -9.1084,\n",
            "        -9.1546, -8.9756, -8.9791, -9.0988, -8.9575, -9.1123, -8.9154, -9.2065,\n",
            "        -9.1588, -8.9991, -8.9383, -9.0776, -9.1297, -8.8438, -9.1390, -9.0429,\n",
            "        -8.9639, -8.9667, -9.0582, -9.1124, -9.0684, -8.9313, -9.1154, -8.9801,\n",
            "        -9.1529, -8.9707, -9.0968, -9.0907, -9.0442, -9.0279, -8.9137, -8.8720,\n",
            "        -8.9720, -8.8788, -8.9752, -8.7495, -8.6574, -8.7382, -8.5721, -8.8280,\n",
            "        -8.7874, -8.9598, -8.8286, -8.9983, -9.0975, -9.1028, -8.8905, -9.1797,\n",
            "        -9.0350, -9.0746, -8.9254, -9.1971, -9.0425, -8.9403, -8.9624, -9.2130,\n",
            "        -8.8830, -8.9845, -9.2905, -8.9932, -9.0619, -9.0725, -9.0492, -9.1226,\n",
            "        -8.9955, -9.0707, -9.1293, -9.2390, -8.8480, -8.9082, -8.7801, -8.7514,\n",
            "        -8.9995, -8.9756, -9.0121, -8.7774, -8.9335, -8.9383, -9.0438, -9.0390,\n",
            "        -9.0088, -9.1912, -8.9419, -9.1547, -9.0086, -8.9144, -9.0135, -9.0685,\n",
            "        -9.0606, -9.2016, -9.2988, -9.1000, -9.2772, -8.9092, -9.1099, -9.0738,\n",
            "        -9.0057, -8.9955, -9.1486, -9.1478, -9.1155, -9.2264, -9.0331, -9.0782,\n",
            "        -8.7966, -8.8988, -9.1445, -9.1526, -9.3343, -9.0414, -8.9894, -9.1400,\n",
            "        -9.1366, -9.1775, -9.3156, -9.0548, -9.0569, -9.0848, -9.0705, -8.9302,\n",
            "        -9.1723, -8.9530, -8.7247, -8.8262, -8.6928, -8.8983, -8.4524, -9.0852,\n",
            "        -8.9426, -9.0784, -9.2236, -9.0087, -8.9009, -8.9837, -9.1231, -9.1106,\n",
            "        -9.2587, -8.9736, -9.0355, -9.0845, -9.0223, -9.2854, -8.9514, -9.1396,\n",
            "        -9.0920, -8.9426, -9.2327, -9.1747, -9.1164, -9.2068, -9.0974, -8.9295,\n",
            "        -8.9223, -9.1829, -8.8783, -9.0351, -9.0418, -9.0804, -9.0245, -8.3396,\n",
            "        -6.5900, -8.7293, -8.8596, -8.5618, -8.8390, -8.7980, -8.8910, -8.9333,\n",
            "        -9.1290, -8.9386, -9.0713, -9.0763, -8.8748, -9.2150, -9.0500, -8.9621,\n",
            "        -8.9318, -9.0793, -9.1969, -8.9837, -9.0979, -9.3245, -9.1165, -9.0548,\n",
            "        -8.9990, -9.0787, -9.0154, -9.1419, -9.2541, -8.9687, -8.8741, -8.7172,\n",
            "        -9.1283, -8.9105, -9.1255, -9.1738, -9.0404, -8.9400, -8.5736, -8.9731,\n",
            "        -8.7693, -9.1460, -9.2741, -9.2795, -9.2581, -9.3068, -9.2858, -9.3061,\n",
            "        -9.2876, -9.3099, -9.2715, -9.2863, -9.2760, -9.3108, -9.2971, -9.2322,\n",
            "        -9.2318, -9.2595, -9.2111, -9.2412, -9.2314, -9.1894, -8.9248, -9.1478],\n",
            "       device='cuda:0') tensor([ -8.3215,  -9.3816,  -9.6364,  -9.8661,  -9.7354,  -9.5899,  -9.3301,\n",
            "         -9.6464,  -9.0572,  -9.1437,  -9.3818,  -9.5433,  -9.2308,  -9.7653,\n",
            "         -9.8458,  -9.7568,  -9.6465,  -9.7343,  -9.6698,  -9.8876,  -9.7956,\n",
            "         -9.6477,  -9.7449,  -9.7347,  -9.6213,  -9.8932,  -9.5767,  -9.7229,\n",
            "         -9.3329,  -9.4047,  -9.5904,  -9.4473,  -9.6029,  -9.8611,  -9.1784,\n",
            "         -9.3878,  -9.6415,  -9.4755,  -9.4967,  -9.5945,  -9.4272,  -9.1273,\n",
            "          8.5139,  -8.8486,  -2.3597,  -9.1736,  -9.5001,  -8.6414,  -9.1824,\n",
            "         -8.7772,  -9.0589,  -9.6602,  -9.8333,  -9.1080,  -9.4803,  -9.5312,\n",
            "         -9.4841,  -9.6098,  -9.6690,  -9.8037,  -9.7779,  -9.8604,  -9.7745,\n",
            "         -9.8350,  -9.6710,  -9.6833,  -9.5778,  -9.5093,  -9.4792,  -9.4176,\n",
            "         -9.4987,  -9.5528,  -9.7815,  -9.7939,  -9.7558,  -9.7985,  -9.4049,\n",
            "         -9.7625,  -9.8996,  -9.9786,  -9.8847, -10.0144,  -9.7698,  -9.5606,\n",
            "         -9.9128,  -9.9017,  -9.7477,  -9.8204,  -9.8227,  -9.8691,  -9.6505,\n",
            "         -9.8884,  -9.8261,  -9.4219,  -9.5150,  -9.5787,  -9.4133,  -7.2011,\n",
            "         -9.4320,  -9.0895,  -9.5620,  -9.6430,  -6.9237,  -9.2585,  -9.2957,\n",
            "         -9.4893,  -9.2009,  -9.4720,  -9.5251,  -9.0200,  -9.4929,  -9.5518,\n",
            "         -9.8084,  -9.6421,  -9.6319,  -9.1705,  -9.5394,  -9.3468,  -9.7333,\n",
            "         -9.9364,  -9.6882,  -9.8745,  -9.7452,  -9.6665,  -9.8710,  -9.4793,\n",
            "         -9.5719,  -9.4929,  -9.4771,  -9.5951,  -9.6628,  -9.5324,  -9.5782,\n",
            "         -9.6936,  -9.7245,  -9.7883,  -9.5570,  -9.8603,  -9.6124,  -9.8628,\n",
            "         -9.6929,  -9.2428,  -9.7946,  -9.7421,  -9.7733,  -9.7856,  -9.3296,\n",
            "         -9.7875,  -9.8034,  -9.3860,  -9.1188,  -6.4453,  -9.7385,  -9.7048,\n",
            "         -9.9656,  -9.9023,  -9.9079,  -9.9098,  -9.8541,  -9.7647, -10.0101,\n",
            "         -9.8556,  -9.7621,  -9.9688,  -9.7726,  -9.9097,  -9.8320,  -9.8890,\n",
            "         -9.7690,  -9.8691,  -9.9733,  -9.9043,  -9.8456,  -9.9607, -10.0516,\n",
            "         -9.9910,  -9.7396,  -9.7321,  -9.8865,  -9.9139,  -9.9787,  -9.7919,\n",
            "         -9.8159,  -9.7371,  -9.6559,  -9.8376, -10.0618,  -9.8191,  -9.6944,\n",
            "         -9.7873,  -9.6576,  -9.7631,  -9.5176,  -9.4498,  -9.8454,  -9.7913,\n",
            "         -9.7058,  -9.6828,  -9.8875,  -9.9563,  -9.7829,  -9.7222,  -9.7490,\n",
            "         -9.7005,  -9.7335,  -9.9061, -10.0207,  -9.7702,  -9.8109,  -9.9258,\n",
            "         -9.7840,  -9.6560,  -9.6130,  -9.5564,  -9.8614,  -9.8819,  -9.8058,\n",
            "         -9.9092,  -9.7506,  -9.7217,  -9.7716,  -9.8677,  -9.9035,  -9.9182,\n",
            "         -9.8677,  -9.8836,  -9.9471, -10.0092,  -9.7460,  -9.8073, -10.0607,\n",
            "         -9.6594,  -9.6885,  -9.5649,  -9.8727,  -9.5469,  -9.6187,  -9.8248,\n",
            "         -9.8042,  -9.7798,  -9.8409,  -9.8900,  -9.9649,  -9.7069,  -9.8058,\n",
            "         -9.8734, -10.0599, -10.0671,  -9.5780,  -9.6918,  -9.8318,  -9.7927,\n",
            "         -9.8780,  -9.9448,  -9.8808,  -9.8837,  -9.7382,  -9.7860,  -9.8297,\n",
            "         -9.7174,  -9.7756,  -9.7171,  -9.9257, -10.0000,  -9.6725,  -9.9389,\n",
            "         -9.5781,  -9.6882,  -9.5438,  -7.7225,  -9.6640,  -9.5078,  -9.4833,\n",
            "         -9.8013,  -9.9131,  -9.3124,  -9.7093,  -9.7513,  -9.3068,  -9.4268,\n",
            "         -9.8685,  -9.7243,  -9.6434,  -9.7763,  -9.6531,  -9.7003,  -9.9366,\n",
            "         -9.6536,  -9.5482,  -9.5483,  -9.3022,  -9.8297,  -9.8167,  -9.6809,\n",
            "         -9.8620,  -9.5218,  -9.4515,  -9.7366,  -9.6846,  -9.5838,  -9.7112,\n",
            "         -9.7672,  -9.5771,  -9.6880,  -9.6030,  -9.5167,  -9.5358,  -9.6091,\n",
            "         -9.7055,  -9.8780,  -9.8277,  -9.9298,  -9.7228,  -9.7906,  -9.6250,\n",
            "         -9.7008,  -9.6336,  -9.5271,  -9.4093,  -9.7094,  -9.4653,  -9.4277,\n",
            "         -9.4966,  -9.8116,  -9.8553,  -9.4538,  -9.4361, -10.0649,  -9.9069,\n",
            "         -9.9652,  -9.9404,  -9.9459,  -9.7018,  -9.8322,  -9.9458,  -9.8490,\n",
            "         -9.6640,  -9.9253,  -9.9942,  -9.8394,  -9.8527, -10.0482, -10.0101,\n",
            "         -9.9197,  -9.9681,  -9.8542,  -9.6280,  -9.7217,  -9.7681,  -9.6367,\n",
            "         -9.5367,  -9.5410,  -9.5243,  -9.6850,  -9.6238,  -9.7060,  -9.5344,\n",
            "         -9.6035,  -9.6389,  -9.8477,  -9.8303,  -9.8196,  -9.8368,  -9.8404,\n",
            "         -9.6915,  -9.7952,  -9.7496,  -9.5457,  -9.5083,  -9.4762,  -9.7971,\n",
            "         -9.4325,  -9.5636,  -9.7898,  -9.5510,  -9.5997,  -9.8494,  -9.6608,\n",
            "         -9.5754,  -9.6922,  -9.7149,  -9.8726,  -9.6821,  -9.7167,  -9.8291,\n",
            "         -9.8943,  -9.6682,  -9.6218,  -9.7070,  -9.7222,  -9.8319,  -9.7952,\n",
            "        -10.0435,  -9.8261,  -9.8763,  -9.7646,  -9.7795,  -9.8548,  -9.9655,\n",
            "         -9.7126,  -9.8132,  -9.5875,  -9.7303,  -9.8641,  -9.8111,  -9.6561,\n",
            "         -9.5264,  -9.4223,  -9.1708,  -9.5963,  -9.5911,  -9.3795,  -9.8868,\n",
            "        -10.0060, -10.0474,  -9.3569,  -9.7587,  -9.6527,  -9.6729,  -9.7016,\n",
            "         -9.7684,  -9.7887,  -9.7765,  -9.7255,  -9.8524,  -9.9889,  -9.7182,\n",
            "         -9.7486,  -9.6646,  -9.8407,  -9.7530,  -9.5890,  -9.6542,  -9.7509,\n",
            "         -9.6662,  -9.8629,  -9.8483,  -9.7241,  -9.9045,  -9.6473,  -9.6112,\n",
            "         -9.5664,  -9.9561,  -9.6157,  -9.4916,  -9.2885,  -7.3400,  -9.2661,\n",
            "         -8.9227,  -9.7280,  -9.8327,  -9.9192,  -9.3861,  -9.8578,  -9.9071,\n",
            "         -9.8821,  -9.7959,  -9.7045,  -9.6090, -10.0096,  -9.8813,  -9.9257,\n",
            "         -9.8653,  -9.9917,  -9.9427,  -9.8051,  -9.7538,  -9.9912,  -9.8161,\n",
            "         -9.8736,  -9.8283,  -9.6987,  -9.8312,  -9.9885, -10.0957,  -9.6498,\n",
            "         -9.6595,  -9.8022,  -9.9390, -10.0832,  -9.7868, -10.0725,  -9.8896,\n",
            "         -9.6562,  -9.4276,  -9.9375,  -9.8690,  -9.3380,  -9.8242,  -9.3396,\n",
            "         -9.8152,  -9.8473,  -9.8798,  -9.8528,  -9.8717,  -9.8438,  -9.8666,\n",
            "         -9.8609,  -9.9097,  -9.8976,  -9.8782,  -9.8531,  -9.8570,  -9.9303,\n",
            "         -9.9240,  -9.8789,  -9.9446,  -9.8986,  -9.8369,  -9.8183,  -9.8560,\n",
            "         -9.3392], device='cuda:0')\n",
            "------7------\n",
            "torch.Size([512])\n",
            "3일 법안심사\n",
            "tensor([-6.9844, -8.8934, -8.9731, -9.1630, -9.0818, -9.1981, -9.0825, -8.8472,\n",
            "        -8.8314, -9.2829, -8.7978, -9.1756, -9.0403, -9.0457, -9.0179, -8.9791,\n",
            "        -8.7838, -9.1408, -8.7478, -8.5482, -8.6677, -8.9950, -8.5941, -8.6775,\n",
            "        -8.2971, -8.6384, -8.7413, -8.8575, -8.7848, -8.5860, -8.8517, -8.9199,\n",
            "        -8.7873, -8.8138, -8.6265, -8.8833, -9.0136, -9.0151, -8.8593, -9.0617,\n",
            "        -8.9171, -8.9223, -9.0900, -8.9176, -8.9479, -9.0356, -8.8674, -8.9387,\n",
            "        -8.9458, -9.0455, -8.8215, -8.9225, -7.5222, -8.5789, -8.1529, -8.2706,\n",
            "        -8.0431, -8.9042, -8.6335, -8.9006, -8.6290, -8.8132, -9.1037, -8.8502,\n",
            "        -8.4383, -8.7958, -9.0079, -9.1302, -8.9550, -8.9669, -8.7965, -9.0170,\n",
            "        -9.0056, -8.6248, -7.2008,  9.4680, -8.1105, -1.8492, -8.1668, -8.6302,\n",
            "        -8.7408, -8.1278, -8.7838, -8.8705, -8.7255, -9.0111, -8.6791, -8.4948,\n",
            "        -8.9780, -8.6033, -8.7628, -8.8497, -8.7665, -8.9997, -8.8113, -8.9396,\n",
            "        -9.2189, -8.7529, -8.6264, -9.1925, -9.0422, -9.0094, -9.1061, -8.6242,\n",
            "        -9.0130, -8.9823, -9.0248, -9.1470, -8.8737, -9.2253, -8.8681, -8.2482,\n",
            "        -8.8294, -8.7356, -8.7516, -9.1990, -8.8516, -8.9744, -8.9837, -8.8105,\n",
            "        -8.9898, -9.2730, -9.0377, -9.0399, -9.0304, -9.0424, -8.8534, -9.0133,\n",
            "        -8.8957, -8.8356, -8.7025, -8.9569, -9.0585, -9.0739, -8.9167, -8.7092,\n",
            "        -8.8148, -9.0843, -8.9157, -8.8041, -9.0795, -8.8995, -9.0423, -9.0167,\n",
            "        -9.0769, -8.9300, -8.9351, -8.9262, -8.8130, -8.9506, -8.9254, -8.9610,\n",
            "        -8.8979, -8.8726, -9.0500, -8.9087, -9.1318, -9.0359, -8.9904, -9.0310,\n",
            "        -8.9658, -9.0356, -8.8552, -8.9718, -8.9890, -8.6129, -8.8306, -8.9790,\n",
            "        -9.1164, -8.8685, -8.9502, -8.9915, -8.8050, -8.9550, -8.8699, -8.7588,\n",
            "        -9.0827, -8.9281, -8.8415, -9.0264, -8.9668, -9.0346, -9.0133, -8.9809,\n",
            "        -9.0025, -9.0645, -9.1106, -9.0689, -8.9810, -8.9705, -8.8447, -9.0373,\n",
            "        -8.9225, -8.9718, -8.9834, -9.2480, -8.9691, -9.0004, -8.9693, -8.8968,\n",
            "        -9.1445, -9.1693, -8.3318, -9.0147, -8.7574, -8.7892, -9.0980, -8.9127,\n",
            "        -9.0434, -8.8566, -8.8339, -9.0204, -9.0120, -8.8309, -9.0200, -9.0121,\n",
            "        -8.9324, -9.0257, -9.0662, -8.9428, -8.9016, -8.8693, -8.8698, -8.9410,\n",
            "        -8.9067, -8.9441, -8.9770, -8.9550, -9.0151, -8.8198, -8.8892, -8.8995,\n",
            "        -8.9505, -8.7555, -8.8550, -8.8881, -8.6616, -8.8324, -8.9003, -8.9534,\n",
            "        -8.9242, -8.9684, -8.9955, -8.9375, -8.8890, -9.0842, -8.6252, -8.9205,\n",
            "        -8.8509, -9.1186, -8.9838, -9.0768, -8.9450, -8.9713, -8.9221, -8.8568,\n",
            "        -8.7969, -8.9729, -8.9735, -8.9277, -8.8215, -8.9700, -8.8654, -8.8701,\n",
            "        -8.9057, -8.8982, -8.9601, -8.8927, -8.7801, -8.8567, -8.9674, -8.8906,\n",
            "        -8.9132, -8.8528, -8.8848, -8.9208, -8.8519, -8.9663, -8.9343, -8.8128,\n",
            "        -8.8893, -9.0450, -8.9851, -8.9822, -8.8898, -8.8810, -8.9246, -8.6596,\n",
            "        -8.8432, -8.9619, -8.9190, -8.8694, -8.9097, -8.9534, -8.8046, -9.0308,\n",
            "        -9.1177, -9.0812, -9.1105, -9.0785, -9.0767, -9.0830, -9.0908, -9.0910,\n",
            "        -9.1151, -9.1284, -9.0936, -9.1605, -9.1742, -9.1629, -9.1447, -9.1709,\n",
            "        -9.1845, -9.1755, -9.2116, -9.2017, -9.2086, -9.2000, -9.1477, -9.1457,\n",
            "        -9.1559, -9.1889, -9.1793, -9.1773, -9.1767, -9.1589, -9.1680, -9.2019,\n",
            "        -9.2151, -9.2217, -9.1988, -9.1743, -9.2099, -9.2024, -9.2228, -9.2055,\n",
            "        -9.2223, -9.1934, -9.2462, -9.2355, -9.2367, -9.2903, -9.2774, -9.2560,\n",
            "        -9.2593, -9.2891, -9.3172, -9.2765, -9.2646, -9.2591, -9.2714, -9.2754,\n",
            "        -9.2701, -9.2651, -9.2474, -9.2225, -9.2624, -9.2380, -9.2554, -9.2575,\n",
            "        -9.2503, -9.2695, -9.2326, -9.2532, -9.2497, -9.2648, -9.2620, -9.2873,\n",
            "        -9.2988, -9.3086, -9.3500, -9.3418, -9.2894, -9.2961, -9.2943, -9.3237,\n",
            "        -9.2960, -9.3189, -9.3292, -9.3323, -9.3431, -9.3619, -9.3509, -9.3382,\n",
            "        -9.3391, -9.2620, -9.2664, -9.2623, -9.2598, -9.2548, -9.2575, -9.2513,\n",
            "        -9.2756, -9.2672, -9.2897, -9.2581, -9.2756, -9.2273, -9.2706, -9.2911,\n",
            "        -9.2930, -9.2289, -9.3133, -9.3260, -9.2885, -9.3454, -9.3442, -9.3385,\n",
            "        -9.2773, -9.3159, -9.3441, -9.3205, -9.2558, -9.2714, -9.2566, -9.2612,\n",
            "        -9.2705, -9.2813, -9.2680, -9.2805, -9.2481, -9.2542, -9.2675, -9.2428,\n",
            "        -9.2424, -9.2344, -9.2491, -9.2129, -9.2279, -9.2857, -9.2951, -9.3160,\n",
            "        -9.3141, -9.3044, -9.3233, -9.3426, -9.2822, -9.2863, -9.2851, -9.2723,\n",
            "        -9.3101, -9.2841, -9.2677, -9.2656, -9.2210, -9.2058, -9.2677, -9.2574,\n",
            "        -9.2701, -9.2396, -9.2284, -9.2218, -9.2186, -9.2199, -9.2207, -9.2324,\n",
            "        -9.2556, -9.2632, -9.2788, -9.2837, -9.2806, -9.2608, -9.2669, -9.3270,\n",
            "        -9.3340, -9.3146, -9.3042, -9.2959, -9.2827, -9.2132, -9.2949, -9.2893,\n",
            "        -9.2972, -9.2754, -9.2839, -9.2565, -9.1301, -9.2637, -9.2762, -9.2082,\n",
            "        -9.2325, -9.2361, -9.2744, -9.2795, -9.3058, -9.3285, -9.3491, -9.3414,\n",
            "        -9.3314, -9.3253, -9.3408, -9.2802, -9.3108, -9.3045, -9.3202, -9.3257,\n",
            "        -9.3252, -9.3055, -9.3268, -9.2889, -9.2708, -9.2900, -9.2777, -9.2444,\n",
            "        -9.2312, -9.2609, -9.2822, -9.2591, -9.2460, -9.2030, -9.2007, -9.0316],\n",
            "       device='cuda:0') tensor([ -7.6853,  -9.5587,  -9.7334,  -9.7334,  -9.7555,  -9.4885,  -9.5851,\n",
            "         -9.6231,  -9.8696,  -9.7448,  -9.8331,  -9.7327,  -9.8680,  -9.6681,\n",
            "         -9.4310,  -9.5192,  -9.4745,  -9.5765,  -9.6424,  -9.9819,  -9.7761,\n",
            "         -9.5818,  -9.2975,  -9.6664,  -9.8176,  -9.5039,  -9.4042,  -9.3555,\n",
            "         -9.5487,  -9.8445,  -9.4189,  -9.6509,  -9.7000,  -9.5677,  -9.7807,\n",
            "         -9.7925,  -9.6069,  -9.3431,  -9.5471,  -9.6136,  -9.7396,  -9.6503,\n",
            "         -9.7074,  -9.9418,  -9.8373,  -9.7287,  -9.8600,  -9.6747,  -9.7622,\n",
            "         -9.7437,  -9.8519,  -9.5674,  -4.0969,  -9.3074,  -9.1590,  -8.9650,\n",
            "         -9.2797,  -9.4538,  -9.4699,  -9.6663,  -9.5457,  -9.5639,  -8.8165,\n",
            "         -9.7772,  -9.9001,  -9.5602,  -9.5099,  -9.5046,  -9.9147,  -9.2975,\n",
            "         -9.5775,  -9.3927,  -8.9978,  -8.4104,  -9.4023,  -1.4258,  -7.8227,\n",
            "          9.2469,  -7.9234,  -8.7933,  -9.5719,  -9.8933,  -9.4455,  -9.4875,\n",
            "         -9.6249,  -9.3211,  -9.4308,  -8.8317,  -8.9310,  -9.3932,  -9.4698,\n",
            "         -9.5223,  -9.8091,  -9.4343,  -9.7182,  -9.6649,  -9.4454,  -9.6464,\n",
            "         -9.7192,  -9.5009,  -9.8110,  -9.7603,  -9.7190,  -9.9037,  -9.6879,\n",
            "         -9.7010,  -9.7425,  -9.6377,  -9.9701,  -9.3584,  -9.5135,  -9.5555,\n",
            "         -9.6687,  -9.5877,  -9.4822,  -9.5955,  -9.9761,  -9.7233,  -9.5470,\n",
            "         -9.7330,  -9.4987,  -9.3549,  -9.5558,  -9.7428,  -9.4978,  -9.7470,\n",
            "         -9.9146,  -9.7118,  -9.6262,  -9.7517,  -9.9891,  -9.6888,  -9.5944,\n",
            "         -9.3895,  -9.6888, -10.0141,  -9.9802,  -9.7116,  -9.9221,  -9.8659,\n",
            "         -9.4978,  -9.7593,  -9.6479,  -9.8905,  -9.8567,  -9.8820,  -9.8459,\n",
            "         -9.8400, -10.1084,  -9.8228, -10.0218,  -9.9098,  -9.9742,  -9.8693,\n",
            "         -9.8096,  -9.9707,  -9.8255,  -9.9650,  -9.8471,  -9.8347, -10.0197,\n",
            "         -9.7396,  -9.6309,  -9.5895,  -9.9078, -10.1604,  -9.9033,  -9.7326,\n",
            "         -9.6994, -10.0565,  -9.8098,  -9.8562,  -9.9328,  -9.8136, -10.0073,\n",
            "        -10.0334,  -9.7053,  -9.8322, -10.0780,  -9.8793,  -9.8898,  -9.8162,\n",
            "         -9.8441,  -9.9320,  -9.8894,  -9.8136,  -9.8919,  -9.7646,  -9.7257,\n",
            "         -9.8149, -10.0858,  -9.8343,  -9.8998,  -9.7614,  -9.7118,  -9.7128,\n",
            "        -10.0548,  -9.8412,  -9.9763,  -9.8120,  -7.9860,  -8.4215,  -9.4669,\n",
            "         -9.5529,  -9.9908,  -9.8136,  -9.6335,  -9.7855,  -9.7730, -10.0150,\n",
            "        -10.1296,  -9.8117,  -9.8645,  -9.9925,  -9.7938,  -9.8533,  -9.9042,\n",
            "         -9.8727,  -9.8298,  -9.9742,  -9.9423,  -9.9494,  -9.9494,  -9.8890,\n",
            "         -9.9444,  -9.9164,  -9.8181,  -9.8757,  -9.8287, -10.0131, -10.0260,\n",
            "         -9.9138,  -9.8042,  -9.9772,  -9.9529,  -9.9471, -10.0524,  -9.8281,\n",
            "         -9.7777,  -9.8648,  -9.9754,  -9.7870,  -9.6662,  -9.7202,  -9.7036,\n",
            "         -9.6869,  -9.8774,  -9.9163,  -9.9693,  -9.6244,  -9.9261,  -9.8015,\n",
            "         -9.8092,  -9.8222,  -9.9923,  -9.8770, -10.0216,  -9.7675,  -9.8068,\n",
            "         -9.8555,  -9.9783,  -9.7529,  -9.8949,  -9.9790,  -9.8922,  -9.9229,\n",
            "         -9.7867,  -9.9253,  -9.9891, -10.0180,  -9.8906,  -9.8365,  -9.7909,\n",
            "         -9.9502,  -9.9635,  -9.8982,  -9.9124,  -9.7414,  -9.8786,  -9.9910,\n",
            "         -9.8629,  -9.7485,  -9.8321,  -9.7972, -10.0173,  -9.8096,  -9.9314,\n",
            "        -10.0502,  -9.8193,  -9.7167,  -9.8252,  -9.9457,  -9.7181,  -9.5946,\n",
            "         -9.7164,  -9.3636,  -9.8569,  -9.8995,  -9.8410,  -9.8902,  -9.8662,\n",
            "         -9.8810,  -9.8823,  -9.9022,  -9.8439,  -9.8583,  -9.8781,  -9.8846,\n",
            "         -9.8989,  -9.9126,  -9.9409,  -9.9132,  -9.9057,  -9.9223,  -9.8843,\n",
            "         -9.8928,  -9.8813,  -9.8878,  -9.9016,  -9.8645,  -9.8925,  -9.9282,\n",
            "         -9.9267,  -9.9245,  -9.8967,  -9.9367,  -9.9593,  -9.9175,  -9.9175,\n",
            "         -9.9179,  -9.9329,  -9.9380,  -9.9437,  -9.9670,  -9.9477,  -9.9244,\n",
            "         -9.9624,  -9.9763,  -9.9365,  -9.9336,  -9.9031,  -9.8812,  -9.9079,\n",
            "         -9.9471,  -9.8853,  -9.9084,  -9.8807,  -9.9571,  -9.9681,  -9.9210,\n",
            "         -9.8917,  -9.8817,  -9.9244,  -9.9243,  -9.8912,  -9.8727,  -9.8460,\n",
            "         -9.9165,  -9.9344,  -9.8780,  -9.9095,  -9.8916,  -9.9424,  -9.9170,\n",
            "         -9.9385,  -9.9376,  -9.9095,  -9.9001,  -9.8829,  -9.8772,  -9.8306,\n",
            "         -9.8307,  -9.9022,  -9.9245,  -9.9100,  -9.8763,  -9.9094,  -9.8947,\n",
            "         -9.8847,  -9.9130,  -9.9102,  -9.8924,  -9.8979,  -9.9071,  -9.8860,\n",
            "         -9.9680,  -9.9726,  -9.9615,  -9.9607,  -9.9961,  -9.9900, -10.0013,\n",
            "         -9.9734,  -9.9733,  -9.9478,  -9.9776,  -9.9668, -10.0298,  -9.9760,\n",
            "         -9.9896,  -9.9921, -10.0272,  -9.9725,  -9.9847, -10.0102,  -9.9524,\n",
            "         -9.9347,  -9.9925, -10.0524,  -9.9663,  -9.9428,  -9.9715, -10.0364,\n",
            "        -10.0164, -10.0251, -10.0105,  -9.9640,  -9.9493,  -9.9901,  -9.9738,\n",
            "        -10.0105,  -9.9899,  -9.9618,  -9.9766,  -9.9073,  -9.9676,  -9.9773,\n",
            "        -10.0301, -10.0115,  -9.9592,  -9.9560,  -9.9935,  -9.9660,  -9.9655,\n",
            "         -9.9348,  -9.9061,  -9.9845,  -9.9910,  -9.9825,  -9.9912,  -9.9138,\n",
            "         -9.9450,  -9.9920,  -9.9690,  -9.9380,  -9.9069,  -9.9460,  -9.9675,\n",
            "         -9.9537,  -9.9315,  -9.9920, -10.0109, -10.0314, -10.0048, -10.0218,\n",
            "        -10.0352, -10.0136, -10.0054,  -9.9879,  -9.9839, -10.0031, -10.0416,\n",
            "        -10.0366,  -9.9925,  -9.9728,  -9.9883,  -9.9804, -10.0309, -10.0377,\n",
            "        -10.0419,  -9.9669,  -9.9753,  -9.9746, -10.0138,  -9.9788, -10.0008,\n",
            "        -10.0947,  -9.9761,  -9.9659, -10.0319, -10.0102, -10.0126,  -9.9767,\n",
            "         -9.9690,  -9.9503,  -9.9305,  -9.9163,  -9.9411,  -9.9582,  -9.9429,\n",
            "         -9.9114, -10.0113,  -9.9745, -10.0056,  -9.9433,  -9.9357,  -9.9276,\n",
            "         -9.9478,  -9.9121,  -9.9186,  -9.9268,  -9.9165,  -9.9270,  -9.9590,\n",
            "         -9.9693,  -9.9424,  -9.9405,  -9.9523,  -9.9504,  -9.8855,  -9.8459,\n",
            "         -9.3647], device='cuda:0')\n",
            "------8------\n",
            "torch.Size([512])\n",
            "유출\n",
            "tensor([-6.8523, -8.8764, -8.7808, -8.7795, -9.1440, -8.9098, -9.0173, -9.1213,\n",
            "        -9.0963, -9.1326, -9.0303, -9.2298, -8.9156, -9.1164, -9.3341, -9.1107,\n",
            "        -8.9975, -8.7661, -8.9882, -8.9306, -8.9274, -8.6988, -8.8990, -8.9232,\n",
            "        -8.7427, -7.6831, -8.6025, -8.8278, -8.6354, -8.6291, -8.9451, -9.0659,\n",
            "        -9.1603, -9.0640, -8.9342, -9.5207, -9.1523, -9.1208, -9.0654, -9.1706,\n",
            "        -8.8306, -8.7340, -8.9074, -9.2552, -8.7523, -9.0341, -9.0689, -8.9830,\n",
            "        -9.1287, -8.9720, -8.8431, -8.9827, -9.2864, -9.1170, -9.3166, -9.1522,\n",
            "        -9.0422, -8.9846, -9.2080, -8.9182, -9.1150, -9.1729, -9.2561, -9.3455,\n",
            "        -9.1914, -9.2088, -9.0648, -8.9633, -9.0266, -9.1163, -9.1987, -8.9546,\n",
            "        -9.0216, -9.0405, -8.7220, -8.7632, -8.8975, -9.0007, -8.9945, -9.2404,\n",
            "        -9.1040, -9.0744, -8.7058, -9.2258, -9.0593, -9.2087, -9.1326, -8.9077,\n",
            "        -9.0724, -8.8497, -8.9990, -9.1946, -9.0850, -9.4771, -9.0354, -9.3088,\n",
            "        -9.0591, -9.0853, -9.1124, -9.4331, -9.1259, -9.3361, -8.9919, -8.9802,\n",
            "        -9.3360, -8.6885, -9.2775, -9.1580, -9.0667, -9.0157, -8.7610, -8.8334,\n",
            "        -8.3989, -9.3871, -8.9957, -9.3389, -9.0430, -9.0851, -8.9357, -9.1021,\n",
            "        -9.3853, -9.1247, -9.2543, -8.9440, -8.9773, -9.1569, -8.9895, -9.0230,\n",
            "        -8.8348, -9.1475, -9.3433, -9.0569, -9.0533, -8.8956, -8.8801, -9.3688,\n",
            "        -9.1268, -9.1771, -9.1456, -9.1153, -8.8093, -9.2579, -8.9983, -9.1558,\n",
            "        -9.1464, -8.8419, -9.2156, -8.9511, -9.1986, -9.0765, -9.0923, -9.1642,\n",
            "        -9.0300, -9.0191, -9.2888, -8.9981, -9.0794, -9.0668, -9.1805, -9.2185,\n",
            "        -8.9512, -9.1867, -9.0190, -9.1344, -9.2118, -9.0975, -9.0152, -9.1050,\n",
            "        -9.0916, -8.9112, -9.2245, -9.1471, -9.1999, -9.0661, -9.1122, -9.0287,\n",
            "        -9.1194, -9.1698, -8.9821, -9.1922, -9.1103, -9.0758, -8.8306, -9.1617,\n",
            "        -8.9429, -9.3152, -9.3583, -8.8862, -9.2416, -9.1285, -8.9978, -8.9516,\n",
            "        -9.0127, -9.0085, -9.1845, -8.9198, -9.0866, -9.2027, -8.9084, -9.1754,\n",
            "        -9.0719, -9.1363, -8.9969, -9.0045, -8.7450, -9.2098, -9.0772, -9.1147,\n",
            "        -9.1516, -9.1875, -8.9248, -8.9389, -9.0758, -9.1355, -9.2249, -9.0468,\n",
            "        -9.0711, -9.1351, -9.2502, -9.0074, -9.0302, -9.2479, -8.9549, -8.9873,\n",
            "        -8.9239, -9.0337, -9.1170, -9.1020, -9.1950, -9.1654, -8.9575, -8.9304,\n",
            "        -8.9683, -8.9661, -8.8165, -9.1132, -9.1150, -9.0457, -9.0648, -9.3182,\n",
            "        -9.0919, -9.2775, -9.0726, -9.1657, -9.0516, -9.1942, -9.1390, -9.0940,\n",
            "        -9.1544, -9.0452, -9.1165, -9.0982, -9.0670, -8.9942, -9.1558, -8.9690,\n",
            "        -9.1840, -9.0209, -9.2296, -9.0411, -9.0404, -9.3418, -9.1228, -9.0858,\n",
            "        -9.1740, -9.0699, -9.1824, -9.1802, -9.0310, -9.0643, -9.1970, -9.1214,\n",
            "        -8.9360, -9.0713, -8.8411, -8.8183, -8.9659, -8.8268, -8.8530, -9.1282,\n",
            "        -8.9826, -9.3454, -8.8971, -9.1752, -8.9578, -9.1512, -8.9627, -9.1955,\n",
            "        -9.2250, -8.9925, -8.8725, -8.7843, -9.1566, -8.8591, -9.0314, -9.1002,\n",
            "        -9.0820, -8.6577, -9.0412, -8.8646, -8.9323, -9.0863, -9.2517, -9.0353,\n",
            "        -9.0967, -9.2040, -9.1992, -8.9001, -8.9987, -8.6598, -8.5982, -8.6499,\n",
            "        -9.3760, -7.6036, -8.9063, -8.7401, -8.9742, -9.3261, -9.0353, -9.3731,\n",
            "        -9.0370, -8.9753, -9.4392, -8.2899, -9.0595, -9.0203, -8.9016, -9.2873,\n",
            "        -8.9394, -9.1226, -8.8836, -8.8663, -9.4530, -8.2194, -8.7985, -9.0782,\n",
            "        -8.8969, -9.0006, -9.0666, -9.3019, -9.0400, -9.1770, -8.8812, -8.9175,\n",
            "        -9.0399, -9.0572, -8.8022, -9.4895, -8.2851, -7.8459, -9.4051, -8.9704,\n",
            "        -9.1348, -9.0737, -9.0049, -9.3462, -9.1103, -9.1968, -9.1682, -8.8836,\n",
            "        -9.2670, -8.9400, -9.4115, -8.9166, -8.7824, -8.6849, -8.9208, -9.0829,\n",
            "        -9.0668, -9.2646, -8.9194, -9.3093, -9.1984, -9.1605, -8.8320, -9.1924,\n",
            "        -8.6373, -9.2475, -8.7063, -9.0761, -8.8450, -8.9431, -9.1430, -8.7980,\n",
            "        -9.1514, -8.9924, -9.0921, -8.6565, -8.9874, -8.9347, -9.2657, -8.9961,\n",
            "        -9.2768, -8.9604, -9.2972, -9.1504, -9.3038, -9.1832, -9.0908, -9.0845,\n",
            "        -8.9643, -9.0297, -9.1554, -9.2698, -9.3595, -8.9288, -9.0956, -9.2278,\n",
            "        -9.1146, -9.1936, -8.9703, -8.8856, -8.9581, -9.1006, -9.0588, -9.1571,\n",
            "        -9.0523, -8.9800, -9.0271, -9.4123, -8.2044, -8.4693, -8.9373, -8.9384,\n",
            "        -8.8205, -9.0757, -8.7770, -9.1147, -9.0064, -9.3049, -9.0042, -9.0415,\n",
            "        -8.9775, -9.0099, -8.7153, -8.7701, -8.9333, -8.8056, -8.8679, -8.7066,\n",
            "        -8.8705, -8.9300, -8.7653, -8.8116, -9.3722, -9.0516, -9.0731, -8.9422,\n",
            "        -9.2661, -8.6698, -8.4946, -8.6667, -9.4005, -8.0384, -8.8006, -8.5083,\n",
            "        -8.7360, -8.9883, -8.9146, -8.6855, -9.2052, -9.1124, -9.0705, -9.0496,\n",
            "        -8.8457, -8.9062, -8.9192, -8.7896, -8.9619, -9.0506, -9.0574, -9.1666,\n",
            "        -9.1713, -8.8611, -8.7885, -9.0503, -9.2634, -9.1378, -9.0690, -8.9707,\n",
            "        -8.8102, -9.1351, -8.8758, -2.1806,  8.6911, -7.9908, -7.5662, -7.7152,\n",
            "        -9.1097, -8.8278, -8.9443, -9.0941, -8.6395, -9.1039, -8.7762, -8.8354,\n",
            "        -9.0700, -9.0097, -8.6286, -9.2120, -9.0219, -9.1655, -9.3785, -9.0272,\n",
            "        -9.2877, -9.0084, -9.0795, -9.1875, -9.2568, -8.8803, -9.1832, -9.1040],\n",
            "       device='cuda:0') tensor([ -7.1736,  -8.7272,  -9.3081,  -9.2516,  -9.3957,  -9.6766,  -9.5651,\n",
            "         -9.3655,  -9.6753,  -9.8042,  -9.7769,  -9.5974,  -9.7525,  -9.6699,\n",
            "         -9.4828,  -9.6363,  -9.1382,  -9.3296,  -9.4667,  -9.4667,  -9.1420,\n",
            "         -9.2736,  -8.9946,  -8.4155,  -8.4193,  -9.0664,  -9.1744,  -9.1329,\n",
            "         -9.4718,  -9.2329,  -9.5721,  -9.6621,  -9.4648,  -9.6447,  -9.5747,\n",
            "         -9.3254,  -9.7005,  -9.6463,  -9.5403,  -9.5309,  -9.2112,  -9.3039,\n",
            "         -9.0757,  -9.1028,  -9.3661,  -9.5135,  -9.6650,  -9.7917,  -9.5416,\n",
            "         -9.7474,  -9.8411,  -9.7108,  -9.3163,  -9.4811,  -9.4173,  -9.5143,\n",
            "         -9.3875,  -9.6535,  -9.5980,  -9.8848,  -9.7472,  -9.7214,  -9.5942,\n",
            "         -9.6659,  -9.8227,  -9.5251,  -9.7229,  -9.6989,  -9.5786,  -9.5736,\n",
            "         -9.6336,  -9.8727,  -9.5382,  -9.6827,  -9.9481,  -9.4573,  -9.5653,\n",
            "         -9.7349,  -9.7400,  -9.4796,  -9.6907,  -9.7053, -10.0686,  -9.7491,\n",
            "         -9.9141,  -9.5549,  -9.2150,  -9.5295,  -9.4181,  -9.7121,  -9.5154,\n",
            "         -9.6419,  -9.6948,  -9.4733,  -9.6496,  -9.4789,  -9.8152,  -9.8097,\n",
            "         -9.5793,  -9.4989,  -9.6455,  -9.5476,  -9.8918,  -9.7317,  -9.2555,\n",
            "         -9.7792,  -9.4673,  -9.6542,  -9.5631,  -9.1884,  -9.3487,  -9.3469,\n",
            "         -9.5950,  -9.4058,  -9.7368,  -9.4656,  -9.7351,  -9.6642,  -9.8355,\n",
            "         -9.6757,  -9.2820,  -9.5580,  -9.5087,  -9.3777,  -9.4137,  -9.3857,\n",
            "         -9.4892,  -9.5849,  -9.7823,  -9.3215,  -9.4316,  -9.5539,  -9.4277,\n",
            "         -9.7791,  -9.7069,  -9.4941,  -9.8234,  -9.5788,  -9.4341,  -9.6916,\n",
            "         -9.8315,  -9.6048,  -9.8096,  -9.6119,  -9.6918,  -9.7869,  -9.7146,\n",
            "         -9.8955,  -9.6428,  -9.6758,  -9.7207,  -9.7578,  -9.5017,  -9.5719,\n",
            "         -9.4076,  -9.5519,  -9.6224,  -9.8352,  -9.5411,  -9.6602,  -9.9536,\n",
            "         -9.5858,  -9.8127,  -9.7460,  -9.5180,  -9.7081,  -9.7341,  -9.5693,\n",
            "         -9.7041,  -9.9464,  -9.7009,  -9.6863,  -9.7389,  -9.8214,  -9.7137,\n",
            "         -9.6255,  -9.6648,  -9.8301,  -9.9243,  -9.7818,  -9.7386,  -9.7288,\n",
            "        -10.0001,  -9.8192,  -9.3879,  -9.0182,  -9.4579,  -9.8352,  -9.6165,\n",
            "         -9.6564,  -9.7900,  -9.4197,  -9.4450,  -9.3502,  -9.3828,  -9.6692,\n",
            "         -9.4999,  -9.4481,  -9.8396,  -9.5658,  -9.5927,  -9.5848,  -9.5201,\n",
            "         -9.6786,  -9.9608,  -9.6543,  -9.8240,  -9.6622,  -9.5608,  -9.4070,\n",
            "         -9.7768,  -9.8054,  -9.7229,  -9.7219,  -9.7774,  -9.9297,  -9.8071,\n",
            "         -9.6491,  -9.6869,  -9.4424,  -9.5290,  -9.4615,  -9.5842,  -9.7534,\n",
            "         -9.8771,  -9.6527,  -9.6053,  -9.6350,  -9.5395,  -9.6632,  -9.8381,\n",
            "         -9.5431,  -9.7576,  -9.7158,  -9.8327,  -9.7983,  -9.6109,  -9.6793,\n",
            "         -9.5477,  -9.6135,  -9.8103,  -9.6829,  -9.8472,  -9.6227,  -9.8076,\n",
            "         -9.6798,  -9.7676,  -9.7595,  -9.6436,  -9.7077,  -9.5959,  -9.8167,\n",
            "         -9.9116,  -9.9434,  -9.6781,  -9.9189,  -9.6095,  -9.7609,  -9.5495,\n",
            "         -9.7939,  -9.7431,  -9.6553,  -9.8868,  -9.8250,  -9.7291,  -9.6860,\n",
            "         -9.5937,  -9.7558,  -9.5152,  -9.5162,  -9.5856,  -9.6080,  -9.8592,\n",
            "         -9.5932,  -9.7433,  -9.8961,  -9.6590,  -9.7574,  -9.8040,  -9.7350,\n",
            "         -9.8682,  -9.5667,  -9.8431,  -9.5935,  -9.7580,  -9.8331, -10.0078,\n",
            "         -9.5229,  -9.5310,  -9.5437,  -9.7483,  -9.8322,  -9.4645,  -9.7450,\n",
            "         -9.6195,  -9.4700,  -9.0882,  -9.6318,  -9.3789,  -9.6486,  -9.7423,\n",
            "         -9.3661,  -9.5749,  -9.8646,  -9.4940,  -9.4227,  -9.6027,  -9.3781,\n",
            "         -6.0897,  -8.8856,  -9.3196,  -9.0161,  -6.7013,  -9.4909,  -9.6152,\n",
            "         -9.8378,  -9.6458,  -9.2611,  -9.4781,  -9.2504,  -9.3257,  -9.1777,\n",
            "         -8.4968,  -9.7161,  -9.4555,  -9.5898,  -9.5932,  -9.3921,  -9.5449,\n",
            "         -9.7084,  -9.4499,  -9.4506,  -8.4206,  -9.8169,  -9.5822,  -9.3772,\n",
            "         -9.5150,  -9.5678,  -9.4799,  -9.5735,  -9.5771,  -9.6425,  -9.8781,\n",
            "         -9.6704,  -9.7590,  -9.5288,  -9.3872,  -7.9394,  -9.3997,  -8.9674,\n",
            "         -9.2612,  -9.6506,  -9.2149,  -9.4745,  -9.6708,  -9.5242,  -9.7526,\n",
            "         -9.5932,  -9.6971,  -9.4075,  -9.1405,  -9.4377,  -9.0688,  -9.2011,\n",
            "         -9.5014,  -9.6005,  -9.7800,  -9.6617,  -9.3244,  -9.6650,  -9.6956,\n",
            "         -9.4484,  -9.4152,  -9.5595,  -9.3723,  -9.6026,  -9.8895,  -9.1470,\n",
            "         -9.7588,  -9.3093,  -9.2968,  -9.4657,  -9.6359,  -9.6865,  -9.4012,\n",
            "         -9.2158,  -9.1984,  -9.5125,  -9.4630,  -9.5627,  -9.4544,  -9.7434,\n",
            "         -9.5671,  -9.8244,  -9.6216,  -9.8254,  -9.4202,  -9.3945,  -9.6655,\n",
            "         -9.7071,  -9.8489,  -9.8283,  -9.8178,  -9.5196,  -9.5406,  -9.9030,\n",
            "         -9.7107,  -9.6557,  -9.4011,  -9.4051,  -9.7228,  -9.8068,  -9.8536,\n",
            "         -9.7175,  -9.4523,  -9.6200,  -9.6514,  -9.3394,  -5.9723,  -8.1069,\n",
            "         -9.5349,  -9.5275,  -9.6243,  -9.8675,  -9.9445,  -9.7156, -10.0496,\n",
            "         -9.6098,  -9.7157,  -9.5017,  -9.7327,  -9.7576,  -9.4286,  -9.0812,\n",
            "         -9.4840,  -9.5992,  -9.8096,  -9.5147,  -9.4874,  -9.4066,  -9.2405,\n",
            "         -8.8759,  -9.5439,  -9.3214,  -9.3199,  -9.5267,  -9.6180,  -9.5140,\n",
            "         -8.1979,  -8.9725,  -9.2803,  -9.1987,  -7.7580,  -9.5228,  -9.8350,\n",
            "         -9.8279,  -9.5312,  -9.6140,  -9.1425,  -9.7026,  -9.6869,  -9.8364,\n",
            "         -9.7565,  -9.5527,  -9.3552,  -9.2408,  -9.8660, -10.0116,  -9.6738,\n",
            "         -9.5906,  -9.4916,  -9.4558,  -9.5592,  -9.8733,  -9.8242,  -9.3994,\n",
            "         -9.1235,  -9.1915,  -9.0609,  -9.3887,  -9.0978,  -8.9864,  -7.4133,\n",
            "          8.8095,  -1.9849,  -8.3842,  -8.8566,  -8.4189,  -8.9598,  -9.5540,\n",
            "         -9.5490,  -9.2932,  -9.4177,  -9.2603,  -9.6088,  -9.5490,  -9.3477,\n",
            "         -9.5312,  -9.9166,  -9.5950,  -9.6130,  -9.5695,  -9.3028,  -9.5907,\n",
            "         -9.3161,  -9.7141,  -9.5568,  -9.3664,  -9.4982,  -9.8445,  -9.5904,\n",
            "         -9.1238], device='cuda:0')\n",
            "------9------\n",
            "torch.Size([512])\n",
            "문건 유출 혐의, 공무상 비밀누설 혐의 등으로 박관천, 조응천 등을 기소하였다. 청와대는 [UNK] 몇 사람이 개인적으로 사심을 갖고 나라를 뒤흔든 있을 수 없는 일을 한 게 밝혀졌다 [UNK] 며 검찰 중간수사결과에 대해 다행이라고 반응하였고, 새누리당 이완구 원내대표는 [UNK] 검찰 수사로 이제 문건파동은 끝내고 민생에 집중하자 [UNK] 고 말했다. 한편, 새정치연합 우윤근 원내대표는 제기된 의혹에\n",
            "tensor([ 7.6237, -6.6597, -7.5126, -7.7718, -8.7610, -7.9174, -8.5492, -8.8966,\n",
            "        -8.8053, -8.4973, -8.5539, -8.9471, -8.4544, -8.7170, -9.1736, -8.7778,\n",
            "        -8.6704, -8.2159, -8.5743, -8.0795, -7.9719, -7.7070, -8.2170, -8.6270,\n",
            "        -8.8640, -8.6416, -8.8829, -8.9252, -8.9406, -8.9063, -8.7428, -8.6707,\n",
            "        -8.7118, -9.0912, -8.9018, -8.5473, -8.7939, -8.9903, -8.1697, -8.3658,\n",
            "        -8.2602, -8.7800, -8.5064, -8.9692, -8.4807, -8.8758, -8.8900, -8.7577,\n",
            "        -8.6895, -8.2689, -9.0791, -8.7578, -8.7922, -8.7242, -8.8037, -8.8477,\n",
            "        -8.5921, -8.8240, -8.9959, -9.0446, -9.0118, -8.9118, -8.8655, -8.5895,\n",
            "        -8.3454, -8.7269, -8.0542, -7.0741, -8.6626, -8.9464, -8.9599, -9.0106,\n",
            "        -9.0157, -8.8345, -9.1490, -8.8326, -8.7419, -8.8800, -8.9834, -8.8926,\n",
            "        -8.3981, -8.7384, -9.0382, -9.0741, -8.6697, -8.7364, -8.8061, -8.8599,\n",
            "        -8.8443, -8.9829, -8.7880, -8.9539, -8.8359, -9.1535, -9.0574, -9.0106,\n",
            "        -9.0590, -8.7192, -8.6288, -8.4253, -8.6288, -8.3199, -8.5692, -8.7085,\n",
            "        -8.6890, -8.9490, -8.6058, -8.9916, -8.9762, -8.4175, -8.8407, -8.9489,\n",
            "        -8.8944, -8.4208, -7.5055, -8.9750, -8.7932, -8.9235, -8.8140, -9.0297,\n",
            "        -9.0844, -8.9437, -8.4709, -8.6743, -8.1672, -8.8964, -8.7698, -8.7156,\n",
            "        -8.5183, -9.0659, -8.9938, -8.9252, -8.5286, -8.9365, -8.6186, -9.2624,\n",
            "        -8.9669, -8.9254, -8.9508, -9.0458, -8.7263, -9.0318, -8.9232, -8.6817,\n",
            "        -8.8677, -8.9988, -8.9379, -8.9435, -8.6426, -8.9095, -9.0314, -8.4647,\n",
            "        -9.0093, -8.5816, -8.9355, -8.6075, -8.7713, -8.6846, -9.2380, -9.2404,\n",
            "        -9.2460, -9.2376, -9.2368, -9.2239, -9.2196, -9.2055, -9.2155, -9.2281,\n",
            "        -9.2518, -9.2169, -9.2022, -9.2553, -9.2116, -9.2001, -9.2172, -9.2135,\n",
            "        -9.2067, -9.2304, -9.2245, -9.2308, -9.2825, -9.2742, -9.3128, -9.3074,\n",
            "        -9.2815, -9.2816, -9.2958, -9.2551, -9.2932, -9.2872, -9.2652, -9.2820,\n",
            "        -9.3136, -9.3019, -9.3283, -9.2939, -9.2888, -9.2662, -9.2410, -9.2510,\n",
            "        -9.2657, -9.2275, -9.2303, -9.2353, -9.2432, -9.2760, -9.2620, -9.2700,\n",
            "        -9.2787, -9.2473, -9.2537, -9.2516, -9.2498, -9.2962, -9.3072, -9.3122,\n",
            "        -9.3072, -9.3428, -9.3160, -9.3383, -9.3096, -9.3362, -9.3335, -9.3323,\n",
            "        -9.2758, -9.3175, -9.2999, -9.3022, -9.2954, -9.3174, -9.3140, -9.2719,\n",
            "        -9.2798, -9.2566, -9.2545, -9.2746, -9.2328, -9.2492, -9.2690, -9.2279,\n",
            "        -9.2804, -9.2844, -9.2742, -9.2822, -9.2894, -9.2901, -9.3157, -9.2829,\n",
            "        -9.2600, -9.2844, -9.3012, -9.2864, -9.3136, -9.2921, -9.2957, -9.3299,\n",
            "        -9.3251, -9.3109, -9.3080, -9.3368, -9.2940, -9.2660, -9.2797, -9.2514,\n",
            "        -9.2735, -9.2724, -9.2564, -9.2979, -9.2841, -9.2376, -9.2532, -9.2521,\n",
            "        -9.2557, -9.2549, -9.2449, -9.2561, -9.2440, -9.3129, -9.3041, -9.3118,\n",
            "        -9.2906, -9.3106, -9.3119, -9.3142, -9.2875, -9.2516, -9.2987, -9.3158,\n",
            "        -9.3016, -9.3006, -9.2650, -9.2894, -9.2985, -9.2801, -9.2671, -9.2465,\n",
            "        -9.2442, -9.2018, -9.2174, -9.2525, -9.2081, -9.2293, -9.2402, -9.2285,\n",
            "        -9.2344, -9.2421, -9.2554, -9.2822, -9.2931, -9.2274, -9.2335, -9.2558,\n",
            "        -9.2475, -9.2898, -9.2601, -9.3050, -9.3321, -9.2651, -9.3328, -9.3253,\n",
            "        -9.3075, -9.2961, -9.2804, -9.2857, -9.2847, -9.2533, -9.2788, -9.2944,\n",
            "        -9.2809, -9.2847, -9.2534, -9.2674, -9.2707, -9.2820, -9.2269, -9.2401,\n",
            "        -9.2378, -9.2688, -9.2584, -9.2750, -9.2994, -9.2987, -9.3122, -9.3537,\n",
            "        -9.3289, -9.3234, -9.2806, -9.2950, -9.3198, -9.3196, -9.3183, -9.2860,\n",
            "        -9.2905, -9.3191, -9.3062, -9.3028, -9.3132, -9.3009, -9.2601, -9.2930,\n",
            "        -9.2499, -9.2611, -9.2345, -9.2483, -9.2404, -9.2491, -9.2789, -9.2893,\n",
            "        -9.2917, -9.3012, -9.2667, -9.2899, -9.2704, -9.2519, -9.2958, -9.3038,\n",
            "        -9.3081, -9.3232, -9.3433, -9.3456, -9.3410, -9.3369, -9.3313, -9.3536,\n",
            "        -9.3395, -9.3037, -9.2753, -9.2955, -9.2599, -9.3043, -9.2977, -9.2752,\n",
            "        -9.2805, -9.3049, -9.3057, -9.2910, -9.2732, -9.2983, -9.2669, -9.2783,\n",
            "        -9.2844, -9.3035, -9.3218, -9.3152, -9.2842, -9.2919, -9.2879, -9.3539,\n",
            "        -9.3610, -9.3569, -9.3335, -9.3126, -9.3206, -9.3524, -9.3387, -9.3081,\n",
            "        -9.3147, -9.3194, -9.3397, -9.3444, -9.3464, -9.3297, -9.3069, -9.2802,\n",
            "        -9.2192, -9.2997, -9.2665, -9.2927, -9.2864, -9.3252, -9.2970, -9.3206,\n",
            "        -9.3305, -9.3357, -9.3619, -9.3245, -9.3386, -9.3352, -9.3020, -9.3349,\n",
            "        -9.3642, -9.3378, -9.3679, -9.3704, -9.3525, -9.3605, -9.3273, -9.3071,\n",
            "        -9.2746, -9.2968, -9.2747, -9.2719, -9.2863, -9.2895, -9.2903, -9.2959,\n",
            "        -9.3186, -9.3306, -9.3239, -9.3367, -9.2985, -9.3235, -9.3231, -9.3178,\n",
            "        -9.3381, -9.3556, -9.3586, -9.3418, -9.3460, -9.3525, -9.3558, -9.3811,\n",
            "        -9.3551, -9.3479, -9.3291, -9.3350, -9.3140, -9.3026, -9.3221, -9.2974,\n",
            "        -9.2925, -9.3094, -9.3359, -9.3358, -9.3566, -9.3375, -9.3312, -9.3471,\n",
            "        -9.3422, -9.3498, -9.3611, -9.3683, -9.4009, -9.3502, -9.3643, -9.3786,\n",
            "        -9.3865, -9.3863, -9.3935, -9.3784, -9.3717, -9.3529, -9.3307, -9.3098,\n",
            "        -9.3212, -9.3276, -9.3191, -9.2962, -9.2622, -9.1187, -9.0675, -8.6735],\n",
            "       device='cuda:0') tensor([ 7.6501, -6.9594, -8.5400, -8.3775, -8.9411, -9.0071, -8.9568, -8.9477,\n",
            "        -9.4059, -9.3840, -9.3612, -9.0409, -9.2439, -9.1667, -9.0726, -9.2274,\n",
            "        -8.6625, -8.6624, -8.9687, -8.5659, -8.1170, -8.2639, -7.7704, -8.7745,\n",
            "        -9.5005, -9.5789, -9.4485, -9.0891, -9.1043, -9.3671, -9.6637, -9.5654,\n",
            "        -9.5191, -9.3250, -9.2837, -9.5765, -9.3751, -8.8279, -9.2540, -8.4385,\n",
            "        -8.6669, -8.4513, -8.6787, -8.7640, -9.1650, -9.1642, -9.3682, -9.1508,\n",
            "        -9.2685, -9.8002, -9.2343, -9.2471, -9.5529, -9.3496, -9.4208, -9.5608,\n",
            "        -9.7200, -9.5673, -9.0923, -9.1018, -9.3633, -9.5820, -9.3409, -9.1415,\n",
            "        -8.4395, -8.0146, -8.8631, -8.8820, -9.0081, -9.4295, -9.4640, -9.5658,\n",
            "        -9.4449, -9.6330, -8.9373, -9.3078, -9.1624, -9.2174, -9.2373, -9.2780,\n",
            "        -9.3097, -9.3906, -9.3583, -9.2798, -9.2829, -9.2503, -9.2355, -8.8585,\n",
            "        -9.5380, -9.1903, -9.6757, -9.4208, -9.6728, -9.3918, -9.5174, -9.5120,\n",
            "        -9.4141, -8.9151, -8.5986, -8.6058, -9.4583, -9.4765, -8.9411, -9.0064,\n",
            "        -9.3748, -9.6357, -9.5484, -9.0981, -9.0694, -9.3639, -8.8236, -9.1309,\n",
            "        -8.8407, -9.3572, -9.3522, -9.3040, -9.4314, -9.2780, -9.0154, -9.1491,\n",
            "        -8.4281, -8.7258, -9.0515, -8.5152, -9.4235, -9.3373, -9.5404, -9.4521,\n",
            "        -9.0464, -9.3562, -9.5673, -9.5169, -9.6506, -9.1105, -9.2428, -9.2336,\n",
            "        -9.6668, -9.7400, -9.3544, -9.5070, -9.1202, -7.8397, -8.8436, -9.1197,\n",
            "        -9.6183, -9.9233, -9.6928, -9.6606, -9.6903, -9.4605, -9.4281, -9.8456,\n",
            "        -9.6472, -9.8003, -9.6855, -9.1526, -6.8056, -8.8675, -9.6928, -9.7621,\n",
            "        -9.7733, -9.7715, -9.8152, -9.8661, -9.8552, -9.8311, -9.7646, -9.7940,\n",
            "        -9.8418, -9.8246, -9.8250, -9.8150, -9.8273, -9.8595, -9.9197, -9.8542,\n",
            "        -9.8554, -9.8389, -9.8455, -9.8586, -9.8071, -9.8469, -9.7997, -9.8170,\n",
            "        -9.8810, -9.8916, -9.8399, -9.7484, -9.7841, -9.8445, -9.8167, -9.7835,\n",
            "        -9.7911, -9.8721, -9.7546, -9.7877, -9.7518, -9.7581, -9.7738, -9.8162,\n",
            "        -9.8179, -9.7911, -9.7749, -9.7793, -9.8036, -9.7602, -9.7837, -9.7785,\n",
            "        -9.7959, -9.8367, -9.8321, -9.7993, -9.7706, -9.7562, -9.7681, -9.7645,\n",
            "        -9.7979, -9.7574, -9.7180, -9.7203, -9.8256, -9.8207, -9.8222, -9.8083,\n",
            "        -9.7438, -9.8023, -9.8699, -9.8278, -9.8095, -9.7870, -9.7893, -9.8560,\n",
            "        -9.8677, -9.8792, -9.8319, -9.8049, -9.7314, -9.8347, -9.7710, -9.8259,\n",
            "        -9.8414, -9.8305, -9.8990, -9.9120, -9.8911, -9.8526, -9.8642, -9.9188,\n",
            "        -9.9412, -9.9096, -9.8792, -9.7738, -9.8169, -9.9353, -9.9182, -9.8626,\n",
            "        -9.8477, -9.8117, -9.8403, -9.7817, -9.8047, -9.8472, -9.7723, -9.8911,\n",
            "        -9.8688, -9.8385, -9.8480, -9.8193, -9.7848, -9.8322, -9.8824, -9.8612,\n",
            "        -9.8273, -9.8046, -9.8304, -9.7856, -9.8604, -9.7811, -9.8056, -9.8300,\n",
            "        -9.8538, -9.8314, -9.8015, -9.7758, -9.7397, -9.8261, -9.8253, -9.7765,\n",
            "        -9.8215, -9.7747, -9.7560, -9.8323, -9.8020, -9.7938, -9.8068, -9.7888,\n",
            "        -9.7955, -9.7579, -9.7920, -9.7818, -9.8071, -9.8090, -9.8294, -9.8683,\n",
            "        -9.8260, -9.8389, -9.8441, -9.8255, -9.8435, -9.9448, -9.9420, -9.9166,\n",
            "        -9.8373, -9.8779, -9.7368, -9.7719, -9.8366, -9.9609, -9.8715, -9.8507,\n",
            "        -9.8539, -9.8600, -9.9221, -9.8921, -9.8368, -9.8619, -9.8627, -9.8180,\n",
            "        -9.8870, -9.8984, -9.8880, -9.8820, -9.8838, -9.8606, -9.8917, -9.9254,\n",
            "        -9.9162, -9.8903, -9.8949, -9.8667, -9.8696, -9.8320, -9.8972, -9.7908,\n",
            "        -9.8395, -9.8267, -9.8848, -9.8855, -9.8700, -9.8594, -9.8275, -9.8405,\n",
            "        -9.9244, -9.8770, -9.8445, -9.8337, -9.8228, -9.7988, -9.8156, -9.8574,\n",
            "        -9.9116, -9.8371, -9.8746, -9.8423, -9.7528, -9.8354, -9.7959, -9.8129,\n",
            "        -9.8061, -9.7867, -9.8910, -9.8587, -9.8794, -9.7772, -9.7917, -9.7773,\n",
            "        -9.8511, -9.8499, -9.7985, -9.8168, -9.7891, -9.7765, -9.8872, -9.8512,\n",
            "        -9.8358, -9.8137, -9.7821, -9.8494, -9.8796, -9.8628, -9.8162, -9.8474,\n",
            "        -9.8366, -9.8689, -9.8675, -9.8894, -9.9064, -9.8872, -9.8645, -9.8784,\n",
            "        -9.9287, -9.8644, -9.9141, -9.8832, -9.8390, -9.8248, -9.8716, -9.9193,\n",
            "        -9.8806, -9.8631, -9.8752, -9.8587, -9.9023, -9.8643, -9.8523, -9.8475,\n",
            "        -9.9248, -9.9004, -9.8919, -9.8632, -9.8348, -9.8011, -9.8640, -9.8960,\n",
            "        -9.9271, -9.8630, -9.9155, -9.8597, -9.8361, -9.8940, -9.9126, -9.8823,\n",
            "        -9.8317, -9.8040, -9.7846, -9.8411, -9.8371, -9.8142, -9.7534, -9.7838,\n",
            "        -9.7662, -9.8496, -9.8249, -9.7965, -9.7979, -9.7949, -9.7949, -9.8303,\n",
            "        -9.8885, -9.8623, -9.8179, -9.8617, -9.8327, -9.8643, -9.8835, -9.8958,\n",
            "        -9.8732, -9.8538, -9.8421, -9.8619, -9.9384, -9.8935, -9.9130, -9.8215,\n",
            "        -9.8496, -9.8749, -9.9037, -9.9324, -9.9032, -9.8855, -9.8193, -9.8197,\n",
            "        -9.8541, -9.8709, -9.8396, -9.8432, -9.8515, -9.8762, -9.8087, -9.8813,\n",
            "        -9.9313, -9.9075, -9.8731, -9.8596, -9.8399, -9.8768, -9.8835, -9.8621,\n",
            "        -9.8283, -9.7985, -9.8112, -9.8469, -9.8548, -9.8685, -9.8237, -9.7963,\n",
            "        -9.7923, -9.8266, -9.8130, -9.7870, -9.7782, -9.7883, -9.8134, -9.7302,\n",
            "        -9.8187, -9.7827, -9.7873, -9.7940, -9.7727, -9.6193, -9.5517, -8.8744],\n",
            "       device='cuda:0')\n",
            "------10------\n",
            "torch.Size([512])\n",
            "네이버\n",
            "tensor([-6.5878, -8.9732, -9.0963, -8.7600, -9.1750, -9.1065, -8.8920, -8.6456,\n",
            "        -8.8846, -8.8653, -8.9917, -8.6150, -8.6482, -8.9874, -8.7883, -7.8199,\n",
            "        -8.5623, -8.6803, -8.8466, -8.4106, -8.8776, -8.4885, -8.0653, -8.9134,\n",
            "        -8.8460, -8.9349, -8.8968, -9.0577, -9.0060, -9.1751, -8.7053, -9.0272,\n",
            "        -8.8624, -8.9371, -9.2383, -8.6979, -8.8019, -8.0908, -8.9243, -8.7013,\n",
            "        -9.0220, -9.2082, -9.1418, -9.0611, -8.9571, -8.7732, -9.1071, -8.6276,\n",
            "        -8.7661, -9.0606, -8.5963, -8.5050, -8.1809, -8.4853, -8.0785, -8.7700,\n",
            "        -8.7815, -8.8031, -8.6118, -8.7755, -8.6254, -9.1191, -8.8251, -8.7423,\n",
            "        -8.7340, -9.0021, -9.0234, -8.8969, -9.2271, -8.9767, -8.7353, -8.8265,\n",
            "        -9.0846, -9.1198, -8.8581, -8.9706, -9.1003, -8.8648, -9.0022, -9.1039,\n",
            "        -9.0140, -8.8441, -9.1058, -8.8585, -9.0584, -9.1290, -8.8098, -9.0623,\n",
            "        -9.0930, -9.1901, -8.5948, -8.8100, -8.8444, -8.6597, -8.7837, -8.0605,\n",
            "        -8.6925, -8.8016, -9.0342, -8.5783, -9.1568, -8.5492, -9.0364, -8.8370,\n",
            "        -8.9381, -8.6182, -9.1481, -9.0447, -9.0752, -9.2398, -8.8000, -9.2071,\n",
            "        -8.4916, -8.5600, -8.6711, -8.2731, -8.7712, -8.1990, -8.5886, -7.7021,\n",
            "        -2.6436,  8.1645, -6.1585, -9.1089, -9.0229, -8.5464, -8.8517, -8.8027,\n",
            "        -8.9153, -9.0223, -8.6400, -9.0532, -8.9059, -8.6530, -8.6328, -9.1055,\n",
            "        -8.9876, -8.9693, -8.6677, -8.6163, -8.9896, -8.4962, -8.6768, -8.8123,\n",
            "        -8.6607, -9.2096, -9.1146, -8.9938, -9.2197, -9.1366, -9.0076, -9.1417,\n",
            "        -8.9035, -9.1583, -8.9634, -8.9092, -8.8925, -8.8393, -9.2218, -9.1542,\n",
            "        -9.0826, -8.9949, -8.8488, -9.0600, -9.0287, -8.6956, -8.1011, -8.8019,\n",
            "        -8.6470, -8.8805, -9.2872, -8.7135, -8.8273, -8.9967, -8.9026, -9.0458,\n",
            "        -8.8510, -9.0488, -8.9623, -9.0587, -8.7996, -9.0238, -8.7432, -8.9709,\n",
            "        -8.9231, -9.6933, -8.0841, -8.7541, -8.9801, -8.6804, -8.9213, -9.0781,\n",
            "        -8.7022, -8.8977, -8.9722, -8.9499, -8.6888, -9.1729, -8.8017, -9.0408,\n",
            "        -8.9869, -8.8300, -8.8385, -7.5136, -8.8872, -8.5629, -8.7889, -8.8875,\n",
            "        -8.0241, -8.8525, -8.5664, -8.9172, -8.8763, -8.8373, -8.7785, -8.8992,\n",
            "        -8.7687, -8.4628, -9.0708, -8.7684, -9.1136, -8.6080, -8.8325, -8.9369,\n",
            "        -9.0455, -8.7912, -8.8215, -8.9911, -8.9941, -9.0369, -8.9849, -9.0195,\n",
            "        -8.9800, -9.0203, -8.6553, -8.4874, -8.9546, -8.9111, -8.8509, -8.7853,\n",
            "        -8.2705, -8.8280, -8.8562, -9.0161, -8.8687, -9.0252, -8.8528, -8.9962,\n",
            "        -9.1054, -8.9904, -8.9077, -9.0001, -9.1745, -8.9965, -8.9227, -9.0485,\n",
            "        -8.9986, -9.0188, -8.8253, -9.0664, -9.2502, -9.2134, -9.1933, -9.2015,\n",
            "        -9.2209, -9.2106, -9.1958, -9.2149, -9.2444, -9.2336, -9.2556, -9.2340,\n",
            "        -9.2370, -9.2163, -9.2060, -9.2225, -9.2669, -9.2507, -9.2833, -9.2785,\n",
            "        -9.2735, -9.2951, -9.2894, -9.2967, -9.3167, -9.2691, -9.2673, -9.2899,\n",
            "        -9.3074, -9.2989, -9.2690, -9.2870, -9.2871, -9.2757, -9.2521, -9.2534,\n",
            "        -9.2539, -9.2618, -9.2019, -9.2214, -9.2244, -9.2286, -9.2428, -9.2599,\n",
            "        -9.2640, -9.2820, -9.2848, -9.2982, -9.2960, -9.3251, -9.3046, -9.3177,\n",
            "        -9.3010, -9.2950, -9.3070, -9.2894, -9.2945, -9.3015, -9.2817, -9.3149,\n",
            "        -9.2990, -9.2771, -9.2596, -9.2675, -9.2503, -9.2415, -9.2564, -9.2805,\n",
            "        -9.2859, -9.2511, -9.2978, -9.2723, -9.2769, -9.2546, -9.2277, -9.2402,\n",
            "        -9.2605, -9.2769, -9.2830, -9.3130, -9.3050, -9.2768, -9.3170, -9.2876,\n",
            "        -9.3314, -9.3045, -9.2912, -9.3104, -9.2950, -9.3017, -9.3048, -9.3098,\n",
            "        -9.2948, -9.2973, -9.3411, -9.3348, -9.2877, -9.2984, -9.2497, -9.2525,\n",
            "        -9.2491, -9.2445, -9.2566, -9.2733, -9.2118, -9.2423, -9.2788, -9.2524,\n",
            "        -9.2962, -9.2961, -9.2600, -9.2593, -9.2594, -9.2746, -9.2922, -9.3039,\n",
            "        -9.3036, -9.2802, -9.3220, -9.3503, -9.3447, -9.3279, -9.3329, -9.3323,\n",
            "        -9.3026, -9.2771, -9.2671, -9.2689, -9.2775, -9.2558, -9.2911, -9.2732,\n",
            "        -9.2890, -9.2809, -9.2874, -9.2847, -9.2904, -9.2540, -9.2806, -9.2616,\n",
            "        -9.2769, -9.3001, -9.3214, -9.3076, -9.3041, -9.2969, -9.3064, -9.3047,\n",
            "        -9.3272, -9.2694, -9.3213, -9.2581, -9.2742, -9.2666, -9.2575, -9.2437,\n",
            "        -9.2473, -9.2671, -9.2317, -9.2714, -9.2693, -9.2305, -9.2436, -9.1974,\n",
            "        -9.1943, -9.2313, -9.2267, -9.2335, -9.2524, -9.2154, -9.2434, -9.2655,\n",
            "        -9.2713, -9.2753, -9.2693, -9.2355, -9.2118, -9.2444, -9.2272, -9.2269,\n",
            "        -9.2325, -9.2423, -9.2382, -9.2465, -9.2399, -9.2478, -9.2251, -9.2170,\n",
            "        -9.2211, -9.2003, -9.1857, -9.1884, -9.1802, -9.2049, -9.1956, -9.2136,\n",
            "        -9.2341, -9.2494, -9.2497, -9.2526, -9.2727, -9.2399, -9.2526, -9.2492,\n",
            "        -9.2315, -9.2585, -9.2446, -9.2484, -9.2565, -9.2296, -9.2621, -9.2634,\n",
            "        -9.2364, -9.2003, -9.2600, -9.2031, -9.2191, -9.2359, -9.2059, -9.2170,\n",
            "        -9.2211, -9.2295, -9.2507, -9.2627, -9.2797, -9.2358, -9.2221, -9.3175,\n",
            "        -9.2852, -9.2827, -9.2486, -9.2634, -9.2797, -9.2895, -9.2745, -9.2888,\n",
            "        -9.2935, -9.2875, -9.3037, -9.2946, -9.2232, -9.2703, -9.2691, -9.2292,\n",
            "        -9.2265, -9.2709, -9.2684, -9.2442, -9.2360, -9.1315, -9.1906, -9.0627],\n",
            "       device='cuda:0') tensor([ -7.3219,  -9.2007,  -9.0664,  -9.5270,  -9.4714,  -9.6567,  -9.7004,\n",
            "         -9.6398,  -9.4202,  -9.3870,  -9.2818,  -8.9585,  -9.3396,  -9.3939,\n",
            "         -9.2465,  -9.5652,  -9.1283,  -9.3580,  -9.7635, -10.1083,  -9.7090,\n",
            "         -9.4872,  -9.3296,  -9.1680,  -9.3278,  -9.4192,  -9.0640,  -9.4862,\n",
            "         -9.6406,  -9.8910, -10.1485,  -9.8319,  -9.8042,  -9.3616,  -9.1806,\n",
            "         -9.1899,  -9.4102,  -9.7058,  -9.5840,  -9.7546,  -9.5527,  -9.3804,\n",
            "         -9.7768,  -9.5881,  -9.4178,  -9.1743,  -9.6582,  -9.8455,  -9.4562,\n",
            "         -9.0297,  -8.9568,  -9.4548,  -8.1684,  -9.1485,  -9.2934,  -9.5599,\n",
            "         -9.6093,  -9.2649,  -9.3747,  -9.4740,  -9.6238,  -9.0918,  -9.6748,\n",
            "         -9.5144,  -9.3637,  -9.4922,  -9.6460,  -9.5781,  -9.1601,  -9.6643,\n",
            "         -9.8269,  -9.5512,  -9.1896,  -9.5603,  -9.7501,  -9.5711,  -9.5683,\n",
            "         -9.6992,  -9.5577,  -9.6740,  -9.7798,  -9.7897,  -9.5350,  -9.7696,\n",
            "         -9.4740,  -9.4871,  -9.7640,  -9.6578,  -9.4785,  -9.6390,  -9.9543,\n",
            "         -9.5315,  -9.0779,  -8.0663,  -9.2028,  -9.3339,  -8.7944,  -9.3932,\n",
            "         -9.3604,  -9.5163,  -9.2247,  -9.2843,  -9.6192,  -9.5580,  -9.7023,\n",
            "         -9.5498,  -9.3187,  -9.7369,  -9.3451,  -9.3611,  -9.6661,  -9.3720,\n",
            "         -9.4871,  -9.3232,  -9.2154,  -9.3867,  -9.0339,  -9.0813,  -9.3084,\n",
            "         -9.2133,   8.8002,  -1.9176,  -7.5247,  -9.2702,  -9.6672,  -9.2402,\n",
            "         -9.6345,  -9.3536,  -9.5250,  -9.7809,  -9.8244,  -9.3897,  -9.6066,\n",
            "         -9.7635,  -9.4408,  -9.4237,  -9.7723,  -9.2088,  -9.5162,  -9.5709,\n",
            "         -9.3331,  -9.4614,  -9.2586,  -9.2191,  -9.4801,  -9.5628,  -9.8806,\n",
            "         -9.7462,  -9.6389,  -9.9196,  -9.7824,  -9.7147,  -9.9789,  -9.8217,\n",
            "         -9.9077,  -9.9755,  -9.8437,  -9.8338,  -9.6015,  -9.8732,  -9.4881,\n",
            "         -9.5806,  -9.8296,  -9.5724,  -9.7101,  -9.7561,  -4.6107,  -9.3073,\n",
            "         -9.5208,  -9.7157,  -9.4523,  -9.8157,  -9.8103,  -9.6379, -10.0485,\n",
            "        -10.0217,  -9.7851,  -9.8022,  -9.9040,  -9.7761,  -9.9069,  -9.8150,\n",
            "         -9.8227,  -9.5453,  -9.3236,  -6.2077,  -9.6085,  -9.6707,  -9.6792,\n",
            "         -9.6938,  -9.3920,  -9.5853,  -9.7138,  -9.4166,  -9.5403,  -9.6593,\n",
            "         -9.7145,  -9.5729,  -9.8546,  -9.6142,  -9.6020,  -9.7390,  -9.4423,\n",
            "         -3.5068,  -9.8464,  -9.9192,  -9.5976,  -9.5698,  -9.9318,  -9.8030,\n",
            "        -10.0209,  -9.9846,  -9.9699,  -9.7884,  -9.7221,  -9.5938,  -9.7973,\n",
            "         -9.9318,  -9.8203, -10.0204,  -9.9060, -10.1771,  -9.9221,  -9.8924,\n",
            "         -9.4322,  -9.8426,  -9.7895,  -9.8610,  -9.7581,  -9.8465,  -9.8296,\n",
            "         -9.7593,  -9.7696,  -9.6529,  -9.9075,  -9.9204,  -9.9045,  -9.9721,\n",
            "         -9.6436,  -9.6297,  -9.8932,  -9.7220,  -9.8178,  -9.7071,  -9.9655,\n",
            "        -10.0045, -10.0215,  -9.9360,  -9.7766,  -9.9737,  -9.9559,  -9.8933,\n",
            "         -9.7290,  -9.9850,  -9.8292,  -9.7250,  -9.6668,  -9.6937,  -9.8590,\n",
            "         -9.2531,  -9.8937,  -9.9832, -10.0327, -10.0260, -10.0079, -10.0397,\n",
            "        -10.0254,  -9.9924,  -9.9893,  -9.9887,  -9.9426,  -9.9711,  -9.9495,\n",
            "         -9.9744, -10.0112,  -9.9731,  -9.9951, -10.0044,  -9.9271,  -9.9720,\n",
            "         -9.9484,  -9.9465,  -9.9753,  -9.9511,  -9.9188,  -9.9709,  -9.9556,\n",
            "         -9.9549,  -9.9310,  -9.9266,  -9.9402,  -9.9294,  -9.9393,  -9.9490,\n",
            "         -9.9700,  -9.9490,  -9.9292,  -9.8486,  -9.9749,  -9.9999,  -9.9687,\n",
            "         -9.9544,  -9.9717,  -9.9723,  -9.9825,  -9.9700,  -9.9687,  -9.9511,\n",
            "         -9.9529,  -9.9367,  -9.9633,  -9.9734,  -9.9921,  -9.9794,  -9.9571,\n",
            "         -9.9985,  -9.9918,  -9.9841, -10.0140,  -9.9635,  -9.9608,  -9.9110,\n",
            "         -9.9953, -10.0194, -10.0379,  -9.9935,  -9.9911,  -9.9816,  -9.9937,\n",
            "        -10.0223,  -9.9836, -10.0100,  -9.9963,  -9.9954, -10.0135, -10.0071,\n",
            "        -10.0100, -10.0012,  -9.9873,  -9.9639,  -9.9873,  -9.9790,  -9.9846,\n",
            "        -10.0240,  -9.9534,  -9.9899,  -9.9913,  -9.9678, -10.0098,  -9.9860,\n",
            "         -9.9553,  -9.9561,  -9.9732,  -9.9567,  -9.9317,  -9.9269,  -9.9627,\n",
            "         -9.9180,  -9.9086,  -9.9599,  -9.9771,  -9.9699,  -9.9381,  -9.8746,\n",
            "         -9.9811,  -9.8874,  -9.9058,  -9.9691,  -9.9021,  -9.9098,  -9.9566,\n",
            "         -9.9671,  -9.9444,  -9.9027,  -9.9003,  -9.9306,  -9.9360,  -9.9122,\n",
            "         -9.9390,  -9.9337,  -9.9142,  -9.9049,  -9.9269,  -9.9350,  -9.9715,\n",
            "         -9.9892,  -9.9443,  -9.9698,  -9.9644,  -9.9835,  -9.9924, -10.0015,\n",
            "         -9.9684,  -9.9710,  -9.9782,  -9.9790,  -9.9959, -10.0181,  -9.9769,\n",
            "        -10.0234, -10.0225, -10.0158, -10.0121, -10.0200, -10.0134, -10.0207,\n",
            "        -10.0000, -10.0025, -10.0095, -10.0673,  -9.9755, -10.0291, -10.0168,\n",
            "        -10.0330, -10.0490,  -9.9875,  -9.9855,  -9.9814, -10.0101,  -9.9733,\n",
            "         -9.9734, -10.0076,  -9.9601,  -9.9847,  -9.9754, -10.0302, -10.0323,\n",
            "         -9.9958,  -9.9706, -10.0311,  -9.9831,  -9.9915,  -9.9941, -10.0024,\n",
            "        -10.0001, -10.0199, -10.0421,  -9.9901,  -9.9787,  -9.9606, -10.0022,\n",
            "        -10.0117, -10.0037,  -9.9823,  -9.9918,  -9.9667,  -9.9696,  -9.9604,\n",
            "         -9.8776, -10.0034, -10.0444, -10.0355, -10.0304, -10.0009, -10.0169,\n",
            "        -10.0337, -10.0209, -10.0076, -10.0019, -10.0042,  -9.9938, -10.0366,\n",
            "        -10.0457, -10.0437, -10.0520, -10.0316, -10.0434, -10.0534, -10.0452,\n",
            "        -10.0587, -10.0141,  -9.9926,  -9.9285,  -9.9880,  -9.9987, -10.0678,\n",
            "        -10.0318,  -9.9794, -10.0513, -10.0508, -10.0296, -10.0572, -10.0092,\n",
            "         -9.9884,  -9.9861, -10.0172, -10.0200,  -9.9471,  -9.9859,  -9.9531,\n",
            "         -9.9856,  -9.9529,  -9.9686,  -9.9792,  -9.9929,  -9.9351,  -9.9314,\n",
            "         -9.9197,  -9.9248,  -9.9468,  -9.9883,  -9.9427,  -9.9167,  -9.9388,\n",
            "         -9.9095,  -9.9576,  -9.9443,  -9.9257,  -9.9287,  -9.8928,  -9.8058,\n",
            "         -9.2518], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = KoMRC.load('/content/test.json')\n",
        "test_dataset = TKIndexerWrappedDataset(test_dataset, tokenizer)\n",
        "print(\"Number of Test Samples\", len(test_dataset))\n",
        "print(test_dataset[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvtpkqbdFsMT",
        "outputId": "a5d2c964-361a-41d3-86fa-e6a1eab99136"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5341/5341 [00:00<00:00, 17308.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Test Samples 5341\n",
            "{'input_ids': tensor([    2, 22917, 28206, 17216, 14522, 37421, 16160, 27025,  8078,  2033,\n",
            "            3, 22496, 22354,  2010, 14388, 32124,  8175,  2011,  3052, 29368,\n",
            "        14702, 29217, 16022, 13975,     1, 22496, 22354, 14702, 19493, 27025,\n",
            "            1,  5887, 17280, 26526, 13980, 14875,  2016, 14099, 22496, 22354,\n",
            "        14702, 19493, 27025,  2010, 16510, 14702, 19493, 27025,  2011,  5883,\n",
            "        22496, 25672, 15142,  8061, 25264, 15142,  2014, 23117, 15142,  2014,\n",
            "        23507, 15142,  6677, 33886,  2014, 21420, 23973, 14856, 17101,  2014,\n",
            "        22496, 18308, 14670, 15525, 28491,  4345, 13979,  7747, 15683,  8038,\n",
            "        18666,  6540, 17666, 14937,  8734, 29453,  8112, 33184,  5226, 17426,\n",
            "        33295, 36886, 29014, 23160, 36044,  2016, 14336,  3033, 35898,  8129,\n",
            "         4340,  3033, 35898,  8167, 14702, 19493, 27025,  8078,  7328, 37997,\n",
            "        14117,  5684, 20875,  8266, 15701,  2010, 32362, 17280,  2011, 14681,\n",
            "        21089,  8122, 14908,  2010, 32362, 17280,  2011, 18666, 28594,  8013,\n",
            "         2016, 27782, 39541, 33803,  5684, 20875,  8266, 15701,  8078, 14149,\n",
            "        15030, 15232, 32749,  8152, 25672, 15142,  8273, 14203, 14121, 28491,\n",
            "        22350, 24827, 20911,  8289, 18938, 31409,  5683, 24815, 27844, 28112,\n",
            "        14060, 26462,  2016,  2053, 15961, 18726,  7328, 37997, 33803, 21089,\n",
            "         8122, 14908,  8034, 34559, 41267, 25672, 15142,  8273, 14203, 14121,\n",
            "        28491,  4345, 14754,  2014,  4485,  9499,  8907,  2117, 15400, 36107,\n",
            "        23034,  8013,  2016,  3033, 20774,  8022,  8167, 14702, 19493, 27025,\n",
            "         2010, 14702,  8152, 17280,  2011,  5883, 14219,  8459,  4626,  8398,\n",
            "        31171,  8147, 14907, 19638, 21156,  8013,  2016, 22496,  8048, 18117,\n",
            "         8008, 14121, 28491, 14219,  8459,  4626,  8398, 31171,  8147, 14907,\n",
            "         8034, 20227,  3175,  7825, 13973, 17136, 36814, 15878, 14186,  2014,\n",
            "        14208, 37872, 24454, 13969, 16530,  8010, 14792, 14978,  3175, 13990,\n",
            "         2016,  3033, 22086,  8022,  8129, 14702, 19493, 27025,  2010, 14702,\n",
            "         8152, 17280,  2011,  5883,  3033, 25672, 15142, 14702, 19493, 27025,\n",
            "        14021, 28594, 21089,  8122, 14908, 18666, 15986, 14349,  2016,  3033,\n",
            "        25447,  8022,  8128,  8129, 14702, 19493, 27025,  2010,  2025,  8152,\n",
            "        17280,  2011, 25957, 22917, 28206,  8147, 15701, 18703, 17234, 28594,\n",
            "         8013,  2016, 28263, 15889,  5683, 24815, 17136, 20911,  8051, 34322,\n",
            "        13975, 22917, 28206,  8147, 15701, 18703,  8034, 17637, 19526, 14406,\n",
            "        14106,  2299,  8050, 22917, 28206, 17216, 21750, 14909,  2016,  3033,\n",
            "        24323,  8022,  8129,  2064, 24801, 20274,  2430,  8019,  8443,  8674,\n",
            "        14702, 19493, 27025,  2010,  2026,  8152, 17280,  2011,  5883, 17609,\n",
            "        20975, 26102, 21527,  5617, 40815,  8266, 19855, 22123,  8215, 14032,\n",
            "         4163,  8264,  8117, 14908, 19638, 21156,  8013,  2016, 14208,  4163,\n",
            "         8264,  8117, 14908,  8034, 14149, 32763, 41436, 23507, 15142,  8008,\n",
            "        16829, 14937, 22181, 14695, 14991, 41450,  8040, 13975, 21088, 19345,\n",
            "        13984,  2016,     3,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), 'start': None, 'end': None, 'guid': 'd14cb73158624cf094c546d856fd3c80'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "\n",
        "os.makedirs('out', exist_ok=True)\n",
        "with torch.no_grad(), open('out/baseline.csv', 'w') as fd:\n",
        "    writer = csv.writer(fd)\n",
        "    writer.writerow(['Id', 'Predicted'])\n",
        "\n",
        "    rows = []\n",
        "    for sample in tqdm(test_dataset, \"Testing\"):\n",
        "\n",
        "        input_ids, token_type_ids, attention_mask = [\n",
        "            torch.tensor(sample[key], dtype=torch.long, device=\"cuda\")\n",
        "            for key in (\"input_ids\", \"token_type_ids\",\"attention_mask\")\n",
        "        ]\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            start_logits, end_logits = model(input_ids=input_ids[None, :], token_type_ids=token_type_ids[None, :], attention_mask=attention_mask[None, :])\n",
        "        start_logits.squeeze_(0), end_logits.squeeze_(0)\n",
        "        \n",
        "        start_prob = start_logits[token_type_ids.bool()][1:-1].softmax(-1)\n",
        "        end_prob = end_logits[token_type_ids.bool()][1:-1].softmax(-1)\n",
        "        probability = torch.triu(start_prob[:, None] @ end_prob[None, :])\n",
        "\n",
        "        if probability.numel() :\n",
        "          index = torch.argmax(probability).item()\n",
        "            \n",
        "          start = index // len(end_prob)\n",
        "          end = index % len(end_prob)\n",
        "          \n",
        "          answer = sample[\"input_ids\"][int(start) : int(end) + 1]\n",
        "          last_answer = tokenizer.decode(answer)\n",
        "          rows.append([sample[\"guid\"], last_answer])\n",
        "\n",
        "\n",
        "          # input_ids, token_type_ids = [\n",
        "          #     torch.tensor(sample[key], dtype=torch.long, device=\"cuda\")\n",
        "          #     for key in (\"input_ids\", \"token_type_ids\")\n",
        "          # ]\n",
        "      \n",
        "          # with torch.no_grad():\n",
        "          #     start_logits, end_logits = model(input_ids=input_ids[None, :], token_type_ids=token_type_ids[None, :])\n",
        "          # start_logits.squeeze_(0), end_logits.squeeze_(0)\n",
        "      \n",
        "          # start_prob = start_logits[token_type_ids.bool()][1:-1].softmax(-1)\n",
        "          # end_prob = end_logits[token_type_ids.bool()][1:-1].softmax(-1)\n",
        "          # probability = torch.triu(start_prob[:, None] @ end_prob[None, :])\n",
        "          # index = torch.argmax(probability).item()\n",
        "      \n",
        "          # start = index // len(end_prob)\n",
        "          # end = index % len(end_prob)\n",
        "      \n",
        "          # start = sample['position'][start][0]\n",
        "          # end = sample['position'][end][1]\n",
        "\n",
        "          # rows.append([sample[\"guid\"], sample['context'][start:end]])\n",
        "    \n",
        "    writer.writerows(rows)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kd46PfDOFvjy",
        "outputId": "7ea036b9-2818-4f3a-a235-993a3958e43d"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing:   0%|          | 0/5341 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n",
            "Testing: 100%|██████████| 5341/5341 [03:35<00:00, 24.80it/s]\n"
          ]
        }
      ]
    }
  ]
}